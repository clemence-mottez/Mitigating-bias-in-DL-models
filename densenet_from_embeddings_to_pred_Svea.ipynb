{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from collections import defaultdict\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"final_data/densenet_valid_embeddings.csv\")\n",
    "train = pd.read_csv(\"final_data/densenet_test_embeddings.csv\", quotechar='\"', on_bad_lines='skip')\n",
    "\n",
    "print(test.columns)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert embeddings from str to list (a bit long for large data sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['embeddings'] = test['embeddings'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['embeddings'] = train['embeddings'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(columns=['path_to_image', 'path_to_dcm'])\n",
    "train = train.drop(columns=['path_to_image', 'path_to_dcm'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove rows that were not processed (embeddings = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_size = test.shape[0] \n",
    "\n",
    "# The previous logic with transforming the list to string and filtering on the length of said string is not necessarily stable and misleading.\n",
    "# Let's implement a more explicit test for what we actually care about: \n",
    "\n",
    "test = test[test['embeddings'].apply(type) == list]\n",
    "\n",
    "final_size = test.shape[0] \n",
    "\n",
    "print(f'Number of test removed rows = {initial_size - final_size}')\n",
    "\n",
    "initial_size = train.shape[0] \n",
    "\n",
    "train = train[train['embeddings'].apply(type) == list]\n",
    "\n",
    "final_size = train.shape[0] \n",
    "\n",
    "print(f'Number of train removed rows = {initial_size - final_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Using Random Forest as the base estimator\n",
    "# base_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# # Multi-output classifier\n",
    "# multi_target_rf = MultiOutputClassifier(base_rf, n_jobs=-1)\n",
    "\n",
    "# # Train the model\n",
    "# multi_target_rf.fit(train_embeddings, y_train)\n",
    "\n",
    "# # Predict on test data\n",
    "# predictions = multi_target_rf.predict(test_embeddings)\n",
    "\n",
    "# # Evaluate the model\n",
    "# print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "# print(\"F1 Score:\", f1_score(y_test, predictions, average='micro'))\n",
    "# print(\"Recall:\", recall_score(y_test, predictions, average='micro'))\n",
    "# print(\"Precision:\", precision_score(y_test, predictions, average='micro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings = pd.DataFrame(train['embeddings'].tolist(), columns=[f'embedding_{i}' for i in range(1024)])\n",
    "test_embeddings = pd.DataFrame(test['embeddings'].tolist(), columns=[f'embedding_{i}' for i in range(1024)])\n",
    "\n",
    "# Diseases to predict\n",
    "diseases = ['Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity', 'Lung Lesion', 'Edema', 'Consolidation', 'Pneumonia',\n",
    "            'Atelectasis', 'Pneumothorax', 'Pleural Effusion', 'Pleural Other', 'Fracture']\n",
    "\n",
    "# Labels for train and test\n",
    "y_train = train[diseases]\n",
    "y_test = test[diseases]\n",
    "\n",
    "# Create x_train and x_test\n",
    "x_train = pd.concat([train.reset_index(), train_embeddings], axis=1)\n",
    "x_test =  pd.concat([test.reset_index(), test_embeddings], axis=1)\n",
    "\n",
    "x_train.drop(columns=[\"embeddings\"] + diseases, inplace=True)\n",
    "x_test.drop(columns=[\"embeddings\"] + diseases, inplace=True)\n",
    "\n",
    "# Create some backups:\n",
    "_x_train, _x_test, _y_train, _y_test = x_train.copy(deep=True), x_test.copy(deep=True), y_train.copy(deep=True), y_test.copy(deep=True)\n",
    "# To restore the backups, run:\n",
    "# x_train, x_test, y_train, y_test = _x_train.copy(deep=True), _x_test.copy(deep=True), _y_train.copy(deep=True), _y_test.copy(deep=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diseases = ['Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity', 'Lung Lesion', 'Edema', \n",
    "            'Consolidation', 'Pneumonia', 'Atelectasis', 'Pneumothorax', \n",
    "            'Pleural Effusion', 'Pleural Other', 'Fracture']\n",
    "\n",
    "def train_model(x_train, y_train, x_test, y_test, model, metric_dimensions=[], columns_to_drop=[], n_components=None):\n",
    "    multi_output_model = MultiOutputClassifier(model)\n",
    "    x_test = x_test.reset_index(drop=True)\n",
    "    y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "    x_train_subset = x_train.drop(columns=columns_to_drop, errors='ignore')\n",
    "    x_test_subset = x_test.drop(columns=columns_to_drop, errors='ignore')\n",
    "    \n",
    "    # Apply PCA if specified\n",
    "    if n_components:\n",
    "        pca = PCA(n_components=n_components)\n",
    "        x_train_subset = pca.fit_transform(x_train_subset)\n",
    "        x_test_subset = pca.transform(x_test_subset)\n",
    "        print(f\"PCA used with {n_components} components.\")\n",
    "    else:\n",
    "        print(\"PCA not used.\")\n",
    "\n",
    "    # Prepare to store all metrics\n",
    "    metrics_data = {\n",
    "        'Metric Dimension': [],\n",
    "        'Subgroup': [],\n",
    "        'Disease': [],\n",
    "        'Accuracy': [],\n",
    "        'F1 Score': [],\n",
    "        'Recall': [],\n",
    "        'Precision': []\n",
    "    }\n",
    "\n",
    "    def calculate_metrics(y_true, y_pred, disease_label=\"Overall\"):\n",
    "        \"\"\" Helper function to calculate metrics and add them to metrics_data \"\"\"\n",
    "        metrics_data['Metric Dimension'].append(metric_dim)\n",
    "        metrics_data['Subgroup'].append(subgroup)\n",
    "        metrics_data['Disease'].append(disease_label)\n",
    "        metrics_data['Accuracy'].append(accuracy_score(y_true, y_pred))\n",
    "        metrics_data['F1 Score'].append(f1_score(y_true, y_pred, average='micro'))\n",
    "        metrics_data['Recall'].append(recall_score(y_true, y_pred, average='micro'))\n",
    "        metrics_data['Precision'].append(precision_score(y_true, y_pred, average='micro'))\n",
    "\n",
    "    # Train the model on the full dataset\n",
    "    try:\n",
    "        multi_output_model.fit(x_train_subset, y_train)\n",
    "        # Make predictions\n",
    "        y_test_preds = pd.DataFrame(multi_output_model.predict(x_test_subset), columns=diseases)\n",
    "        metric_dim, subgroup = \"all\", \"all\"\n",
    "        calculate_metrics(y_test, y_test_preds)\n",
    "        # Calculate metrics for each disease individually\n",
    "        for disease in diseases:\n",
    "            calculate_metrics(y_test[disease], y_test_preds[disease], disease_label=disease)\n",
    "    except ValueError:\n",
    "        print(\"Multi-output not supported. Training each disease separately.\")\n",
    "        for disease in diseases:\n",
    "            model.fit(x_train_subset, y_train[disease])\n",
    "            y_test_preds = model.predict(x_test_subset)\n",
    "            metric_dim, subgroup = \"all\", \"all\"\n",
    "            calculate_metrics(y_test[disease], y_test_preds, disease_label=disease)\n",
    "\n",
    "    # Calculate metrics for each dimension in `metric_dimensions`\n",
    "    for metric_dim in metric_dimensions:\n",
    "        for subgroup in x_test[metric_dim].unique():\n",
    "            # Create a boolean mask for the subgroup\n",
    "            mask = (x_test[metric_dim] == subgroup)\n",
    "            x_test_subgroup = x_test_subset[mask]\n",
    "            y_test_subgroup = y_test.loc[mask]\n",
    "            try:\n",
    "                y_test_preds_subgroup = y_test_preds.loc[mask]\n",
    "                calculate_metrics(y_test_subgroup, y_test_preds_subgroup)\n",
    "                for disease in diseases:\n",
    "                    calculate_metrics(y_test_subgroup[disease], y_test_preds_subgroup[disease], disease_label=disease)\n",
    "            except Exception:\n",
    "                for disease in diseases:\n",
    "                    y_test_subgroup_disease = y_test_subgroup[disease]\n",
    "                    y_test_preds_disease = model.predict(x_test_subgroup)\n",
    "                    calculate_metrics(y_test_subgroup_disease, y_test_preds_disease, disease_label=disease)\n",
    "\n",
    "    # Convert metrics_data to DataFrame and return\n",
    "    metrics_df = pd.DataFrame(metrics_data)\n",
    "    metrics_df = metrics_df.reset_index(drop=True)\n",
    "    print(metrics_df.columns) \n",
    "    return metrics_df\n",
    "\n",
    "def plot_metrics(metrics_df, metric_name, modelname, trainingsize):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 14))  # Größere Figur\n",
    "    fig.suptitle(f\"{metric_name} Comparison Across Dimensions\", fontsize=18)\n",
    "    fig.text(0.5, 0.94, f\"Trained with model: {modelname} on the following training size: {trainingsize}\", \n",
    "             ha='center', fontsize=12, color=\"gray\")\n",
    "\n",
    "    palette = [\"#3498DB\", \"#FFC300\", \"#2ECC71\", \"#E74C3C\"]\n",
    "# Plot 1: Metric by Disease for each Sex\n",
    "    sex_data = metrics_df[metrics_df['Metric Dimension'] == 'sex']\n",
    "    sns.barplot(data=sex_data, x='Disease', y=metric_name, hue='Subgroup', ax=axes[0, 0], palette=palette[:2])\n",
    "    axes[0, 0].set_title(f\"{metric_name} by Disease and Sex\", fontsize=14)\n",
    "    axes[0, 0].tick_params(axis='x', rotation=90)\n",
    "    \n",
    "    # Plot 2: Metric by Disease for each Insurance_Type\n",
    "    insurance_data = metrics_df[metrics_df['Metric Dimension'] == 'insurance_type']\n",
    "    sns.barplot(data=insurance_data, x='Disease', y=metric_name, hue='Subgroup', ax=axes[0, 1], palette=palette[:3])\n",
    "    axes[0, 1].set_title(f\"{metric_name} by Disease and Insurance Type\", fontsize=14)\n",
    "    axes[0, 1].tick_params(axis='x', rotation=90)  \n",
    "    \n",
    "    # Plot 3: Metric by Disease for each Race\n",
    "    race_data = metrics_df[metrics_df['Metric Dimension'] == 'race']\n",
    "    sns.barplot(data=race_data, x='Disease', y=metric_name, hue='Subgroup', ax=axes[1, 0], palette=palette[:3])  \n",
    "    axes[1, 0].set_title(f\"{metric_name} by Disease and Race\", fontsize=14)\n",
    "    axes[1, 0].tick_params(axis='x', rotation=90)  \n",
    "    \n",
    "    # Plot 4: Overall Metric by Disease (no subgroups)\n",
    "    overall_disease_data = metrics_df[(metrics_df['Metric Dimension'] == 'all') & (metrics_df['Disease'] != 'Overall')]\n",
    "    overall_metric = metrics_df[(metrics_df['Metric Dimension'] == 'all') & (metrics_df['Disease'] == 'Overall')]\n",
    "    # Add the overall metric as a new row in the DataFrame for plotting\n",
    "    if not overall_metric.empty:\n",
    "        overall_row = pd.DataFrame({\n",
    "            'Disease': ['Overall'], \n",
    "            metric_name: [overall_metric[metric_name].values[0]]  # Accuracy over all diseases\n",
    "        })\n",
    "        overall_disease_data = pd.concat([overall_disease_data, overall_row], ignore_index=True)\n",
    "\n",
    "    # Plot the data including the \"Overall\" bar\n",
    "    sns.barplot(data=overall_disease_data, x='Disease', y=metric_name, ax=axes[1, 1], color=palette[0])\n",
    "    axes[1, 1].set_title(f\"{metric_name} by Disease (Overall)\", fontsize=14)\n",
    "    axes[1, 1].tick_params(axis='x', rotation=90)\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.3)  \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.92])  \n",
    "    plt.savefig(f\"ml_plots/{metric_name}_{modelname}_{trainingsize}_comparison.png\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "training_size = 2000\n",
    "use_pca = True        \n",
    "n_components = 10     \n",
    "\n",
    "# rcf = RandomForestClassifier(n_estimators=30, random_state=42)\n",
    "# rcf_metrics = train_model(\n",
    "#     x_train=x_train.iloc[:training_size], \n",
    "#     y_train=y_train.iloc[:training_size], \n",
    "#     x_test=x_test, \n",
    "#     y_test=y_test, \n",
    "#     model=rcf, \n",
    "#     metric_dimensions=[\"sex\", \"race\", \"insurance_type\"],\n",
    "#     n_components=n_components   \n",
    "# )\n",
    "\n",
    "# # Naive Bayes\n",
    "# naive_bayes = MultinomialNB()\n",
    "# nb_metrics = train_model(\n",
    "#     x_train=x_train.iloc[:training_size], \n",
    "#     y_train=y_train.iloc[:training_size], \n",
    "#     x_test=x_test, \n",
    "#     y_test=y_test, \n",
    "#     model=naive_bayes, \n",
    "#     metric_dimensions=[\"sex\", \"race\", \"insurance_type\"],\n",
    "#     n_components=None  \n",
    "# )\n",
    "\n",
    "#Gradient Boosting\n",
    "xgb = GradientBoostingClassifier(learning_rate=0.1, n_estimators=30, verbose=1, random_state=42, n_iter_no_change=5)\n",
    "xgb_metrics = train_model(\n",
    "   x_train=x_train.iloc[:training_size], \n",
    "   y_train=y_train.iloc[:training_size], \n",
    "   x_test=x_test, \n",
    "    y_test=y_test, \n",
    "    model=xgb, \n",
    "    metric_dimensions=[\"sex\", \"race\", \"insurance_type\"],\n",
    "   n_components=n_components   \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# # Decision Tree\n",
    "# dct = DecisionTreeClassifier(random_state=42)\n",
    "# dct_metrics = train_model(\n",
    "#     x_train=x_train.iloc[:training_size], \n",
    "#     y_train=y_train.iloc[:training_size], \n",
    "#     x_test=x_test, \n",
    "#     y_test=y_test, \n",
    "#     model=dct, \n",
    "#     metric_dimensions=[\"sex\", \"race\", \"insurance_type\"],\n",
    "#     n_components=n_components \n",
    "# )\n",
    "\n",
    "# Plotting\n",
    "for metric in ['Accuracy', 'F1 Score', 'Recall', 'Precision']:\n",
    "    #plot_metrics(rcf_metrics, metric, \"RandomForest_with_PCA\" , str(training_size))\n",
    "    #plot_metrics(nb_metrics, metric, \"NaiveBayes\", str(training_size))\n",
    "    plot_metrics(xgb_metrics, metric, \"GradientBoosting_with_PCA\" , str(training_size))\n",
    "    # plot_metrics(dct_metrics, metric, \"DecisionTree_with_PCA\", str(training_size))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diseases = ['Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity', 'Lung Lesion', 'Edema', \n",
    "            'Consolidation', 'Pneumonia', 'Atelectasis', 'Pneumothorax', \n",
    "            'Pleural Effusion', 'Pleural Other', 'Fracture']\n",
    "\n",
    "def train_model(x_train, y_train, x_test, y_test, model, metric_dimensions=[], columns_to_drop=[], n_components=None):\n",
    "    multi_output_model = MultiOutputClassifier(model)\n",
    "    x_test = x_test.reset_index(drop=True)\n",
    "    y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "    x_train_subset = x_train.drop(columns=columns_to_drop, errors='ignore')\n",
    "    x_test_subset = x_test.drop(columns=columns_to_drop, errors='ignore')\n",
    "    \n",
    "    # Apply PCA if wanted\n",
    "    if n_components:\n",
    "        pca = PCA(n_components=n_components)\n",
    "        x_train_subset = pca.fit_transform(x_train_subset)\n",
    "        x_test_subset = pca.transform(x_test_subset)\n",
    "        print(f\"PCA used with {n_components} components.\")\n",
    "    else:\n",
    "        print(\"PCA not used.\")\n",
    "\n",
    "    metrics_data = {\n",
    "        'Metric Dimension': [],\n",
    "        'Subgroup': [],\n",
    "        'Disease': [],\n",
    "        'Accuracy': [],\n",
    "        'F1 Score': [],\n",
    "        'Recall': [],\n",
    "        'Precision': [],\n",
    "        'AUC': [] \n",
    "    }\n",
    "\n",
    "    def calculate_metrics(y_true, y_pred, y_pred_proba=None, disease_label=\"Overall\"):\n",
    "        \"\"\" Helper function to calculate metrics and add them to metrics_data \"\"\"\n",
    "        metrics_data['Metric Dimension'].append(metric_dim)\n",
    "        metrics_data['Subgroup'].append(subgroup)\n",
    "        metrics_data['Disease'].append(disease_label)\n",
    "        metrics_data['Accuracy'].append(accuracy_score(y_true, y_pred))\n",
    "        metrics_data['F1 Score'].append(f1_score(y_true, y_pred, average='micro'))\n",
    "        metrics_data['Recall'].append(recall_score(y_true, y_pred, average='micro'))\n",
    "        metrics_data['Precision'].append(precision_score(y_true, y_pred, average='micro'))\n",
    "\n",
    "        if y_pred_proba is not None:\n",
    "            try:\n",
    "                auc = roc_auc_score(y_true, y_pred_proba)\n",
    "            except ValueError: \n",
    "                auc = None\n",
    "            metrics_data['AUC'].append(auc)\n",
    "        else:\n",
    "            metrics_data['AUC'].append(None)\n",
    "    try:\n",
    "        multi_output_model.fit(x_train_subset, y_train)\n",
    "        y_test_preds = pd.DataFrame(multi_output_model.predict(x_test_subset), columns=diseases)\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_test_preds_proba = pd.DataFrame({disease: probs[:, 1] for disease, probs in zip(diseases, multi_output_model.predict_proba(x_test_subset))}) # Dataframe with probabilites \n",
    "        else:\n",
    "            y_test_preds_proba = None\n",
    "\n",
    "        metric_dim, subgroup = \"all\", \"all\"\n",
    "        calculate_metrics(y_test, y_test_preds, y_test_preds_proba)\n",
    "        \n",
    "        # Calculate metrics for each disease individually\n",
    "        for disease in diseases:\n",
    "            y_true_disease = y_test[disease]\n",
    "            y_pred_disease = y_test_preds[disease]\n",
    "            y_pred_proba_disease = y_test_preds_proba[disease] if y_test_preds_proba is not None else None\n",
    "            calculate_metrics(y_true_disease, y_pred_disease, y_pred_proba_disease, disease_label=disease)\n",
    "    except ValueError:\n",
    "        print(\"Multi-output not supported. Training each disease separately.\")\n",
    "        for disease in diseases:\n",
    "            model.fit(x_train_subset, y_train[disease])\n",
    "            y_test_preds = model.predict(x_test_subset)\n",
    "            y_test_preds_proba = model.predict_proba(x_test_subset)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "            metric_dim, subgroup = \"all\", \"all\"\n",
    "            calculate_metrics(y_test[disease], y_test_preds, y_test_preds_proba, disease_label=disease)\n",
    "\n",
    "    # Calculate metrics for each dimension in `metric_dimensions` - in our case mostly sex, race, and insurance_type\n",
    "    for metric_dim in metric_dimensions:\n",
    "        for subgroup in x_test[metric_dim].unique(): #looks at every unique subgroup e.g. female and male \n",
    "            mask = (x_test[metric_dim] == subgroup) # here we only look at the rows where the subgroup e.g. female is True\n",
    "            x_test_subgroup = x_test_subset[mask]\n",
    "            y_test_subgroup = y_test.loc[mask]\n",
    "            try:\n",
    "                y_test_preds_subgroup = y_test_preds.loc[mask] # filtern of the predictions we made before just with that one subgroup\n",
    "                y_test_preds_proba_subgroup = y_test_preds_proba.loc[mask] if y_test_preds_proba is not None else None # filters also if applicable the y_test_pred_proba for that subgorup and line?\n",
    "                calculate_metrics(y_test_subgroup, y_test_preds_subgroup, y_test_preds_proba_subgroup)\n",
    "                for disease in diseases:\n",
    "                    y_true_subgroup_disease = y_test_subgroup[disease]\n",
    "                    y_pred_subgroup_disease = y_test_preds_subgroup[disease]\n",
    "                    y_pred_proba_subgroup_disease = y_test_preds_proba_subgroup[disease] if y_test_preds_proba_subgroup is not None else None\n",
    "                    calculate_metrics(y_true_subgroup_disease, y_pred_subgroup_disease, y_pred_proba_subgroup_disease, disease_label=disease)\n",
    "            except Exception:\n",
    "                for disease in diseases:\n",
    "                    y_test_subgroup_disease = y_test_subgroup[disease]\n",
    "                    y_test_preds_disease = model.predict(x_test_subgroup)\n",
    "                    y_test_preds_proba_disease = model.predict_proba(x_test_subgroup)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "                    calculate_metrics(y_test_subgroup_disease, y_test_preds_disease, y_test_preds_proba_disease, disease_label=disease)\n",
    "\n",
    "    # Convert metrics_data to DataFrame and return\n",
    "    metrics_df = pd.DataFrame(metrics_data)\n",
    "    metrics_df = metrics_df.reset_index(drop=True)\n",
    "    print(metrics_df.columns) \n",
    "    return metrics_df\n",
    "\n",
    "def plot_metrics(metrics_df, metric_name, modelname, trainingsize):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 14))  # Größere Figur\n",
    "    fig.suptitle(f\"{metric_name} Comparison Across Dimensions\", fontsize=18)\n",
    "    fig.text(0.5, 0.94, f\"Trained with model: {modelname} on the following training size: {trainingsize}\", \n",
    "             ha='center', fontsize=12, color=\"gray\")\n",
    "\n",
    "    palette = [\"#3498DB\", \"#FFC300\", \"#2ECC71\", \"#E74C3C\"]\n",
    "# Plot 1: Metric by Disease for each Sex\n",
    "    sex_data = metrics_df[metrics_df['Metric Dimension'] == 'sex']\n",
    "    sns.barplot(data=sex_data, x='Disease', y=metric_name, hue='Subgroup', ax=axes[0, 0], palette=palette[:2])\n",
    "    axes[0, 0].set_title(f\"{metric_name} by Disease and Sex\", fontsize=14)\n",
    "    axes[0, 0].tick_params(axis='x', rotation=90)\n",
    "    \n",
    "    # Plot 2: Metric by Disease for each Insurance_Type\n",
    "    insurance_data = metrics_df[metrics_df['Metric Dimension'] == 'insurance_type']\n",
    "    sns.barplot(data=insurance_data, x='Disease', y=metric_name, hue='Subgroup', ax=axes[0, 1], palette=palette[:3])\n",
    "    axes[0, 1].set_title(f\"{metric_name} by Disease and Insurance Type\", fontsize=14)\n",
    "    axes[0, 1].tick_params(axis='x', rotation=90)  \n",
    "    \n",
    "    # Plot 3: Metric by Disease for each Race\n",
    "    race_data = metrics_df[metrics_df['Metric Dimension'] == 'race']\n",
    "    sns.barplot(data=race_data, x='Disease', y=metric_name, hue='Subgroup', ax=axes[1, 0], palette=palette[:3])  \n",
    "    axes[1, 0].set_title(f\"{metric_name} by Disease and Race\", fontsize=14)\n",
    "    axes[1, 0].tick_params(axis='x', rotation=90)  \n",
    "    \n",
    "    # Plot 4: Overall Metric by Disease (no subgroups)\n",
    "    overall_disease_data = metrics_df[(metrics_df['Metric Dimension'] == 'all') & (metrics_df['Disease'] != 'Overall')]\n",
    "    overall_metric = metrics_df[(metrics_df['Metric Dimension'] == 'all') & (metrics_df['Disease'] == 'Overall')]\n",
    "    # Add the overall metric as a new row in the DataFrame for plotting\n",
    "    if not overall_metric.empty:\n",
    "        overall_row = pd.DataFrame({\n",
    "            'Disease': ['Overall'], \n",
    "            metric_name: [overall_metric[metric_name].values[0]]  # Accuracy over all diseases\n",
    "        })\n",
    "        overall_disease_data = pd.concat([overall_disease_data, overall_row], ignore_index=True)\n",
    "\n",
    "    # Plot the data including the \"Overall\" bar\n",
    "    sns.barplot(data=overall_disease_data, x='Disease', y=metric_name, ax=axes[1, 1], color=palette[0])\n",
    "    axes[1, 1].set_title(f\"{metric_name} by Disease (Overall)\", fontsize=14)\n",
    "    axes[1, 1].tick_params(axis='x', rotation=90)\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.3)  \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.92])  \n",
    "    plt.savefig(f\"ml_plots/{metric_name}_{modelname}_{trainingsize}_comparison.png\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "training_size = 2000\n",
    "use_pca = True        \n",
    "n_components = 10     \n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    use_label_encoder=False,      \n",
    "    eval_metric='logloss',   \n",
    "    learning_rate=0.1,\n",
    "    n_estimators=30,\n",
    "    random_state=42\n",
    ")\n",
    "xgb_metrics = train_model(\n",
    "    x_train=x_train.iloc[:training_size], \n",
    "    y_train=y_train.iloc[:training_size], \n",
    "    x_test=x_test, \n",
    "    y_test=y_test, \n",
    "    model=xgb_model, \n",
    "    metric_dimensions=[\"sex\", \"race\", \"insurance_type\"],\n",
    "    n_components=n_components \n",
    ")\n",
    "\n",
    "# rcf = RandomForestClassifier(n_estimators=30, random_state=42)\n",
    "# rcf_metrics = train_model(\n",
    "#     x_train=x_train.iloc[:training_size], \n",
    "#     y_train=y_train.iloc[:training_size], \n",
    "#     x_test=x_test, \n",
    "#     y_test=y_test, \n",
    "#     model=rcf, \n",
    "#     metric_dimensions=[\"sex\", \"race\", \"insurance_type\"],\n",
    "#     n_components=n_components   \n",
    "# )\n",
    "\n",
    "# # Naive Bayes\n",
    "# naive_bayes = MultinomialNB()\n",
    "# nb_metrics = train_model(\n",
    "#     x_train=x_train.iloc[:training_size], \n",
    "#     y_train=y_train.iloc[:training_size], \n",
    "#     x_test=x_test, \n",
    "#     y_test=y_test, \n",
    "#     model=naive_bayes, \n",
    "#     metric_dimensions=[\"sex\", \"race\", \"insurance_type\"],\n",
    "#     n_components=None  \n",
    "# )\n",
    "\n",
    "# # Gradient Boosting\n",
    "# xgb = GradientBoostingClassifier(learning_rate=0.1, n_estimators=30, verbose=1, random_state=42, n_iter_no_change=5)\n",
    "# xgb_metrics = train_model(\n",
    "#     x_train=x_train.iloc[:training_size], \n",
    "#     y_train=y_train.iloc[:training_size], \n",
    "#     x_test=x_test, \n",
    "#     y_test=y_test, \n",
    "#     model=xgb, \n",
    "#     metric_dimensions=[\"sex\", \"race\", \"insurance_type\"],\n",
    "#     n_components=n_components   \n",
    "# )\n",
    "\n",
    "# # Decision Tree\n",
    "# dct = DecisionTreeClassifier(random_state=42)\n",
    "# dct_metrics = train_model(\n",
    "#     x_train=x_train.iloc[:training_size], \n",
    "#     y_train=y_train.iloc[:training_size], \n",
    "#     x_test=x_test, \n",
    "#     y_test=y_test, \n",
    "#     model=dct, \n",
    "#     metric_dimensions=[\"sex\", \"race\", \"insurance_type\"],\n",
    "#     n_components=n_components \n",
    "# )\n",
    "\n",
    "# Plotting\n",
    "for metric in ['Accuracy', 'F1 Score', 'Recall', 'Precision','AUC']:\n",
    "    #plot_metrics(rcf_metrics, metric, \"RandomForest_with_PCA\" , str(training_size))\n",
    "    #plot_metrics(nb_metrics, metric, \"NaiveBayes\", str(training_size))\n",
    "    plot_metrics(xgb_metrics, metric, \"GradientBoosting_with_PCA\" , str(training_size))\n",
    "    # plot_metrics(dct_metrics, metric, \"DecisionTree_with_PCA\", str(training_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "diseases = ['Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity', 'Lung Lesion', 'Edema', \n",
    "            'Consolidation', 'Pneumonia', 'Atelectasis', 'Pneumothorax', \n",
    "            'Pleural Effusion', 'Pleural Other', 'Fracture']\n",
    "\n",
    "def train_model(x_train, y_train, x_test, y_test, model, metric_dimensions=[], columns_to_drop=[], n_components=None):\n",
    "    multi_output_model = MultiOutputClassifier(model)\n",
    "    x_test = x_test.reset_index(drop=True)\n",
    "    y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "    x_train_subset = x_train.drop(columns=columns_to_drop, errors='ignore')\n",
    "    x_test_subset = x_test.drop(columns=columns_to_drop, errors='ignore')\n",
    "    \n",
    "    # Apply PCA if specified\n",
    "    if n_components:\n",
    "        pca = PCA(n_components=n_components)\n",
    "        x_train_subset = pca.fit_transform(x_train_subset)\n",
    "        x_test_subset = pca.transform(x_test_subset)\n",
    "        print(f\"PCA used with {n_components} components.\")\n",
    "    else:\n",
    "        print(\"PCA not used.\")\n",
    "\n",
    "    # Prepare to store all metrics\n",
    "    metrics_data = {\n",
    "        'Metric Dimension': [],\n",
    "        'Subgroup': [],\n",
    "        'Disease': [],\n",
    "        'Accuracy': [],\n",
    "        'F1 Score': [],\n",
    "        'Recall': [],\n",
    "        'Precision': [],\n",
    "        'AUC': []  # Adding AUC field\n",
    "    }\n",
    "\n",
    "    # Dictionary to store AUC values per disease for each subgroup (to calculate Delta AUC)\n",
    "    auc_values_per_disease = defaultdict(dict)\n",
    "\n",
    "    def calculate_metrics(y_true, y_pred, y_pred_proba=None, disease_label=\"Overall\"):\n",
    "        \"\"\" Helper function to calculate metrics and add them to metrics_data \"\"\"\n",
    "        metrics_data['Metric Dimension'].append(metric_dim)\n",
    "        metrics_data['Subgroup'].append(subgroup)\n",
    "        metrics_data['Disease'].append(disease_label)\n",
    "        metrics_data['Accuracy'].append(accuracy_score(y_true, y_pred))\n",
    "        metrics_data['F1 Score'].append(f1_score(y_true, y_pred, average='micro'))\n",
    "        metrics_data['Recall'].append(recall_score(y_true, y_pred, average='micro'))\n",
    "        metrics_data['Precision'].append(precision_score(y_true, y_pred, average='micro'))\n",
    "\n",
    "        # Calculate AUC if probabilities are provided\n",
    "        if y_pred_proba is not None:\n",
    "            try:\n",
    "                auc = roc_auc_score(y_true, y_pred_proba)\n",
    "                metrics_data['AUC'].append(auc)\n",
    "                if metric_dim != \"all\":  # Only store for subgroups, not for \"overall\"\n",
    "                    auc_values_per_disease[disease_label][subgroup] = auc\n",
    "            except ValueError:  \n",
    "                metrics_data['AUC'].append(None)\n",
    "        else:\n",
    "            metrics_data['AUC'].append(None)\n",
    "\n",
    "    try:\n",
    "        multi_output_model.fit(x_train_subset, y_train)\n",
    "        y_test_preds = pd.DataFrame(multi_output_model.predict(x_test_subset), columns=diseases)\n",
    "        \n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_test_preds_proba = pd.DataFrame({disease: probs[:, 1] for disease, probs in zip(diseases, multi_output_model.predict_proba(x_test_subset))})\n",
    "        else:\n",
    "            y_test_preds_proba = None\n",
    "\n",
    "        metric_dim, subgroup = \"all\", \"all\"\n",
    "        calculate_metrics(y_test, y_test_preds, y_test_preds_proba)\n",
    "        \n",
    "        for disease in diseases:\n",
    "            y_true_disease = y_test[disease]\n",
    "            y_pred_disease = y_test_preds[disease]\n",
    "            y_pred_proba_disease = y_test_preds_proba[disease] if y_test_preds_proba is not None else None\n",
    "            calculate_metrics(y_true_disease, y_pred_disease, y_pred_proba_disease, disease_label=disease)\n",
    "    except ValueError:\n",
    "        print(\"Multi-output not supported. Training each disease separately.\")\n",
    "        for disease in diseases:\n",
    "            model.fit(x_train_subset, y_train[disease])\n",
    "            y_test_preds = model.predict(x_test_subset)\n",
    "            y_test_preds_proba = model.predict_proba(x_test_subset)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "            metric_dim, subgroup = \"all\", \"all\"\n",
    "            calculate_metrics(y_test[disease], y_test_preds, y_test_preds_proba, disease_label=disease)\n",
    "\n",
    "    # Calculate metrics for each dimension in `metric_dimensions`\n",
    "    for metric_dim in metric_dimensions:\n",
    "        for subgroup in x_test[metric_dim].unique():\n",
    "            mask = (x_test[metric_dim] == subgroup)\n",
    "            x_test_subgroup = x_test_subset[mask]\n",
    "            y_test_subgroup = y_test.loc[mask]\n",
    "            try:\n",
    "                y_test_preds_subgroup = y_test_preds.loc[mask]\n",
    "                y_test_preds_proba_subgroup = y_test_preds_proba.loc[mask] if y_test_preds_proba is not None else None\n",
    "                calculate_metrics(y_test_subgroup, y_test_preds_subgroup, y_test_preds_proba_subgroup)\n",
    "                for disease in diseases:\n",
    "                    y_true_subgroup_disease = y_test_subgroup[disease]\n",
    "                    y_pred_subgroup_disease = y_test_preds_subgroup[disease]\n",
    "                    y_pred_proba_subgroup_disease = y_test_preds_proba_subgroup[disease] if y_test_preds_proba_subgroup is not None else None\n",
    "                    calculate_metrics(y_true_subgroup_disease, y_pred_subgroup_disease, y_pred_proba_subgroup_disease, disease_label=disease)\n",
    "            except Exception:\n",
    "                for disease in diseases:\n",
    "                    y_test_subgroup_disease = y_test_subgroup[disease]\n",
    "                    y_test_preds_disease = model.predict(x_test_subgroup)\n",
    "                    y_test_preds_proba_disease = model.predict_proba(x_test_subgroup)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "                    calculate_metrics(y_test_subgroup_disease, y_test_preds_disease, y_test_preds_proba_disease, disease_label=disease)\n",
    "\n",
    "    # Calculate Delta AUC for each disease\n",
    "    delta_auc_values = {}\n",
    "    for disease, auc_dict in auc_values_per_disease.items():\n",
    "        if len(auc_dict) > 1:  # Ensure there are multiple subgroups to compare\n",
    "            delta_auc = max(auc_dict.values()) - min(auc_dict.values())\n",
    "            delta_auc_values[disease] = delta_auc\n",
    "        else:\n",
    "            delta_auc_values[disease] = None  # Not applicable if only one subgroup\n",
    "\n",
    "    # Print Delta AUC for each disease\n",
    "    for disease, delta_auc in delta_auc_values.items():\n",
    "        print(f\"Delta AUC for {disease}: {delta_auc}\")\n",
    "\n",
    "    # Convert metrics_data to DataFrame and return\n",
    "    metrics_df = pd.DataFrame(metrics_data)\n",
    "    metrics_df = metrics_df.reset_index(drop=True)\n",
    "    print(metrics_df.columns) \n",
    "    return metrics_df\n",
    "\n",
    "training_size = 2000\n",
    "use_pca = True        \n",
    "n_components = 10     \n",
    "\n",
    "# rcf = RandomForestClassifier(n_estimators=30, random_state=42)\n",
    "# rcf_metrics = train_model(\n",
    "#     x_train=x_train.iloc[:training_size], \n",
    "#     y_train=y_train.iloc[:training_size], \n",
    "#     x_test=x_test, \n",
    "#     y_test=y_test, \n",
    "#     model=rcf, \n",
    "#     metric_dimensions=[\"sex\", \"race\", \"insurance_type\"],\n",
    "#     n_components=n_components   \n",
    "# )\n",
    "\n",
    "# # Naive Bayes\n",
    "# naive_bayes = MultinomialNB()\n",
    "# nb_metrics = train_model(\n",
    "#     x_train=x_train.iloc[:training_size], \n",
    "#     y_train=y_train.iloc[:training_size], \n",
    "#     x_test=x_test, \n",
    "#     y_test=y_test, \n",
    "#     model=naive_bayes, \n",
    "#     metric_dimensions=[\"sex\", \"race\", \"insurance_type\"],\n",
    "#     n_components=None  \n",
    "# )\n",
    "\n",
    "# Gradient Boosting\n",
    "xgb = GradientBoostingClassifier(learning_rate=0.1, n_estimators=30, verbose=1, random_state=42, n_iter_no_change=5)\n",
    "xgb_metrics = train_model(\n",
    "    x_train=x_train.iloc[:training_size], \n",
    "    y_train=y_train.iloc[:training_size], \n",
    "    x_test=x_test, \n",
    "    y_test=y_test, \n",
    "    model=xgb, \n",
    "    metric_dimensions=[\"sex\", \"race\", \"insurance_type\"],\n",
    "    n_components=n_components   \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the disease accoring to a threashold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "diseases = ['Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity', 'Lung Lesion', 'Edema', \n",
    "            'Consolidation', 'Pneumonia', 'Atelectasis', 'Pneumothorax', \n",
    "            'Pleural Effusion', 'Pleural Other', 'Fracture']\n",
    "\n",
    "def train_model(x_train, y_train, x_test, y_test, model, metric_dimensions=[], columns_to_drop=[], n_components=None):\n",
    "    multi_output_model = MultiOutputClassifier(model)\n",
    "    x_test = x_test.reset_index(drop=True)\n",
    "    y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "    x_train_subset = x_train.drop(columns=columns_to_drop, errors='ignore')\n",
    "    x_test_subset = x_test.drop(columns=columns_to_drop, errors='ignore')\n",
    "    \n",
    "    if n_components:\n",
    "        pca = PCA(n_components=n_components)\n",
    "        x_train_subset = pca.fit_transform(x_train_subset)\n",
    "        x_test_subset = pca.transform(x_test_subset)\n",
    "        print(f\"PCA used with {n_components} components.\")\n",
    "    else:\n",
    "        print(\"PCA not used.\")\n",
    "\n",
    "    metrics_data = {\n",
    "        'Metric Dimension': [],\n",
    "        'Subgroup': [],\n",
    "        'Disease': [],\n",
    "        'Accuracy': [],\n",
    "        'F1 Score': [],\n",
    "        'Recall': [],\n",
    "        'Precision': [],\n",
    "        'AUC': []\n",
    "    }\n",
    "\n",
    "    # Dictionary to store AUC values for calculating Delta AUC\n",
    "    auc_values_per_disease = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "    def calculate_metrics(y_true, y_pred, y_pred_proba=None, disease_label=\"Overall\"):\n",
    "        metrics_data['Metric Dimension'].append(metric_dim)\n",
    "        metrics_data['Subgroup'].append(subgroup)\n",
    "        metrics_data['Disease'].append(disease_label)\n",
    "        metrics_data['Accuracy'].append(accuracy_score(y_true, y_pred))\n",
    "        metrics_data['F1 Score'].append(f1_score(y_true, y_pred, average='micro'))\n",
    "        metrics_data['Recall'].append(recall_score(y_true, y_pred, average='micro'))\n",
    "        metrics_data['Precision'].append(precision_score(y_true, y_pred, average='micro'))\n",
    "\n",
    "        if y_pred_proba is not None:\n",
    "            try:\n",
    "                auc = roc_auc_score(y_true, y_pred_proba)\n",
    "                metrics_data['AUC'].append(auc)\n",
    "                if metric_dim != \"all\":  # Only store for subgroups, not for \"overall\"\n",
    "                    auc_values_per_disease[disease_label][metric_dim][subgroup] = auc\n",
    "            except ValueError:\n",
    "                metrics_data['AUC'].append(None)\n",
    "        else:\n",
    "            metrics_data['AUC'].append(None)\n",
    "\n",
    "    try:\n",
    "        multi_output_model.fit(x_train_subset, y_train)\n",
    "        y_test_preds = pd.DataFrame(multi_output_model.predict(x_test_subset), columns=diseases)\n",
    "        \n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_test_preds_proba = pd.DataFrame({disease: probs[:, 1] for disease, probs in zip(diseases, multi_output_model.predict_proba(x_test_subset))})\n",
    "        else:\n",
    "            y_test_preds_proba = None\n",
    "\n",
    "        metric_dim, subgroup = \"all\", \"all\"\n",
    "        calculate_metrics(y_test, y_test_preds, y_test_preds_proba)\n",
    "        \n",
    "        for disease in diseases:\n",
    "            y_true_disease = y_test[disease]\n",
    "            y_pred_disease = y_test_preds[disease]\n",
    "            y_pred_proba_disease = y_test_preds_proba[disease] if y_test_preds_proba is not None else None\n",
    "            calculate_metrics(y_true_disease, y_pred_disease, y_pred_proba_disease, disease_label=disease)\n",
    "    except ValueError:\n",
    "        print(\"Multi-output not supported. Training each disease separately.\")\n",
    "        for disease in diseases:\n",
    "            model.fit(x_train_subset, y_train[disease])\n",
    "            y_test_preds = model.predict(x_test_subset)\n",
    "            y_test_preds_proba = model.predict_proba(x_test_subset)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "            metric_dim, subgroup = \"all\", \"all\"\n",
    "            calculate_metrics(y_test[disease], y_test_preds, y_test_preds_proba, disease_label=disease)\n",
    "\n",
    "    for metric_dim in metric_dimensions:\n",
    "        for subgroup in x_test[metric_dim].unique():\n",
    "            mask = (x_test[metric_dim] == subgroup)\n",
    "            x_test_subgroup = x_test_subset[mask]\n",
    "            y_test_subgroup = y_test.loc[mask]\n",
    "            try:\n",
    "                y_test_preds_subgroup = y_test_preds.loc[mask]\n",
    "                y_test_preds_proba_subgroup = y_test_preds_proba.loc[mask] if y_test_preds_proba is not None else None\n",
    "                calculate_metrics(y_test_subgroup, y_test_preds_subgroup, y_test_preds_proba_subgroup)\n",
    "                for disease in diseases:\n",
    "                    y_true_subgroup_disease = y_test_subgroup[disease]\n",
    "                    y_pred_subgroup_disease = y_test_preds_subgroup[disease]\n",
    "                    y_pred_proba_subgroup_disease = y_test_preds_proba_subgroup[disease] if y_test_preds_proba_subgroup is not None else None\n",
    "                    calculate_metrics(y_true_subgroup_disease, y_pred_subgroup_disease, y_pred_proba_subgroup_disease, disease_label=disease)\n",
    "            except Exception:\n",
    "                for disease in diseases:\n",
    "                    y_test_subgroup_disease = y_test_subgroup[disease]\n",
    "                    y_test_preds_disease = model.predict(x_test_subgroup)\n",
    "                    y_test_preds_proba_disease = model.predict_proba(x_test_subgroup)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "                    calculate_metrics(y_test_subgroup_disease, y_test_preds_disease, y_test_preds_proba_disease, disease_label=disease)\n",
    "\n",
    "    delta_auc_table = {'Disease': [], 'Metric Dimension': [], 'Delta AUC': []}\n",
    "    max_delta_auc = 0\n",
    "\n",
    "    for disease, dim_dict in auc_values_per_disease.items():\n",
    "        for dimension, subgroups in dim_dict.items():\n",
    "            if len(subgroups) > 1:  # Only calculate delta if multiple subgroups\n",
    "                delta_auc = max(subgroups.values()) - min(subgroups.values())\n",
    "                delta_auc_table['Disease'].append(disease)\n",
    "                delta_auc_table['Metric Dimension'].append(dimension)\n",
    "                delta_auc_table['Delta AUC'].append(delta_auc)\n",
    "                if delta_auc > max_delta_auc:\n",
    "                    max_delta_auc = delta_auc\n",
    "\n",
    "    print(f\"Maximum Delta AUC: {max_delta_auc}\")\n",
    "\n",
    "    delta_auc_df = pd.DataFrame(delta_auc_table)\n",
    "    print(delta_auc_df)\n",
    "\n",
    "    # Convert metrics_data to DataFrame and return\n",
    "    metrics_df = pd.DataFrame(metrics_data)\n",
    "    metrics_df = metrics_df.reset_index(drop=True)\n",
    "    return metrics_df, delta_auc_df\n",
    "\n",
    "training_size = 2000\n",
    "use_pca = True        \n",
    "n_components = 10     \n",
    "\n",
    "# rcf = RandomForestClassifier(n_estimators=30, random_state=42)\n",
    "# rcf_metrics = train_model(\n",
    "#     x_train=x_train.iloc[:training_size], \n",
    "#     y_train=y_train.iloc[:training_size], \n",
    "#     x_test=x_test, \n",
    "#     y_test=y_test, \n",
    "#     model=rcf, \n",
    "#     metric_dimensions=[\"sex\", \"race\", \"insurance_type\"],\n",
    "#     n_components=n_components   \n",
    "# )\n",
    "\n",
    "# # Naive Bayes\n",
    "# naive_bayes = MultinomialNB()\n",
    "# nb_metrics = train_model(\n",
    "#     x_train=x_train.iloc[:training_size], \n",
    "#     y_train=y_train.iloc[:training_size], \n",
    "#     x_test=x_test, \n",
    "#     y_test=y_test, \n",
    "#     model=naive_bayes, \n",
    "#     metric_dimensions=[\"sex\", \"race\", \"insurance_type\"],\n",
    "#     n_components=None  \n",
    "# )\n",
    "\n",
    "# Gradient Boosting\n",
    "xgb = GradientBoostingClassifier(learning_rate=0.1, n_estimators=30, verbose=1, random_state=42, n_iter_no_change=5)\n",
    "xgb_metrics = train_model(\n",
    "    x_train=x_train.iloc[:training_size], \n",
    "    y_train=y_train.iloc[:training_size], \n",
    "    x_test=x_test, \n",
    "    y_test=y_test, \n",
    "    model=xgb, \n",
    "    metric_dimensions=[\"sex\", \"race\", \"insurance_type\"],\n",
    "    n_components=n_components   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_delta_auc(auc_values_per_disease):\n",
    "    \"\"\"Berechnet Delta AUC für jede Krankheit und jede Metric Dimension\"\"\"\n",
    "    delta_auc_table = {'Disease': [], 'Metric Dimension': [], 'Delta AUC': []}\n",
    "    max_delta_auc = 0\n",
    "\n",
    "    for disease, dim_dict in auc_values_per_disease.items():\n",
    "        for dimension, subgroups in dim_dict.items():\n",
    "            if len(subgroups) > 1:  # Berechne Delta nur, wenn mehrere Subgruppen vorhanden sind\n",
    "                delta_auc = max(subgroups.values()) - min(subgroups.values())\n",
    "                delta_auc_table['Disease'].append(disease)\n",
    "                delta_auc_table['Metric Dimension'].append(dimension)\n",
    "                delta_auc_table['Delta AUC'].append(delta_auc)\n",
    "                if delta_auc > max_delta_auc:\n",
    "                    max_delta_auc = delta_auc\n",
    "\n",
    "    print(f\"Maximum Delta AUC: {max_delta_auc}\")\n",
    "    delta_auc_df = pd.DataFrame(delta_auc_table)\n",
    "    return delta_auc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x_train, y_train, x_test, y_test, model, metric_dimensions=[], columns_to_drop=[], n_components=None):\n",
    "    multi_output_model = MultiOutputClassifier(model)\n",
    "    x_test = x_test.reset_index(drop=True)\n",
    "    y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "    x_train_subset = x_train.drop(columns=columns_to_drop, errors='ignore')\n",
    "    x_test_subset = x_test.drop(columns=columns_to_drop, errors='ignore')\n",
    "    \n",
    "    if n_components:\n",
    "        pca = PCA(n_components=n_components)\n",
    "        x_train_subset = pca.fit_transform(x_train_subset)\n",
    "        x_test_subset = pca.transform(x_test_subset)\n",
    "        print(f\"PCA used with {n_components} components.\")\n",
    "    else:\n",
    "        print(\"PCA not used.\")\n",
    "\n",
    "    metrics_data = {\n",
    "        'Metric Dimension': [],\n",
    "        'Subgroup': [],\n",
    "        'Disease': [],\n",
    "        'Accuracy': [],\n",
    "        'F1 Score': [],\n",
    "        'Recall': [],\n",
    "        'Precision': [],\n",
    "        'AUC': []\n",
    "    }\n",
    "\n",
    "    # Dictionary to store AUC values for calculating Delta AUC\n",
    "    auc_values_per_disease = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "    def calculate_metrics(y_true, y_pred, y_pred_proba=None, disease_label=\"Overall\"):\n",
    "        metrics_data['Metric Dimension'].append(metric_dim)\n",
    "        metrics_data['Subgroup'].append(subgroup)\n",
    "        metrics_data['Disease'].append(disease_label)\n",
    "        metrics_data['Accuracy'].append(accuracy_score(y_true, y_pred))\n",
    "        metrics_data['F1 Score'].append(f1_score(y_true, y_pred, average='micro'))\n",
    "        metrics_data['Recall'].append(recall_score(y_true, y_pred, average='micro'))\n",
    "        metrics_data['Precision'].append(precision_score(y_true, y_pred, average='micro'))\n",
    "\n",
    "        if y_pred_proba is not None:\n",
    "            try:\n",
    "                auc = roc_auc_score(y_true, y_pred_proba)\n",
    "                metrics_data['AUC'].append(auc)\n",
    "                if metric_dim != \"all\":  # Nur für Subgruppen speichern, nicht für \"overall\"\n",
    "                    auc_values_per_disease[disease_label][metric_dim][subgroup] = auc\n",
    "            except ValueError:\n",
    "                metrics_data['AUC'].append(None)\n",
    "        else:\n",
    "            metrics_data['AUC'].append(None)\n",
    "\n",
    "    try:\n",
    "        multi_output_model.fit(x_train_subset, y_train)\n",
    "        y_test_preds = pd.DataFrame(multi_output_model.predict(x_test_subset), columns=diseases)\n",
    "        \n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_test_preds_proba = pd.DataFrame({disease: probs[:, 1] for disease, probs in zip(diseases, multi_output_model.predict_proba(x_test_subset))})\n",
    "        else:\n",
    "            y_test_preds_proba = None\n",
    "\n",
    "        metric_dim, subgroup = \"all\", \"all\"\n",
    "        calculate_metrics(y_test, y_test_preds, y_test_preds_proba)\n",
    "        \n",
    "        for disease in diseases:\n",
    "            y_true_disease = y_test[disease]\n",
    "            y_pred_disease = y_test_preds[disease]\n",
    "            y_pred_proba_disease = y_test_preds_proba[disease] if y_test_preds_proba is not None else None\n",
    "            calculate_metrics(y_true_disease, y_pred_disease, y_pred_proba_disease, disease_label=disease)\n",
    "    except ValueError:\n",
    "        print(\"Multi-output not supported. Training each disease separately.\")\n",
    "        for disease in diseases:\n",
    "            model.fit(x_train_subset, y_train[disease])\n",
    "            y_test_preds = model.predict(x_test_subset)\n",
    "            y_test_preds_proba = model.predict_proba(x_test_subset)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "            metric_dim, subgroup = \"all\", \"all\"\n",
    "            calculate_metrics(y_test[disease], y_test_preds, y_test_preds_proba, disease_label=disease)\n",
    "\n",
    "    for metric_dim in metric_dimensions:\n",
    "        for subgroup in x_test[metric_dim].unique():\n",
    "            mask = (x_test[metric_dim] == subgroup)\n",
    "            x_test_subgroup = x_test_subset[mask]\n",
    "            y_test_subgroup = y_test.loc[mask]\n",
    "            try:\n",
    "                y_test_preds_subgroup = y_test_preds.loc[mask]\n",
    "                y_test_preds_proba_subgroup = y_test_preds_proba.loc[mask] if y_test_preds_proba is not None else None\n",
    "                calculate_metrics(y_test_subgroup, y_test_preds_subgroup, y_test_preds_proba_subgroup)\n",
    "                for disease in diseases:\n",
    "                    y_true_subgroup_disease = y_test_subgroup[disease]\n",
    "                    y_pred_subgroup_disease = y_test_preds_subgroup[disease]\n",
    "                    y_pred_proba_subgroup_disease = y_test_preds_proba_subgroup[disease] if y_test_preds_proba_subgroup is not None else None\n",
    "                    calculate_metrics(y_true_subgroup_disease, y_pred_subgroup_disease, y_pred_proba_subgroup_disease, disease_label=disease)\n",
    "            except Exception:\n",
    "                for disease in diseases:\n",
    "                    y_test_subgroup_disease = y_test_subgroup[disease]\n",
    "                    y_test_preds_disease = model.predict(x_test_subgroup)\n",
    "                    y_test_preds_proba_disease = model.predict_proba(x_test_subgroup)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "                    calculate_metrics(y_test_subgroup_disease, y_test_preds_disease, y_test_preds_proba_disease, disease_label=disease)\n",
    "\n",
    "    # Rufe die neue Delta AUC-Funktion auf und gib das Ergebnis als Tabelle zurück\n",
    "    delta_auc_df = calculate_delta_auc(auc_values_per_disease)\n",
    "    print(delta_auc_df)\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics_data)\n",
    "    metrics_df = metrics_df.reset_index(drop=True)\n",
    "    return metrics_df, delta_auc_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_size = 2000\n",
    "use_pca = True        \n",
    "n_components = 10     \n",
    "\n",
    "xgb = GradientBoostingClassifier(learning_rate=0.1, n_estimators=30, verbose=1, random_state=42, n_iter_no_change=5)\n",
    "xgb_metrics = train_model(\n",
    "    x_train=x_train.iloc[:training_size], \n",
    "    y_train=y_train.iloc[:training_size], \n",
    "    x_test=x_test, \n",
    "    y_test=y_test, \n",
    "    model=xgb, \n",
    "    metric_dimensions=[\"sex\", \"race\", \"insurance_type\"],\n",
    "    n_components=n_components   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_auc_df = calculate_delta_auc(auc_values_per_disease)\n",
    "print(delta_auc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Liste der Krankheiten\n",
    "diseases = ['Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity', 'Lung Lesion', 'Edema', \n",
    "            'Consolidation', 'Pneumonia', 'Atelectasis', 'Pneumothorax', \n",
    "            'Pleural Effusion', 'Pleural Other', 'Fracture']\n",
    "\n",
    "# Delta AUC Berechnungsfunktion\n",
    "def calculate_delta_auc(auc_values_per_disease):\n",
    "    \"\"\"Berechnet Delta AUC für jede Krankheit und jede Metric Dimension\"\"\"\n",
    "    delta_auc_table = {'Disease': [], 'Metric Dimension': [], 'Delta AUC': []}\n",
    "    max_delta_auc = 0\n",
    "\n",
    "    for disease, dim_dict in auc_values_per_disease.items():\n",
    "        for dimension, subgroups in dim_dict.items():\n",
    "            if len(subgroups) > 1:  # Berechne Delta nur, wenn mehrere Subgruppen vorhanden sind\n",
    "                delta_auc = max(subgroups.values()) - min(subgroups.values())\n",
    "                delta_auc_table['Disease'].append(disease)\n",
    "                delta_auc_table['Metric Dimension'].append(dimension)\n",
    "                delta_auc_table['Delta AUC'].append(delta_auc)\n",
    "                if delta_auc > max_delta_auc:\n",
    "                    max_delta_auc = delta_auc\n",
    "\n",
    "    print(f\"Maximum Delta AUC: {max_delta_auc}\")\n",
    "    delta_auc_df = pd.DataFrame(delta_auc_table)\n",
    "    return delta_auc_df\n",
    "\n",
    "# Training und Metriken-Funktion\n",
    "def train_model(x_train, y_train, x_test, y_test, model, metric_dimensions=[], columns_to_drop=[], n_components=None):\n",
    "    multi_output_model = MultiOutputClassifier(model)\n",
    "    x_test = x_test.reset_index(drop=True)\n",
    "    y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "    x_train_subset = x_train.drop(columns=columns_to_drop, errors='ignore')\n",
    "    x_test_subset = x_test.drop(columns=columns_to_drop, errors='ignore')\n",
    "    \n",
    "    if n_components:\n",
    "        pca = PCA(n_components=n_components)\n",
    "        x_train_subset = pca.fit_transform(x_train_subset)\n",
    "        x_test_subset = pca.transform(x_test_subset)\n",
    "        print(f\"PCA used with {n_components} components.\")\n",
    "    else:\n",
    "        print(\"PCA not used.\")\n",
    "\n",
    "    metrics_data = {\n",
    "        'Metric Dimension': [],\n",
    "        'Subgroup': [],\n",
    "        'Disease': [],\n",
    "        'Accuracy': [],\n",
    "        'F1 Score': [],\n",
    "        'Recall': [],\n",
    "        'Precision': [],\n",
    "        'AUC': []\n",
    "    }\n",
    "\n",
    "    # Dictionary to store AUC values for calculating Delta AUC\n",
    "    auc_values_per_disease = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "    def calculate_metrics(y_true, y_pred, y_pred_proba=None, disease_label=\"Overall\"):\n",
    "        metrics_data['Metric Dimension'].append(metric_dim)\n",
    "        metrics_data['Subgroup'].append(subgroup)\n",
    "        metrics_data['Disease'].append(disease_label)\n",
    "        metrics_data['Accuracy'].append(accuracy_score(y_true, y_pred))\n",
    "        metrics_data['F1 Score'].append(f1_score(y_true, y_pred, average='micro'))\n",
    "        metrics_data['Recall'].append(recall_score(y_true, y_pred, average='micro'))\n",
    "        metrics_data['Precision'].append(precision_score(y_true, y_pred, average='micro'))\n",
    "\n",
    "        if y_pred_proba is not None:\n",
    "            try:\n",
    "                auc = roc_auc_score(y_true, y_pred_proba)\n",
    "                metrics_data['AUC'].append(auc)\n",
    "                if metric_dim != \"all\":  # Nur für Subgruppen speichern, nicht für \"overall\"\n",
    "                    auc_values_per_disease[disease_label][metric_dim][subgroup] = auc\n",
    "            except ValueError:\n",
    "                metrics_data['AUC'].append(None)\n",
    "        else:\n",
    "            metrics_data['AUC'].append(None)\n",
    "\n",
    "    try:\n",
    "        multi_output_model.fit(x_train_subset, y_train)\n",
    "        y_test_preds = pd.DataFrame(multi_output_model.predict(x_test_subset), columns=diseases)\n",
    "        \n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_test_preds_proba = pd.DataFrame({disease: probs[:, 1] for disease, probs in zip(diseases, multi_output_model.predict_proba(x_test_subset))})\n",
    "        else:\n",
    "            y_test_preds_proba = None\n",
    "\n",
    "        metric_dim, subgroup = \"all\", \"all\"\n",
    "        calculate_metrics(y_test, y_test_preds, y_test_preds_proba)\n",
    "        \n",
    "        for disease in diseases:\n",
    "            y_true_disease = y_test[disease]\n",
    "            y_pred_disease = y_test_preds[disease]\n",
    "            y_pred_proba_disease = y_test_preds_proba[disease] if y_test_preds_proba is not None else None\n",
    "            calculate_metrics(y_true_disease, y_pred_disease, y_pred_proba_disease, disease_label=disease)\n",
    "    except ValueError:\n",
    "        print(\"Multi-output not supported. Training each disease separately.\")\n",
    "        for disease in diseases:\n",
    "            model.fit(x_train_subset, y_train[disease])\n",
    "            y_test_preds = model.predict(x_test_subset)\n",
    "            y_test_preds_proba = model.predict_proba(x_test_subset)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "            metric_dim, subgroup = \"all\", \"all\"\n",
    "            calculate_metrics(y_test[disease], y_test_preds, y_test_preds_proba, disease_label=disease)\n",
    "\n",
    "    for metric_dim in metric_dimensions:\n",
    "        for subgroup in x_test[metric_dim].unique():\n",
    "            mask = (x_test[metric_dim] == subgroup)\n",
    "            x_test_subgroup = x_test_subset[mask]\n",
    "            y_test_subgroup = y_test.loc[mask]\n",
    "            try:\n",
    "                y_test_preds_subgroup = y_test_preds.loc[mask]\n",
    "                y_test_preds_proba_subgroup = y_test_preds_proba.loc[mask] if y_test_preds_proba is not None else None\n",
    "                calculate_metrics(y_test_subgroup, y_test_preds_subgroup, y_test_preds_proba_subgroup)\n",
    "                for disease in diseases:\n",
    "                    y_true_subgroup_disease = y_test_subgroup[disease]\n",
    "                    y_pred_subgroup_disease = y_test_preds_subgroup[disease]\n",
    "                    y_pred_proba_subgroup_disease = y_test_preds_proba_subgroup[disease] if y_test_preds_proba_subgroup is not None else None\n",
    "                    calculate_metrics(y_true_subgroup_disease, y_pred_subgroup_disease, y_pred_proba_subgroup_disease, disease_label=disease)\n",
    "            except Exception:\n",
    "                for disease in diseases:\n",
    "                    y_test_subgroup_disease = y_test_subgroup[disease]\n",
    "                    y_test_preds_disease = model.predict(x_test_subgroup)\n",
    "                    y_test_preds_proba_disease = model.predict_proba(x_test_subgroup)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "                    calculate_metrics(y_test_subgroup_disease, y_test_preds_disease, y_test_preds_proba_disease, disease_label=disease)\n",
    "\n",
    "    # Rufe die Delta AUC-Berechnungsfunktion auf und erstelle das DataFrame delta_auc_df\n",
    "    delta_auc_df = calculate_delta_auc(auc_values_per_disease)\n",
    "    print(\"Delta AUC Tabelle:\")\n",
    "    print(delta_auc_df)\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics_data)\n",
    "    metrics_df = metrics_df.reset_index(drop=True)\n",
    "    return metrics_df, delta_auc_df\n",
    "\n",
    "# Beispielaufruf der Funktion und Analyse der Ergebnisse\n",
    "training_size = 2000\n",
    "use_pca = True        \n",
    "n_components = 10     \n",
    "\n",
    "xgb = GradientBoostingClassifier(learning_rate=0.1, n_estimators=30, verbose=1, random_state=42, n_iter_no_change=5)\n",
    "\n",
    "# Trainiere das Modell und speichere die Leistungsmetriken und Delta AUC-Werte\n",
    "metrics_df, delta_auc_df = train_model(\n",
    "    x_train=x_train.iloc[:training_size], \n",
    "    y_train=y_train.iloc[:training_size], \n",
    "    x_test=x_test, \n",
    "    y_test=y_test, \n",
    "    model=xgb, \n",
    "    metric_dimensions=[\"sex\", \"race\", \"insurance_type\"],\n",
    "    n_components=n_components   \n",
    ")\n",
    "\n",
    "# Zeige die Leistung für jede Krankheit und Delta AUC an\n",
    "print(\"Leistung für jede Krankheit:\")\n",
    "print(metrics_df[metrics_df['Metric Dimension'] == 'all'][['Disease', 'Accuracy', 'F1 Score', 'Recall', 'Precision', 'AUC']])\n",
    "\n",
    "print(\"\\nDelta AUC für jede Krankheit und Dimension:\")\n",
    "print(delta_auc_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Liste der Krankheiten\n",
    "diseases = ['Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity', 'Lung Lesion', 'Edema', \n",
    "            'Consolidation', 'Pneumonia', 'Atelectasis', 'Pneumothorax', \n",
    "            'Pleural Effusion', 'Pleural Other', 'Fracture']\n",
    "\n",
    "# Delta AUC Berechnungsfunktion\n",
    "def calculate_delta_auc(auc_values_per_disease):\n",
    "    \"\"\"Berechnet Delta AUC für jede Krankheit und jede Metric Dimension\"\"\"\n",
    "    delta_auc_table = {'Disease': [], 'Metric Dimension': [], 'Delta AUC': []}\n",
    "    max_delta_auc = 0\n",
    "\n",
    "    for disease, dim_dict in auc_values_per_disease.items():\n",
    "        for dimension, subgroups in dim_dict.items():\n",
    "            if len(subgroups) > 1:  # Berechne Delta nur, wenn mehrere Subgruppen vorhanden sind\n",
    "                delta_auc = max(subgroups.values()) - min(subgroups.values())\n",
    "                delta_auc_table['Disease'].append(disease)\n",
    "                delta_auc_table['Metric Dimension'].append(dimension)\n",
    "                delta_auc_table['Delta AUC'].append(delta_auc)\n",
    "                if delta_auc > max_delta_auc:\n",
    "                    max_delta_auc = delta_auc\n",
    "\n",
    "    delta_auc_df = pd.DataFrame(delta_auc_table)\n",
    "    return delta_auc_df\n",
    "\n",
    "# Funktion zur Anzeige der Delta AUC-Tabellen für jede metric_dimension\n",
    "def display_delta_auc_tables(delta_auc_df):\n",
    "    \"\"\"Zeigt Delta AUC-Tabellen für jede metric_dimension und gibt den maximalen Delta AUC aus.\"\"\"\n",
    "    \n",
    "    # Teil-DataFrames für jede metric_dimension\n",
    "    sex_delta_auc = delta_auc_df[delta_auc_df['Metric Dimension'] == 'sex']\n",
    "    race_delta_auc = delta_auc_df[delta_auc_df['Metric Dimension'] == 'race']\n",
    "    insurance_delta_auc = delta_auc_df[delta_auc_df['Metric Dimension'] == 'insurance_type']\n",
    "    \n",
    "    # Ausgabe der Tabellen für jede metric_dimension\n",
    "    print(\"\\nDelta AUC Tabelle für 'sex':\")\n",
    "    print(sex_delta_auc.to_string(index=False))  # Entfernt Index-Spalte\n",
    "    \n",
    "    print(\"\\nDelta AUC Tabelle für 'race':\")\n",
    "    print(race_delta_auc.to_string(index=False))\n",
    "    \n",
    "    print(\"\\nDelta AUC Tabelle für 'insurance_type':\")\n",
    "    print(insurance_delta_auc.to_string(index=False))\n",
    "    \n",
    "    # Maximalen Delta AUC-Wert berechnen und ausgeben\n",
    "    max_delta_auc = delta_auc_df['Delta AUC'].max()\n",
    "    print(f\"\\nMaximaler Delta AUC über alle Gruppen hinweg: {max_delta_auc:.3f}\")\n",
    "\n",
    "# Training und Metriken-Funktion\n",
    "def train_model(x_train, y_train, x_test, y_test, model, metric_dimensions=[], columns_to_drop=[], n_components=None):\n",
    "    multi_output_model = MultiOutputClassifier(model)\n",
    "    x_test = x_test.reset_index(drop=True)\n",
    "    y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "    x_train_subset = x_train.drop(columns=columns_to_drop, errors='ignore')\n",
    "    x_test_subset = x_test.drop(columns=columns_to_drop, errors='ignore')\n",
    "    \n",
    "    if n_components:\n",
    "        pca = PCA(n_components=n_components)\n",
    "        x_train_subset = pca.fit_transform(x_train_subset)\n",
    "        x_test_subset = pca.transform(x_test_subset)\n",
    "        print(f\"PCA used with {n_components} components.\")\n",
    "    else:\n",
    "        print(\"PCA not used.\")\n",
    "\n",
    "    metrics_data = {\n",
    "        'Metric Dimension': [],\n",
    "        'Subgroup': [],\n",
    "        'Disease': [],\n",
    "        'Accuracy': [],\n",
    "        'F1 Score': [],\n",
    "        'Recall': [],\n",
    "        'Precision': [],\n",
    "        'AUC': []\n",
    "    }\n",
    "\n",
    "    # Dictionary to store AUC values for calculating Delta AUC\n",
    "    auc_values_per_disease = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "    def calculate_metrics(y_true, y_pred, y_pred_proba=None, disease_label=\"Overall\"):\n",
    "        metrics_data['Metric Dimension'].append(metric_dim)\n",
    "        metrics_data['Subgroup'].append(subgroup)\n",
    "        metrics_data['Disease'].append(disease_label)\n",
    "        metrics_data['Accuracy'].append(accuracy_score(y_true, y_pred))\n",
    "        metrics_data['F1 Score'].append(f1_score(y_true, y_pred, average='micro'))\n",
    "        metrics_data['Recall'].append(recall_score(y_true, y_pred, average='micro'))\n",
    "        metrics_data['Precision'].append(precision_score(y_true, y_pred, average='micro'))\n",
    "\n",
    "        if y_pred_proba is not None:\n",
    "            try:\n",
    "                auc = roc_auc_score(y_true, y_pred_proba)\n",
    "                metrics_data['AUC'].append(auc)\n",
    "                if metric_dim != \"all\":  # Nur für Subgruppen speichern, nicht für \"overall\"\n",
    "                    auc_values_per_disease[disease_label][metric_dim][subgroup] = auc\n",
    "            except ValueError:\n",
    "                metrics_data['AUC'].append(None)\n",
    "        else:\n",
    "            metrics_data['AUC'].append(None)\n",
    "\n",
    "    try:\n",
    "        multi_output_model.fit(x_train_subset, y_train)\n",
    "        y_test_preds = pd.DataFrame(multi_output_model.predict(x_test_subset), columns=diseases)\n",
    "        \n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_test_preds_proba = pd.DataFrame({disease: probs[:, 1] for disease, probs in zip(diseases, multi_output_model.predict_proba(x_test_subset))})\n",
    "        else:\n",
    "            y_test_preds_proba = None\n",
    "\n",
    "        metric_dim, subgroup = \"all\", \"all\"\n",
    "        calculate_metrics(y_test, y_test_preds, y_test_preds_proba)\n",
    "        \n",
    "        for disease in diseases:\n",
    "            y_true_disease = y_test[disease]\n",
    "            y_pred_disease = y_test_preds[disease]\n",
    "            y_pred_proba_disease = y_test_preds_proba[disease] if y_test_preds_proba is not None else None\n",
    "            calculate_metrics(y_true_disease, y_pred_disease, y_pred_proba_disease, disease_label=disease)\n",
    "    except ValueError:\n",
    "        print(\"Multi-output not supported. Training each disease separately.\")\n",
    "        for disease in diseases:\n",
    "            model.fit(x_train_subset, y_train[disease])\n",
    "            y_test_preds = model.predict(x_test_subset)\n",
    "            y_test_preds_proba = model.predict_proba(x_test_subset)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "            metric_dim, subgroup = \"all\", \"all\"\n",
    "            calculate_metrics(y_test[disease], y_test_preds, y_test_preds_proba, disease_label=disease)\n",
    "\n",
    "    for metric_dim in metric_dimensions:\n",
    "        for subgroup in x_test[metric_dim].unique():\n",
    "            mask = (x_test[metric_dim] == subgroup)\n",
    "            x_test_subgroup = x_test_subset[mask]\n",
    "            y_test_subgroup = y_test.loc[mask]\n",
    "            try:\n",
    "                y_test_preds_subgroup = y_test_preds.loc[mask]\n",
    "                y_test_preds_proba_subgroup = y_test_preds_proba.loc[mask] if y_test_preds_proba is not None else None\n",
    "                calculate_metrics(y_test_subgroup, y_test_preds_subgroup, y_test_preds_proba_subgroup)\n",
    "                for disease in diseases:\n",
    "                    y_true_subgroup_disease = y_test_subgroup[disease]\n",
    "                    y_pred_subgroup_disease = y_test_preds_subgroup[disease]\n",
    "                    y_pred_proba_subgroup_disease = y_test_preds_proba_subgroup[disease] if y_test_preds_proba_subgroup is not None else None\n",
    "                    calculate_metrics(y_true_subgroup_disease, y_pred_subgroup_disease, y_pred_proba_subgroup_disease, disease_label=disease)\n",
    "            except Exception:\n",
    "                for disease in diseases:\n",
    "                    y_test_subgroup_disease = y_test_subgroup[disease]\n",
    "                    y_test_preds_disease = model.predict(x_test_subgroup)\n",
    "                    y_test_preds_proba_disease = model.predict_proba(x_test_subgroup)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "                    calculate_metrics(y_test_subgroup_disease, y_test_preds_disease, y_test_preds_proba_disease, disease_label=disease)\n",
    "\n",
    "    # Rufe die Delta AUC-Berechnungsfunktion auf und erstelle das DataFrame delta_auc_df\n",
    "    delta_auc_df = calculate_delta_auc(auc_values_per_disease)\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics_data)\n",
    "    metrics_df = metrics_df.reset_index(drop=True)\n",
    "    return metrics_df, delta_auc_df\n",
    "\n",
    "# Beispielaufruf der Funktion und Analyse der Ergebnisse\n",
    "training_size = 2000\n",
    "use_pca = True        \n",
    "n_components = 10     \n",
    "\n",
    "xgb = GradientBoostingClassifier(learning_rate=0.1, n_estimators=30, verbose=1, random_state=42, n_iter_no_change=5)\n",
    "\n",
    "# Trainiere das Modell und speichere die Leistungsmetriken und Delta AUC-Werte\n",
    "metrics_df, delta_auc_df = train_model(\n",
    "    x_train=x_train.iloc[:training_size], \n",
    "    y_train=y_train.iloc[:training_size], \n",
    "    x_test=x_test, \n",
    "    y_test=y_test, \n",
    "    model=xgb, \n",
    "    metric_dimensions=[\"sex\", \"race\", \"insurance_type\"],\n",
    "    n_components=n_components   \n",
    ")\n",
    "\n",
    "# Zeige die Delta AUC-Tabellen für jede metric_dimension an\n",
    "display_delta_auc_tables(delta_auc_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Liste der Krankheiten\n",
    "diseases = ['Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity', 'Lung Lesion', 'Edema', \n",
    "            'Consolidation', 'Pneumonia', 'Atelectasis', 'Pneumothorax', \n",
    "            'Pleural Effusion', 'Pleural Other', 'Fracture']\n",
    "\n",
    "# Delta AUC Berechnungsfunktion\n",
    "def calculate_delta_auc(auc_values_per_disease):\n",
    "    \"\"\"Berechnet Delta AUC für jede Krankheit und jede Metric Dimension und erstellt Tabellen für jede Dimension\"\"\"\n",
    "    sex_table = []\n",
    "    race_table = []\n",
    "    insurance_type_table = []\n",
    "    \n",
    "    for disease, dim_dict in auc_values_per_disease.items():\n",
    "        # Tabelle für 'sex'\n",
    "        if 'sex' in dim_dict:\n",
    "            male_auc = dim_dict['sex'].get('male', None)\n",
    "            female_auc = dim_dict['sex'].get('female', None)\n",
    "            delta_auc_sex = abs(male_auc - female_auc) if male_auc is not None and female_auc is not None else None\n",
    "            sex_table.append([disease, male_auc, female_auc, delta_auc_sex])\n",
    "\n",
    "        # Tabelle für 'race'\n",
    "        if 'race' in dim_dict:\n",
    "            asian_auc = dim_dict['race'].get('asian', None)\n",
    "            white_auc = dim_dict['race'].get('white', None)\n",
    "            black_auc = dim_dict['race'].get('black', None)\n",
    "            delta_auc_race = (max([asian_auc, white_auc, black_auc]) - \n",
    "                              min([auc for auc in [asian_auc, white_auc, black_auc] if auc is not None])) \\\n",
    "                              if None not in [asian_auc, white_auc, black_auc] else None\n",
    "            race_table.append([disease, asian_auc, white_auc, black_auc, delta_auc_race])\n",
    "\n",
    "        # Tabelle für 'insurance_type'\n",
    "        if 'insurance_type' in dim_dict:\n",
    "            private_auc = dim_dict['insurance_type'].get('private', None)\n",
    "            medicaid_auc = dim_dict['insurance_type'].get('medicaid', None)\n",
    "            medicare_auc = dim_dict['insurance_type'].get('medicare', None)\n",
    "            delta_auc_insurance = (max([private_auc, medicaid_auc, medicare_auc]) - \n",
    "                                   min([auc for auc in [private_auc, medicaid_auc, medicare_auc] if auc is not None])) \\\n",
    "                                   if None not in [private_auc, medicaid_auc, medicare_auc] else None\n",
    "            insurance_type_table.append([disease, private_auc, medicaid_auc, medicare_auc, delta_auc_insurance])\n",
    "    \n",
    "    # Erstelle DataFrames für jede Tabelle\n",
    "    sex_df = pd.DataFrame(sex_table, columns=['Disease', 'AUC (Male)', 'AUC (Female)', 'AUC Delta'])\n",
    "    race_df = pd.DataFrame(race_table, columns=['Disease', 'AUC (Asian)', 'AUC (White)', 'AUC (Black)', 'AUC Delta'])\n",
    "    insurance_type_df = pd.DataFrame(insurance_type_table, columns=['Disease', 'AUC (Private)', 'AUC (Medicaid)', 'AUC (Medicare)', 'AUC Delta'])\n",
    "\n",
    "    return sex_df, race_df, insurance_type_df\n",
    "\n",
    "# Training und Metriken-Funktion\n",
    "def train_model(x_train, y_train, x_test, y_test, model, metric_dimensions=[], columns_to_drop=[], n_components=None):\n",
    "    multi_output_model = MultiOutputClassifier(model)\n",
    "    x_test = x_test.reset_index(drop=True)\n",
    "    y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "    x_train_subset = x_train.drop(columns=columns_to_drop, errors='ignore')\n",
    "    x_test_subset = x_test.drop(columns=columns_to_drop, errors='ignore')\n",
    "    \n",
    "    if n_components:\n",
    "        pca = PCA(n_components=n_components)\n",
    "        x_train_subset = pca.fit_transform(x_train_subset)\n",
    "        x_test_subset = pca.transform(x_test_subset)\n",
    "        print(f\"PCA used with {n_components} components.\")\n",
    "    else:\n",
    "        print(\"PCA not used.\")\n",
    "\n",
    "    metrics_data = {\n",
    "        'Metric Dimension': [],\n",
    "        'Subgroup': [],\n",
    "        'Disease': [],\n",
    "        'Accuracy': [],\n",
    "        'F1 Score': [],\n",
    "        'Recall': [],\n",
    "        'Precision': [],\n",
    "        'AUC': []\n",
    "    }\n",
    "\n",
    "    # Dictionary to store AUC values for calculating Delta AUC\n",
    "    auc_values_per_disease = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "    def calculate_metrics(y_true, y_pred, y_pred_proba=None, disease_label=\"Overall\"):\n",
    "        metrics_data['Metric Dimension'].append(metric_dim)\n",
    "        metrics_data['Subgroup'].append(subgroup)\n",
    "        metrics_data['Disease'].append(disease_label)\n",
    "        metrics_data['Accuracy'].append(accuracy_score(y_true, y_pred))\n",
    "        metrics_data['F1 Score'].append(f1_score(y_true, y_pred, average='micro'))\n",
    "        metrics_data['Recall'].append(recall_score(y_true, y_pred, average='micro'))\n",
    "        metrics_data['Precision'].append(precision_score(y_true, y_pred, average='micro'))\n",
    "\n",
    "        if y_pred_proba is not None:\n",
    "            try:\n",
    "                auc = roc_auc_score(y_true, y_pred_proba)\n",
    "                metrics_data['AUC'].append(auc)\n",
    "                if metric_dim != \"all\":  # Nur für Subgruppen speichern, nicht für \"overall\"\n",
    "                    auc_values_per_disease[disease_label][metric_dim][subgroup] = auc\n",
    "            except ValueError:\n",
    "                metrics_data['AUC'].append(None)\n",
    "        else:\n",
    "            metrics_data['AUC'].append(None)\n",
    "\n",
    "    try:\n",
    "        multi_output_model.fit(x_train_subset, y_train)\n",
    "        y_test_preds = pd.DataFrame(multi_output_model.predict(x_test_subset), columns=diseases)\n",
    "        \n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_test_preds_proba = pd.DataFrame({disease: probs[:, 1] for disease, probs in zip(diseases, multi_output_model.predict_proba(x_test_subset))})\n",
    "        else:\n",
    "            y_test_preds_proba = None\n",
    "\n",
    "        metric_dim, subgroup = \"all\", \"all\"\n",
    "        calculate_metrics(y_test, y_test_preds, y_test_preds_proba)\n",
    "        \n",
    "        for disease in diseases:\n",
    "            y_true_disease = y_test[disease]\n",
    "            y_pred_disease = y_test_preds[disease]\n",
    "            y_pred_proba_disease = y_test_preds_proba[disease] if y_test_preds_proba is not None else None\n",
    "            calculate_metrics(y_true_disease, y_pred_disease, y_pred_proba_disease, disease_label=disease)\n",
    "    except ValueError:\n",
    "        print(\"Multi-output not supported. Training each disease separately.\")\n",
    "        for disease in diseases:\n",
    "            model.fit(x_train_subset, y_train[disease])\n",
    "            y_test_preds = model.predict(x_test_subset)\n",
    "            y_test_preds_proba = model.predict_proba(x_test_subset)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "            metric_dim, subgroup = \"all\", \"all\"\n",
    "            calculate_metrics(y_test[disease], y_test_preds, y_test_preds_proba, disease_label=disease)\n",
    "\n",
    "    for metric_dim in metric_dimensions:\n",
    "        for subgroup in x_test[metric_dim].unique():\n",
    "            mask = (x_test[metric_dim] == subgroup)\n",
    "            x_test_subgroup = x_test_subset[mask]\n",
    "            y_test_subgroup = y_test.loc[mask]\n",
    "            try:\n",
    "                y_test_preds_subgroup = y_test_preds.loc[mask]\n",
    "                y_test_preds_proba_subgroup = y_test_preds_proba.loc[mask] if y_test_preds_proba is not None else None\n",
    "                calculate_metrics(y_test_subgroup, y_test_preds_subgroup, y_test_preds_proba_subgroup)\n",
    "                for disease in diseases:\n",
    "                    y_true_subgroup_disease = y_test_subgroup[disease]\n",
    "                    y_pred_subgroup_disease = y_test_preds_subgroup[disease]\n",
    "                    y_pred_proba_subgroup_disease = y_test_preds_proba_subgroup[disease] if y_test_preds_proba_subgroup is not None else None\n",
    "                    calculate_metrics(y_true_subgroup_disease, y_pred_subgroup_disease, y_pred_proba_subgroup_disease, disease_label=disease)\n",
    "            except Exception:\n",
    "                for disease in diseases:\n",
    "                    y_test_subgroup_disease = y_test_subgroup[disease]\n",
    "                    y_test_preds_disease = model.predict(x_test_subgroup)\n",
    "                    y_test_preds_proba_disease = model.predict_proba(x_test_subgroup)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "                    calculate_metrics(y_test_subgroup_disease, y_test_preds_disease, y_test_preds_proba_disease, disease_label=disease)\n",
    "\n",
    "    delta_auc_df = calculate_delta_auc(auc_values_per_disease)\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics_data)\n",
    "    metrics_df = metrics_df.reset_index(drop=True)\n",
    "    return metrics_df, delta_auc_df\n",
    "\n",
    "# Beispielaufruf der Funktion und Analyse der Ergebnisse\n",
    "training_size = 2000\n",
    "use_pca = True        \n",
    "n_components = 10     \n",
    "\n",
    "xgb = GradientBoostingClassifier(learning_rate=0.1, n_estimators=30, verbose=1, random_state=42, n_iter_no_change=5)\n",
    "\n",
    "# Trainiere das Modell und speichere die Leistungsmetriken und Delta AUC-Werte\n",
    "metrics_df, delta_auc_df = train_model(\n",
    "    x_train=x_train.iloc[:training_size], \n",
    "    y_train=y_train.iloc[:training_size], \n",
    "    x_test=x_test, \n",
    "    y_test=y_test, \n",
    "    model=xgb, \n",
    "    metric_dimensions=[\"sex\", \"race\", \"insurance_type\"],\n",
    "    n_components=n_components   \n",
    ")\n",
    "\n",
    "# Zeige die Delta AUC-Tabellen für jede metric_dimension an\n",
    "sex_df, race_df, insurance_type_df = delta_auc_df\n",
    "print(\"\\nDelta AUC Tabelle für 'sex':\")\n",
    "print(sex_df)\n",
    "print(\"\\nDelta AUC Tabelle für 'race':\")\n",
    "print(race_df)\n",
    "print(\"\\nDelta AUC Tabelle für 'insurance_type':\")\n",
    "print(insurance_type_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Liste der Krankheiten\n",
    "diseases = ['Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity', 'Lung Lesion', 'Edema', \n",
    "            'Consolidation', 'Pneumonia', 'Atelectasis', 'Pneumothorax', \n",
    "            'Pleural Effusion', 'Pleural Other', 'Fracture']\n",
    "\n",
    "# Delta AUC Berechnungsfunktion\n",
    "def calculate_delta_auc(auc_values_per_disease):\n",
    "    \"\"\"Berechnet Delta AUC für jede Krankheit und jede Metric Dimension und erstellt Tabellen für jede Dimension\"\"\"\n",
    "    sex_table = []\n",
    "    race_table = []\n",
    "    insurance_type_table = []\n",
    "    \n",
    "    for disease, dim_dict in auc_values_per_disease.items():\n",
    "        # Tabelle für 'sex'\n",
    "        if 'sex' in dim_dict:\n",
    "            male_auc = dim_dict['sex'].get('male', None)\n",
    "            female_auc = dim_dict['sex'].get('female', None)\n",
    "            delta_auc_sex = abs(male_auc - female_auc) if male_auc is not None and female_auc is not None else None\n",
    "            sex_table.append([disease, male_auc, female_auc, delta_auc_sex])\n",
    "\n",
    "        # Tabelle für 'race'\n",
    "        if 'race' in dim_dict:\n",
    "            asian_auc = dim_dict['race'].get('asian', None)\n",
    "            white_auc = dim_dict['race'].get('white', None)\n",
    "            black_auc = dim_dict['race'].get('black', None)\n",
    "            delta_auc_race = (max([asian_auc, white_auc, black_auc]) - \n",
    "                              min([auc for auc in [asian_auc, white_auc, black_auc] if auc is not None])) \\\n",
    "                              if None not in [asian_auc, white_auc, black_auc] else None\n",
    "            race_table.append([disease, asian_auc, white_auc, black_auc, delta_auc_race])\n",
    "\n",
    "        # Tabelle für 'insurance_type'\n",
    "        if 'insurance_type' in dim_dict:\n",
    "            private_auc = dim_dict['insurance_type'].get('private', None)\n",
    "            medicaid_auc = dim_dict['insurance_type'].get('medicaid', None)\n",
    "            medicare_auc = dim_dict['insurance_type'].get('medicare', None)\n",
    "            delta_auc_insurance = (max([private_auc, medicaid_auc, medicare_auc]) - \n",
    "                                   min([auc for auc in [private_auc, medicaid_auc, medicare_auc] if auc is not None])) \\\n",
    "                                   if None not in [private_auc, medicaid_auc, medicare_auc] else None\n",
    "            insurance_type_table.append([disease, private_auc, medicaid_auc, medicare_auc, delta_auc_insurance])\n",
    "    \n",
    "    # Erstelle DataFrames für jede Tabelle\n",
    "    sex_df = pd.DataFrame(sex_table, columns=['Disease', 'AUC (Male)', 'AUC (Female)', 'AUC Delta'])\n",
    "    race_df = pd.DataFrame(race_table, columns=['Disease', 'AUC (Asian)', 'AUC (White)', 'AUC (Black)', 'AUC Delta'])\n",
    "    insurance_type_df = pd.DataFrame(insurance_type_table, columns=['Disease', 'AUC (Private)', 'AUC (Medicaid)', 'AUC (Medicare)', 'AUC Delta'])\n",
    "\n",
    "    return sex_df, race_df, insurance_type_df\n",
    "\n",
    "# Training und Metriken-Funktion\n",
    "def train_model(x_train, y_train, x_test, y_test, model, metric_dimensions=[], columns_to_drop=[], n_components=None):\n",
    "    multi_output_model = MultiOutputClassifier(model)\n",
    "    x_test = x_test.reset_index(drop=True)\n",
    "    y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "    x_train_subset = x_train.drop(columns=columns_to_drop, errors='ignore')\n",
    "    x_test_subset = x_test.drop(columns=columns_to_drop, errors='ignore')\n",
    "    \n",
    "    if n_components:\n",
    "        pca = PCA(n_components=n_components)\n",
    "        x_train_subset = pca.fit_transform(x_train_subset)\n",
    "        x_test_subset = pca.transform(x_test_subset)\n",
    "        print(f\"PCA used with {n_components} components.\")\n",
    "    else:\n",
    "        print(\"PCA not used.\")\n",
    "\n",
    "    metrics_data = {\n",
    "        'Metric Dimension': [],\n",
    "        'Subgroup': [],\n",
    "        'Disease': [],\n",
    "        'Accuracy': [],\n",
    "        'F1 Score': [],\n",
    "        'Recall': [],\n",
    "        'Precision': [],\n",
    "        'AUC': []\n",
    "    }\n",
    "\n",
    "    # Dictionary to store AUC values for calculating Delta AUC\n",
    "    auc_values_per_disease = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "    def calculate_metrics(y_true, y_pred, y_pred_proba=None, disease_label=\"Overall\"):\n",
    "        metrics_data['Metric Dimension'].append(metric_dim)\n",
    "        metrics_data['Subgroup'].append(subgroup)\n",
    "        metrics_data['Disease'].append(disease_label)\n",
    "        metrics_data['Accuracy'].append(accuracy_score(y_true, y_pred))\n",
    "        metrics_data['F1 Score'].append(f1_score(y_true, y_pred, average='micro'))\n",
    "        metrics_data['Recall'].append(recall_score(y_true, y_pred, average='micro'))\n",
    "        metrics_data['Precision'].append(precision_score(y_true, y_pred, average='micro'))\n",
    "\n",
    "        if y_pred_proba is not None:\n",
    "            try:\n",
    "                auc = roc_auc_score(y_true, y_pred_proba)\n",
    "                metrics_data['AUC'].append(auc)\n",
    "                if metric_dim != \"all\":  # Nur für Subgruppen speichern, nicht für \"overall\"\n",
    "                    auc_values_per_disease[disease_label][metric_dim][subgroup] = auc\n",
    "            except ValueError:\n",
    "                metrics_data['AUC'].append(None)\n",
    "        else:\n",
    "            metrics_data['AUC'].append(None)\n",
    "\n",
    "    try:\n",
    "        multi_output_model.fit(x_train_subset, y_train)\n",
    "        y_test_preds = pd.DataFrame(multi_output_model.predict(x_test_subset), columns=diseases)\n",
    "        \n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_test_preds_proba = pd.DataFrame({disease: probs[:, 1] for disease, probs in zip(diseases, multi_output_model.predict_proba(x_test_subset))})\n",
    "        else:\n",
    "            y_test_preds_proba = None\n",
    "\n",
    "        metric_dim, subgroup = \"all\", \"all\"\n",
    "        calculate_metrics(y_test, y_test_preds, y_test_preds_proba)\n",
    "        \n",
    "        for disease in diseases:\n",
    "            y_true_disease = y_test[disease]\n",
    "            y_pred_disease = y_test_preds[disease]\n",
    "            y_pred_proba_disease = y_test_preds_proba[disease] if y_test_preds_proba is not None else None\n",
    "            calculate_metrics(y_true_disease, y_pred_disease, y_pred_proba_disease, disease_label=disease)\n",
    "    except ValueError:\n",
    "        print(\"Multi-output not supported. Training each disease separately.\")\n",
    "        for disease in diseases:\n",
    "            model.fit(x_train_subset, y_train[disease])\n",
    "            y_test_preds = model.predict(x_test_subset)\n",
    "            y_test_preds_proba = model.predict_proba(x_test_subset)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "            metric_dim, subgroup = \"all\", \"all\"\n",
    "            calculate_metrics(y_test[disease], y_test_preds, y_test_preds_proba, disease_label=disease)\n",
    "\n",
    "    for metric_dim in metric_dimensions:\n",
    "        for subgroup in x_test[metric_dim].unique():\n",
    "            mask = (x_test[metric_dim] == subgroup)\n",
    "            x_test_subgroup = x_test_subset[mask]\n",
    "            y_test_subgroup = y_test.loc[mask]\n",
    "            try:\n",
    "                y_test_preds_subgroup = y_test_preds.loc[mask]\n",
    "                y_test_preds_proba_subgroup = y_test_preds_proba.loc[mask] if y_test_preds_proba is not None else None\n",
    "                calculate_metrics(y_test_subgroup, y_test_preds_subgroup, y_test_preds_proba_subgroup)\n",
    "                for disease in diseases:\n",
    "                    y_true_subgroup_disease = y_test_subgroup[disease]\n",
    "                    y_pred_subgroup_disease = y_test_preds_subgroup[disease]\n",
    "                    y_pred_proba_subgroup_disease = y_test_preds_proba_subgroup[disease] if y_test_preds_proba_subgroup is not None else None\n",
    "                    calculate_metrics(y_true_subgroup_disease, y_pred_subgroup_disease, y_pred_proba_subgroup_disease, disease_label=disease)\n",
    "            except Exception:\n",
    "                for disease in diseases:\n",
    "                    y_test_subgroup_disease = y_test_subgroup[disease]\n",
    "                    y_test_preds_disease = model.predict(x_test_subgroup)\n",
    "                    y_test_preds_proba_disease = model.predict_proba(x_test_subgroup)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "                    calculate_metrics(y_test_subgroup_disease, y_test_preds_disease, y_test_preds_proba_disease, disease_label=disease)\n",
    "\n",
    "    delta_auc_df = calculate_delta_auc(auc_values_per_disease)\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics_data)\n",
    "    metrics_df = metrics_df.reset_index(drop=True)\n",
    "    return metrics_df, delta_auc_df\n",
    "\n",
    "\n",
    "# Beispielaufruf der Funktion und Analyse der Ergebnisse\n",
    "training_size = 2000\n",
    "use_pca = True        \n",
    "n_components = 10     \n",
    "\n",
    "xgb = GradientBoostingClassifier(learning_rate=0.1, n_estimators=30, verbose=1, random_state=42, n_iter_no_change=5)\n",
    "\n",
    "# Trainiere das Modell und speichere die Leistungsmetriken und Delta AUC-Werte\n",
    "metrics_df, delta_auc_df = train_model(\n",
    "    x_train=x_train.iloc[:training_size], \n",
    "    y_train=y_train.iloc[:training_size], \n",
    "    x_test=x_test, \n",
    "    y_test=y_test, \n",
    "    model=xgb, \n",
    "    metric_dimensions=[\"sex\", \"race\", \"insurance_type\"],\n",
    "    n_components=n_components   \n",
    ")\n",
    "\n",
    "# Zeige die Delta AUC-Tabellen für jede metric_dimension an\n",
    "sex_df, race_df, insurance_type_df = delta_auc_df\n",
    "print(\"\\nDelta AUC Tabelle für 'sex':\")\n",
    "print(sex_df)\n",
    "print(\"\\nDelta AUC Tabelle für 'race':\")\n",
    "print(race_df)\n",
    "print(\"\\nDelta AUC Tabelle für 'insurance_type':\")\n",
    "print(insurance_type_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mitigate-bias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
