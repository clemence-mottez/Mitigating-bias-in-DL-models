{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splits adapted from Glocker et al. [Risk of Bias in Chest Radiography Deep Learning Foundation Models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total:  127118\n",
      "Train:  0.5994823707106782\n",
      "Valid:  0.09969477178684372\n",
      "Test:  0.300822857502478\n"
     ]
    }
   ],
   "source": [
    "# Glocker et al. split: \n",
    "train = 76205\n",
    "valid = 12673\n",
    "test=38240\n",
    "\n",
    "sum = train + valid + test\n",
    "print(\"Total: \", sum)\n",
    "\n",
    "print(\"Train: \", train/sum)\n",
    "print(\"Valid: \", valid/sum)\n",
    "print(\"Test: \", test/sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_data/chexpert_plus_240401_cleaned_label_sex.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 114511 samples\n",
      "Validation set: 7634 samples\n",
      "Test set: 68708 samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Split into train (60%) and temp (40%) while stratifying\n",
    "train_df, temp_df = train_test_split(df, test_size=0.4, stratify=df['sex'], random_state=42)\n",
    "\n",
    "# Step 2: Split temp into validation (20%) and test (20%) while stratifying\n",
    "valid_df, test_df = train_test_split(temp_df, test_size=0.9, stratify=temp_df['sex'], random_state=42)\n",
    "\n",
    "# Drop the combined bias column if not needed\n",
    "#train_df = train_df.drop(columns=['bias_combined'])\n",
    "#valid_df = valid_df.drop(columns=['bias_combined'])\n",
    "#test_df = test_df.drop(columns=['bias_combined'])\n",
    "\n",
    "# Print the number of samples in each set (optional)\n",
    "print(f\"Training set: {len(train_df)} samples\")\n",
    "print(f\"Validation set: {len(valid_df)} samples\")\n",
    "print(f\"Test set: {len(test_df)} samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sex distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### OVERALL DATA ###\n",
      "      Count\n",
      "sex        \n",
      "0    112034\n",
      "1     78819\n",
      "     Percentage\n",
      "sex            \n",
      "0     58.701723\n",
      "1     41.298277\n",
      "\n",
      "\n",
      "### TRAIN SET ###\n",
      "     Count\n",
      "sex       \n",
      "0    67220\n",
      "1    47291\n",
      "     Percentage\n",
      "sex            \n",
      "0     58.701784\n",
      "1     41.298216\n",
      "\n",
      "\n",
      "### TEST SET ###\n",
      "     Count\n",
      "sex       \n",
      "0    40333\n",
      "1    28375\n",
      "     Percentage\n",
      "sex            \n",
      "0     58.702043\n",
      "1     41.297957\n",
      "\n",
      "\n",
      "### VALIDATION SET ###\n",
      "     Count\n",
      "sex       \n",
      "0     4481\n",
      "1     3153\n",
      "     Percentage\n",
      "sex            \n",
      "0      58.69793\n",
      "1      41.30207\n"
     ]
    }
   ],
   "source": [
    "# Print overall race distribution\n",
    "print(\"### OVERALL DATA ###\")\n",
    "print(df['sex'].value_counts().to_frame('Count'))\n",
    "print(df['sex'].value_counts(normalize=True).to_frame('Percentage') * 100)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print training set race distribution\n",
    "print(\"### TRAIN SET ###\")\n",
    "print(train_df['sex'].value_counts().to_frame('Count'))\n",
    "print(train_df['sex'].value_counts(normalize=True).to_frame('Percentage') * 100)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print test set race distribution\n",
    "print(\"### TEST SET ###\")\n",
    "print(test_df['sex'].value_counts().to_frame('Count'))\n",
    "print(test_df['sex'].value_counts(normalize=True).to_frame('Percentage') * 100)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print validation set race distribution\n",
    "print(\"### VALIDATION SET ###\")\n",
    "print(valid_df['sex'].value_counts().to_frame('Count'))\n",
    "print(valid_df['sex'].value_counts(normalize=True).to_frame('Percentage') * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving df_sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df drop columns with Unnamed\n",
    "train_df = train_df.loc[:, ~train_df.columns.str.contains('^Unnamed')]\n",
    "valid_df = valid_df.loc[:, ~valid_df.columns.str.contains('^Unnamed')]\n",
    "test_df = test_df.loc[:, ~test_df.columns.str.contains('^Unnamed')]\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "train_df.to_csv('final_data/chexpert_plus_240401_train_sex.csv', index=False)\n",
    "valid_df.to_csv('final_data/chexpert_plus_240401_valid_sex.csv', index=False)\n",
    "test_df.to_csv('final_data/chexpert_plus_240401_test_sex.csv', index=False)\n",
    "# df.to_csv('/data4/lfay/chexpert_plus_240401_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### race distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_data/chexpert_plus_240401_cleaned_label_race.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 83194 samples\n",
      "Validation set: 5546 samples\n",
      "Test set: 49918 samples\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Split into train (60%) and temp (40%) while stratifying\n",
    "train_df, temp_df = train_test_split(df, test_size=0.4, stratify=df['race'], random_state=42)\n",
    "\n",
    "# Step 2: Split temp into validation (20%) and test (20%) while stratifying\n",
    "valid_df, test_df = train_test_split(temp_df, test_size=0.9, stratify=temp_df['race'], random_state=42)\n",
    "\n",
    "# Drop the combined bias column if not needed\n",
    "#train_df = train_df.drop(columns=['bias_combined'])\n",
    "#valid_df = valid_df.drop(columns=['bias_combined'])\n",
    "#test_df = test_df.drop(columns=['bias_combined'])\n",
    "\n",
    "# Print the number of samples in each set (optional)\n",
    "print(f\"Training set: {len(train_df)} samples\")\n",
    "print(f\"Validation set: {len(valid_df)} samples\")\n",
    "print(f\"Test set: {len(test_df)} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### OVERALL DATA ###\n",
      "       Count\n",
      "race        \n",
      "0     108502\n",
      "1      20012\n",
      "2      10144\n",
      "      Percentage\n",
      "race            \n",
      "0      78.251525\n",
      "1      14.432633\n",
      "2       7.315842\n",
      "\n",
      "\n",
      "### TRAIN SET ###\n",
      "      Count\n",
      "race       \n",
      "0     65101\n",
      "1     12007\n",
      "2      6086\n",
      "      Percentage\n",
      "race            \n",
      "0      78.252037\n",
      "1      14.432531\n",
      "2       7.315431\n",
      "\n",
      "\n",
      "### TEST SET ###\n",
      "      Count\n",
      "race       \n",
      "0     39061\n",
      "1      7205\n",
      "2      3652\n",
      "      Percentage\n",
      "race            \n",
      "0      78.250331\n",
      "1      14.433671\n",
      "2       7.315998\n",
      "\n",
      "\n",
      "### VALIDATION SET ###\n",
      "      Count\n",
      "race       \n",
      "0      4340\n",
      "1       800\n",
      "2       406\n",
      "      Percentage\n",
      "race            \n",
      "0      78.254598\n",
      "1      14.424811\n",
      "2       7.320591\n"
     ]
    }
   ],
   "source": [
    "# Print overall race distribution\n",
    "print(\"### OVERALL DATA ###\")\n",
    "print(df['race'].value_counts().to_frame('Count'))\n",
    "print(df['race'].value_counts(normalize=True).to_frame('Percentage') * 100)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print training set race distribution\n",
    "print(\"### TRAIN SET ###\")\n",
    "print(train_df['race'].value_counts().to_frame('Count'))\n",
    "print(train_df['race'].value_counts(normalize=True).to_frame('Percentage') * 100)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print test set race distribution\n",
    "print(\"### TEST SET ###\")\n",
    "print(test_df['race'].value_counts().to_frame('Count'))\n",
    "print(test_df['race'].value_counts(normalize=True).to_frame('Percentage') * 100)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print validation set race distribution\n",
    "print(\"### VALIDATION SET ###\")\n",
    "print(valid_df['race'].value_counts().to_frame('Count'))\n",
    "print(valid_df['race'].value_counts(normalize=True).to_frame('Percentage') * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving df_race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df drop columns with Unnamed\n",
    "train_df = train_df.loc[:, ~train_df.columns.str.contains('^Unnamed')]\n",
    "valid_df = valid_df.loc[:, ~valid_df.columns.str.contains('^Unnamed')]\n",
    "test_df = test_df.loc[:, ~test_df.columns.str.contains('^Unnamed')]\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "train_df.to_csv('final_data/chexpert_plus_240401_train_race.csv', index=False)\n",
    "valid_df.to_csv('final_data/chexpert_plus_240401_valid_race.csv', index=False)\n",
    "test_df.to_csv('final_data/chexpert_plus_240401_test_race.csv', index=False)\n",
    "# df.to_csv('/data4/lfay/chexpert_plus_240401_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### insurance type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_data/chexpert_plus_240401_cleaned_label_health.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 90273 samples\n",
      "Validation set: 6018 samples\n",
      "Test set: 54165 samples\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Split into train (60%) and temp (40%) while stratifying\n",
    "train_df, temp_df = train_test_split(df, test_size=0.4, stratify=df['insurance_type'], random_state=42)\n",
    "\n",
    "# Step 2: Split temp into validation (20%) and test (20%) while stratifying\n",
    "valid_df, test_df = train_test_split(temp_df, test_size=0.9, stratify=temp_df['insurance_type'], random_state=42)\n",
    "\n",
    "# Drop the combined bias column if not needed\n",
    "#train_df = train_df.drop(columns=['bias_combined'])\n",
    "#valid_df = valid_df.drop(columns=['bias_combined'])\n",
    "#test_df = test_df.drop(columns=['bias_combined'])\n",
    "\n",
    "# Print the number of samples in each set (optional)\n",
    "print(f\"Training set: {len(train_df)} samples\")\n",
    "print(f\"Validation set: {len(valid_df)} samples\")\n",
    "print(f\"Test set: {len(test_df)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### OVERALL DATA ###\n",
      "                Count\n",
      "insurance_type       \n",
      "1               91316\n",
      "2               40881\n",
      "0               18259\n",
      "                Percentage\n",
      "insurance_type            \n",
      "1                60.692827\n",
      "2                27.171399\n",
      "0                12.135774\n",
      "\n",
      "\n",
      "### TRAIN SET ###\n",
      "                Count\n",
      "insurance_type       \n",
      "1               54789\n",
      "2               24529\n",
      "0               10955\n",
      "                Percentage\n",
      "insurance_type            \n",
      "1                60.692566\n",
      "2                27.172023\n",
      "0                12.135411\n",
      "\n",
      "\n",
      "### TEST SET ###\n",
      "                Count\n",
      "insurance_type       \n",
      "1               32874\n",
      "2               14717\n",
      "0                6574\n",
      "                Percentage\n",
      "insurance_type            \n",
      "1                60.692329\n",
      "2                27.170682\n",
      "0                12.136989\n",
      "\n",
      "\n",
      "### VALIDATION SET ###\n",
      "                Count\n",
      "insurance_type       \n",
      "1                3653\n",
      "2                1635\n",
      "0                 730\n",
      "                Percentage\n",
      "insurance_type            \n",
      "1                60.701230\n",
      "2                27.168495\n",
      "0                12.130276\n"
     ]
    }
   ],
   "source": [
    "# Print overall race distribution\n",
    "print(\"### OVERALL DATA ###\")\n",
    "print(df['insurance_type'].value_counts().to_frame('Count'))\n",
    "print(df['insurance_type'].value_counts(normalize=True).to_frame('Percentage') * 100)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print training set race distribution\n",
    "print(\"### TRAIN SET ###\")\n",
    "print(train_df['insurance_type'].value_counts().to_frame('Count'))\n",
    "print(train_df['insurance_type'].value_counts(normalize=True).to_frame('Percentage') * 100)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print test set race distribution\n",
    "print(\"### TEST SET ###\")\n",
    "print(test_df['insurance_type'].value_counts().to_frame('Count'))\n",
    "print(test_df['insurance_type'].value_counts(normalize=True).to_frame('Percentage') * 100)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print validation set race distribution\n",
    "print(\"### VALIDATION SET ###\")\n",
    "print(valid_df['insurance_type'].value_counts().to_frame('Count'))\n",
    "print(valid_df['insurance_type'].value_counts(normalize=True).to_frame('Percentage') * 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save df_insurance_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df drop columns with Unnamed\n",
    "train_df = train_df.loc[:, ~train_df.columns.str.contains('^Unnamed')]\n",
    "valid_df = valid_df.loc[:, ~valid_df.columns.str.contains('^Unnamed')]\n",
    "test_df = test_df.loc[:, ~test_df.columns.str.contains('^Unnamed')]\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "train_df.to_csv('final_data/chexpert_plus_240401_train_insurance_type.csv', index=False)\n",
    "valid_df.to_csv('final_data/chexpert_plus_240401_valid_insurance_type.csv', index=False)\n",
    "test_df.to_csv('final_data/chexpert_plus_240401_test_insurance_type.csv', index=False)\n",
    "# df.to_csv('/data4/lfay/chexpert_plus_240401_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
