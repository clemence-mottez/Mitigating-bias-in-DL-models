{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splits adapted from Glocker et al. [Risk of Bias in Chest Radiography Deep Learning Foundation Models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total:  127118\n",
      "Train:  0.5994823707106782\n",
      "Valid:  0.09969477178684372\n",
      "Test:  0.300822857502478\n"
     ]
    }
   ],
   "source": [
    "# Glocker et al. split: \n",
    "train = 76205\n",
    "valid = 12673\n",
    "test=38240\n",
    "\n",
    "sum = train + valid + test\n",
    "print(\"Total: \", sum)\n",
    "\n",
    "print(\"Train: \", train/sum)\n",
    "print(\"Valid: \", valid/sum)\n",
    "print(\"Test: \", test/sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_data/chexpert_plus_240401_cleaned_label.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 67263 samples\n",
      "Validation set: 4484 samples\n",
      "Test set: 40358 samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Split into train (60%) and temp (40%) while stratifying\n",
    "train_df, temp_df = train_test_split(df, test_size=0.4, stratify=df['sex'], random_state=42)\n",
    "\n",
    "# Step 2: Split temp into validation (20%) and test (20%) while stratifying\n",
    "valid_df, test_df = train_test_split(temp_df, test_size=0.9, stratify=temp_df['sex'], random_state=42)\n",
    "\n",
    "# Drop the combined bias column if not needed\n",
    "#train_df = train_df.drop(columns=['bias_combined'])\n",
    "#valid_df = valid_df.drop(columns=['bias_combined'])\n",
    "#test_df = test_df.drop(columns=['bias_combined'])\n",
    "\n",
    "# Print the number of samples in each set (optional)\n",
    "print(f\"Training set: {len(train_df)} samples\")\n",
    "print(f\"Validation set: {len(valid_df)} samples\")\n",
    "print(f\"Test set: {len(test_df)} samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sex distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### OVERALL DATA ###\n",
      "     Count\n",
      "sex       \n",
      "0    65060\n",
      "1    47045\n",
      "     Percentage\n",
      "sex            \n",
      "0     58.034878\n",
      "1     41.965122\n",
      "\n",
      "\n",
      "### TRAIN SET ###\n",
      "     Count\n",
      "sex       \n",
      "0    39036\n",
      "1    28227\n",
      "     Percentage\n",
      "sex            \n",
      "0     58.034878\n",
      "1     41.965122\n",
      "\n",
      "\n",
      "### TEST SET ###\n",
      "     Count\n",
      "sex       \n",
      "0    23422\n",
      "1    16936\n",
      "     Percentage\n",
      "sex            \n",
      "0     58.035582\n",
      "1     41.964418\n",
      "\n",
      "\n",
      "### VALIDATION SET ###\n",
      "     Count\n",
      "sex       \n",
      "0     2602\n",
      "1     1882\n",
      "     Percentage\n",
      "sex            \n",
      "0     58.028546\n",
      "1     41.971454\n"
     ]
    }
   ],
   "source": [
    "# Print overall race distribution\n",
    "print(\"### OVERALL DATA ###\")\n",
    "print(df['sex'].value_counts().to_frame('Count'))\n",
    "print(df['sex'].value_counts(normalize=True).to_frame('Percentage') * 100)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print training set race distribution\n",
    "print(\"### TRAIN SET ###\")\n",
    "print(train_df['sex'].value_counts().to_frame('Count'))\n",
    "print(train_df['sex'].value_counts(normalize=True).to_frame('Percentage') * 100)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print test set race distribution\n",
    "print(\"### TEST SET ###\")\n",
    "print(test_df['sex'].value_counts().to_frame('Count'))\n",
    "print(test_df['sex'].value_counts(normalize=True).to_frame('Percentage') * 100)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print validation set race distribution\n",
    "print(\"### VALIDATION SET ###\")\n",
    "print(valid_df['sex'].value_counts().to_frame('Count'))\n",
    "print(valid_df['sex'].value_counts(normalize=True).to_frame('Percentage') * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving df_sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df drop columns with Unnamed\n",
    "train_df = train_df.loc[:, ~train_df.columns.str.contains('^Unnamed')]\n",
    "valid_df = valid_df.loc[:, ~valid_df.columns.str.contains('^Unnamed')]\n",
    "test_df = test_df.loc[:, ~test_df.columns.str.contains('^Unnamed')]\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "train_df.to_csv('final_data/chexpert_plus_240401_train_sex.csv', index=False)\n",
    "valid_df.to_csv('final_data/chexpert_plus_240401_valid_sex.csv', index=False)\n",
    "test_df.to_csv('final_data/chexpert_plus_240401_test_sex.csv', index=False)\n",
    "# df.to_csv('/data4/lfay/chexpert_plus_240401_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### race distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 67263 samples\n",
      "Validation set: 4484 samples\n",
      "Test set: 40358 samples\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Split into train (60%) and temp (40%) while stratifying\n",
    "train_df, temp_df = train_test_split(df, test_size=0.4, stratify=df['race'], random_state=42)\n",
    "\n",
    "# Step 2: Split temp into validation (20%) and test (20%) while stratifying\n",
    "valid_df, test_df = train_test_split(temp_df, test_size=0.9, stratify=temp_df['race'], random_state=42)\n",
    "\n",
    "# Drop the combined bias column if not needed\n",
    "#train_df = train_df.drop(columns=['bias_combined'])\n",
    "#valid_df = valid_df.drop(columns=['bias_combined'])\n",
    "#test_df = test_df.drop(columns=['bias_combined'])\n",
    "\n",
    "# Print the number of samples in each set (optional)\n",
    "print(f\"Training set: {len(train_df)} samples\")\n",
    "print(f\"Validation set: {len(valid_df)} samples\")\n",
    "print(f\"Test set: {len(test_df)} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### OVERALL DATA ###\n",
      "      Count\n",
      "race       \n",
      "0     87681\n",
      "1     16420\n",
      "2      8004\n",
      "      Percentage\n",
      "race            \n",
      "0      78.213282\n",
      "1      14.646983\n",
      "2       7.139735\n",
      "\n",
      "\n",
      "### TRAIN SET ###\n",
      "      Count\n",
      "race       \n",
      "0     52609\n",
      "1      9852\n",
      "2      4802\n",
      "      Percentage\n",
      "race            \n",
      "0      78.213877\n",
      "1      14.646983\n",
      "2       7.139140\n",
      "\n",
      "\n",
      "### TEST SET ###\n",
      "      Count\n",
      "race       \n",
      "0     31565\n",
      "1      5911\n",
      "2      2882\n",
      "      Percentage\n",
      "race            \n",
      "0      78.212498\n",
      "1      14.646415\n",
      "2       7.141087\n",
      "\n",
      "\n",
      "### VALIDATION SET ###\n",
      "      Count\n",
      "race       \n",
      "0      3507\n",
      "1       657\n",
      "2       320\n",
      "      Percentage\n",
      "race            \n",
      "0      78.211418\n",
      "1      14.652096\n",
      "2       7.136485\n"
     ]
    }
   ],
   "source": [
    "# Print overall race distribution\n",
    "print(\"### OVERALL DATA ###\")\n",
    "print(df['race'].value_counts().to_frame('Count'))\n",
    "print(df['race'].value_counts(normalize=True).to_frame('Percentage') * 100)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print training set race distribution\n",
    "print(\"### TRAIN SET ###\")\n",
    "print(train_df['race'].value_counts().to_frame('Count'))\n",
    "print(train_df['race'].value_counts(normalize=True).to_frame('Percentage') * 100)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print test set race distribution\n",
    "print(\"### TEST SET ###\")\n",
    "print(test_df['race'].value_counts().to_frame('Count'))\n",
    "print(test_df['race'].value_counts(normalize=True).to_frame('Percentage') * 100)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print validation set race distribution\n",
    "print(\"### VALIDATION SET ###\")\n",
    "print(valid_df['race'].value_counts().to_frame('Count'))\n",
    "print(valid_df['race'].value_counts(normalize=True).to_frame('Percentage') * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving df_race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df drop columns with Unnamed\n",
    "train_df = train_df.loc[:, ~train_df.columns.str.contains('^Unnamed')]\n",
    "valid_df = valid_df.loc[:, ~valid_df.columns.str.contains('^Unnamed')]\n",
    "test_df = test_df.loc[:, ~test_df.columns.str.contains('^Unnamed')]\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "train_df.to_csv('final_data/chexpert_plus_240401_train_race.csv', index=False)\n",
    "valid_df.to_csv('final_data/chexpert_plus_240401_valid_race.csv', index=False)\n",
    "test_df.to_csv('final_data/chexpert_plus_240401_test_race.csv', index=False)\n",
    "# df.to_csv('/data4/lfay/chexpert_plus_240401_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### insurance type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 67263 samples\n",
      "Validation set: 4484 samples\n",
      "Test set: 40358 samples\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Split into train (60%) and temp (40%) while stratifying\n",
    "train_df, temp_df = train_test_split(df, test_size=0.4, stratify=df['insurance_type'], random_state=42)\n",
    "\n",
    "# Step 2: Split temp into validation (20%) and test (20%) while stratifying\n",
    "valid_df, test_df = train_test_split(temp_df, test_size=0.9, stratify=temp_df['insurance_type'], random_state=42)\n",
    "\n",
    "# Drop the combined bias column if not needed\n",
    "#train_df = train_df.drop(columns=['bias_combined'])\n",
    "#valid_df = valid_df.drop(columns=['bias_combined'])\n",
    "#test_df = test_df.drop(columns=['bias_combined'])\n",
    "\n",
    "# Print the number of samples in each set (optional)\n",
    "print(f\"Training set: {len(train_df)} samples\")\n",
    "print(f\"Validation set: {len(valid_df)} samples\")\n",
    "print(f\"Test set: {len(test_df)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### OVERALL DATA ###\n",
      "                Count\n",
      "insurance_type       \n",
      "1               71875\n",
      "2               30590\n",
      "0                9640\n",
      "                Percentage\n",
      "insurance_type            \n",
      "1                64.114000\n",
      "2                27.286919\n",
      "0                 8.599081\n",
      "\n",
      "\n",
      "### TRAIN SET ###\n",
      "                Count\n",
      "insurance_type       \n",
      "1               43125\n",
      "2               18354\n",
      "0                5784\n",
      "                Percentage\n",
      "insurance_type            \n",
      "1                64.114000\n",
      "2                27.286919\n",
      "0                 8.599081\n",
      "\n",
      "\n",
      "### TEST SET ###\n",
      "                Count\n",
      "insurance_type       \n",
      "1               25875\n",
      "2               11013\n",
      "0                3470\n",
      "                Percentage\n",
      "insurance_type            \n",
      "1                64.113683\n",
      "2                27.288270\n",
      "0                 8.598047\n",
      "\n",
      "\n",
      "### VALIDATION SET ###\n",
      "                Count\n",
      "insurance_type       \n",
      "1                2875\n",
      "2                1223\n",
      "0                 386\n",
      "                Percentage\n",
      "insurance_type            \n",
      "1                64.116860\n",
      "2                27.274755\n",
      "0                 8.608385\n"
     ]
    }
   ],
   "source": [
    "# Print overall race distribution\n",
    "print(\"### OVERALL DATA ###\")\n",
    "print(df['insurance_type'].value_counts().to_frame('Count'))\n",
    "print(df['insurance_type'].value_counts(normalize=True).to_frame('Percentage') * 100)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print training set race distribution\n",
    "print(\"### TRAIN SET ###\")\n",
    "print(train_df['insurance_type'].value_counts().to_frame('Count'))\n",
    "print(train_df['insurance_type'].value_counts(normalize=True).to_frame('Percentage') * 100)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print test set race distribution\n",
    "print(\"### TEST SET ###\")\n",
    "print(test_df['insurance_type'].value_counts().to_frame('Count'))\n",
    "print(test_df['insurance_type'].value_counts(normalize=True).to_frame('Percentage') * 100)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print validation set race distribution\n",
    "print(\"### VALIDATION SET ###\")\n",
    "print(valid_df['insurance_type'].value_counts().to_frame('Count'))\n",
    "print(valid_df['insurance_type'].value_counts(normalize=True).to_frame('Percentage') * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save df_insurance_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df drop columns with Unnamed\n",
    "train_df = train_df.loc[:, ~train_df.columns.str.contains('^Unnamed')]\n",
    "valid_df = valid_df.loc[:, ~valid_df.columns.str.contains('^Unnamed')]\n",
    "test_df = test_df.loc[:, ~test_df.columns.str.contains('^Unnamed')]\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "train_df.to_csv('final_data/chexpert_plus_240401_train_insurance_type.csv', index=False)\n",
    "valid_df.to_csv('final_data/chexpert_plus_240401_valid_insurance_type.csv', index=False)\n",
    "test_df.to_csv('final_data/chexpert_plus_240401_test_insurance_type.csv', index=False)\n",
    "# df.to_csv('/data4/lfay/chexpert_plus_240401_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
