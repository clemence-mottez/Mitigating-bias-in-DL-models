{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from collections import defaultdict\n",
    "from scipy.stats import entropy\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix, roc_auc_score, precision_recall_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['path_to_image', 'path_to_dcm', 'age', 'sex', 'race', 'insurance_type',\n",
      "       'No Finding', 'Enlarged Cardiomediastinum', 'Cardiomegaly',\n",
      "       'Lung Opacity', 'Lung Lesion', 'Edema', 'Consolidation', 'Pneumonia',\n",
      "       'Atelectasis', 'Pneumothorax', 'Pleural Effusion', 'Pleural Other',\n",
      "       'Fracture', 'Support Devices', 'embeddings'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path_to_image</th>\n",
       "      <th>path_to_dcm</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>insurance_type</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>...</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Support Devices</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/patient47347/study3/view1_frontal.jpg</td>\n",
       "      <td>train/patient47347/study3/view1_frontal.dcm</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0029132624622434378, 0.1020001769065857, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/patient37527/study12/view1_frontal.jpg</td>\n",
       "      <td>train/patient37527/study12/view1_frontal.dcm</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0014348188415169716, 0.0543656125664711, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/patient41208/study9/view1_frontal.jpg</td>\n",
       "      <td>train/patient41208/study9/view1_frontal.dcm</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.001982336398214102, 0.040021587163209915, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/patient39357/study1/view1_frontal.jpg</td>\n",
       "      <td>train/patient39357/study1/view1_frontal.dcm</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.001741771469824016, 0.0560498870909214, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/patient31982/study4/view1_frontal.jpg</td>\n",
       "      <td>train/patient31982/study4/view1_frontal.dcm</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[9.678312198957428e-05, 0.12247737497091293, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  path_to_image  \\\n",
       "0   train/patient47347/study3/view1_frontal.jpg   \n",
       "1  train/patient37527/study12/view1_frontal.jpg   \n",
       "2   train/patient41208/study9/view1_frontal.jpg   \n",
       "3   train/patient39357/study1/view1_frontal.jpg   \n",
       "4   train/patient31982/study4/view1_frontal.jpg   \n",
       "\n",
       "                                    path_to_dcm   age  sex  race  \\\n",
       "0   train/patient47347/study3/view1_frontal.dcm  78.0    1     0   \n",
       "1  train/patient37527/study12/view1_frontal.dcm  63.0    0     1   \n",
       "2   train/patient41208/study9/view1_frontal.dcm  70.0    0     0   \n",
       "3   train/patient39357/study1/view1_frontal.dcm  79.0    1     1   \n",
       "4   train/patient31982/study4/view1_frontal.dcm  67.0    0     0   \n",
       "\n",
       "   insurance_type  No Finding  Enlarged Cardiomediastinum  Cardiomegaly  \\\n",
       "0               1           0                           0             1   \n",
       "1               2           0                           0             0   \n",
       "2               1           0                           0             0   \n",
       "3               1           0                           0             0   \n",
       "4               0           0                           0             0   \n",
       "\n",
       "   Lung Opacity  ...  Edema  Consolidation  Pneumonia  Atelectasis  \\\n",
       "0             0  ...      1              0          0            1   \n",
       "1             0  ...      0              0          0            0   \n",
       "2             1  ...      0              0          0            0   \n",
       "3             0  ...      0              0          1            0   \n",
       "4             0  ...      0              1          0            0   \n",
       "\n",
       "   Pneumothorax  Pleural Effusion  Pleural Other  Fracture  Support Devices  \\\n",
       "0             0                 1              0         1                1   \n",
       "1             0                 1              0         0                0   \n",
       "2             0                 0              0         0                0   \n",
       "3             0                 0              0         0                0   \n",
       "4             0                 1              0         0                0   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [0.0029132624622434378, 0.1020001769065857, 0....  \n",
       "1  [0.0014348188415169716, 0.0543656125664711, 0....  \n",
       "2  [0.001982336398214102, 0.040021587163209915, 0...  \n",
       "3  [0.001741771469824016, 0.0560498870909214, 0.1...  \n",
       "4  [9.678312198957428e-05, 0.12247737497091293, 0...  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"../model_dev/densenet_data/densenet_test_embeddings.csv\", quotechar='\"', on_bad_lines='skip')\n",
    "train = pd.read_csv(\"../model_dev/densenet_data/densenet_train_embeddings.csv\", quotechar='\"', on_bad_lines='skip')\n",
    "# valid = pd.read_csv(\"../model_dev/densenet_data/densenet_valid_embeddings.csv\", quotechar='\"', on_bad_lines='skip')\n",
    "\n",
    "print(test.columns)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert embeddings from str to list (a bit long for large data sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['embeddings'] = test['embeddings'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['embeddings'] = train['embeddings'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(columns=['path_to_image', 'path_to_dcm'])\n",
    "train = train.drop(columns=['path_to_image', 'path_to_dcm'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove rows that were not processed (embeddings = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test removed rows = 51\n",
      "Number of train removed rows = 67\n"
     ]
    }
   ],
   "source": [
    "initial_size = test.shape[0] \n",
    "\n",
    "# The previous logic with transforming the list to string and filtering on the length of said string is not necessarily stable and misleading.\n",
    "# Let's implement a more explicit test for what we actually care about: \n",
    "\n",
    "test = test[test['embeddings'].apply(type) == list]\n",
    "\n",
    "final_size = test.shape[0] \n",
    "\n",
    "print(f'Number of test removed rows = {initial_size - final_size}')\n",
    "\n",
    "initial_size = train.shape[0] \n",
    "\n",
    "train = train[train['embeddings'].apply(type) == list]\n",
    "\n",
    "final_size = train.shape[0] \n",
    "\n",
    "print(f'Number of train removed rows = {initial_size - final_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert age to binary to study bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 70\n",
    "test['age'] = (test['age'] >= a).astype(int)\n",
    "train['age'] = (train['age'] >= a).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create artificial training distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial sex Distribution:\n",
      "sex\n",
      "0    38998\n",
      "1    28198\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Initial Race Distribution:\n",
      "race\n",
      "0    52553\n",
      "1     9844\n",
      "2     4799\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Initial Age Distribution:\n",
      "age\n",
      "0    42267\n",
      "1    24929\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Initial Health Distribution:\n",
      "insurance_type\n",
      "1    43076\n",
      "2    18340\n",
      "0     5780\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial sex Distribution:\")\n",
    "print(train['sex'].value_counts())\n",
    "\n",
    "print(\"\\nInitial Race Distribution:\")\n",
    "print(train['race'].value_counts())\n",
    "\n",
    "print(\"\\nInitial Age Distribution:\")\n",
    "print(train['age'].value_counts())\n",
    "\n",
    "print(\"\\nInitial Health Distribution:\")\n",
    "print(train['insurance_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diseases = ['Cardiomegaly', 'Lung Opacity', 'Edema', 'Atelectasis', 'Pneumothorax', 'Pleural Effusion']\n",
    "# other_cols = ['age', 'sex', 'race', 'insurance_type','embeddings']\n",
    "\n",
    "# train = train[diseases + other_cols]\n",
    "\n",
    "\n",
    "# # Create a list to store resampled data\n",
    "# resampled_data = []\n",
    "\n",
    "# # Determine the size of the largest group based on `sex`, `race`, `insurance_type`\n",
    "# max_size = train.groupby(['sex', 'race', 'age', 'insurance_type']).size().max()\n",
    "\n",
    "# # Loop over each group combination of `sex`, `race`, `insurance_type`\n",
    "# for group, data in train.groupby(['sex', 'race', 'age', 'insurance_type']):\n",
    "\n",
    "#     # Calculate the number of times we need to repeat the data to reach `max_size`\n",
    "#     num_repeats = max_size // len(data)\n",
    "#     remainder = max_size % len(data)\n",
    "\n",
    "#     # Repeat the data `num_repeats` times and add a random sample to reach `max_size`\n",
    "#     resampled_group = pd.concat([data] * num_repeats + [data.sample(remainder, random_state=42)])\n",
    "\n",
    "#     # Append to the list of resampled data\n",
    "#     resampled_data.append(resampled_group)\n",
    "\n",
    "# # Combine all resampled groups back into a single DataFrame\n",
    "# train = pd.concat(resampled_data, ignore_index=True)\n",
    "\n",
    "\n",
    "# train = train.sample(frac=1).reset_index(drop=True)\n",
    "# train = train[:65000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\nFinal sex Distribution:\")\n",
    "# print(train['sex'].value_counts())\n",
    "\n",
    "# print(\"\\nFinal Race Distribution:\")\n",
    "# print(train['race'].value_counts())\n",
    "\n",
    "# print(\"\\nFinal Age Distribution:\")\n",
    "# print(train['age'].value_counts())\n",
    "\n",
    "# print(\"\\nFinal Health Distribution:\")\n",
    "# print(train['insurance_type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings = pd.DataFrame(train['embeddings'].tolist())\n",
    "test_embeddings = pd.DataFrame(test['embeddings'].tolist())\n",
    "# valid_embeddings = pd.DataFrame(valid['embeddings'].tolist())\n",
    "\n",
    "\n",
    "# Diseases to predict\n",
    "# diseases = ['Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity', 'Lung Lesion', 'Edema', 'Consolidation', 'Pneumonia',\n",
    "#             'Atelectasis', 'Pneumothorax', 'Pleural Effusion', 'Pleural Other', 'Fracture']\n",
    "diseases = ['Cardiomegaly', 'Lung Opacity', 'Edema', 'Atelectasis', 'Pneumothorax', 'Pleural Effusion']\n",
    "diseases = ['Cardiomegaly', 'Lung Opacity', 'Edema', 'Pleural Effusion']\n",
    "\n",
    "# Labels for train and test\n",
    "y_train = train[diseases]\n",
    "y_test = test[diseases]\n",
    "\n",
    "# Create x_train and x_test\n",
    "x_train = pd.concat([train.reset_index(), train_embeddings], axis=1)\n",
    "x_test =  pd.concat([test.reset_index(), test_embeddings], axis=1)\n",
    "\n",
    "x_train.drop(columns=[\"embeddings\"] + diseases, inplace=True)\n",
    "x_test.drop(columns=[\"embeddings\"] + diseases, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove embeddings that contain too much information concerning the subgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_to_remove = [634, 611, 304, 885, 867, 508, 892, 973, 889, 441, 160, 416, 632, 13, 630, 371, 105, 108]\n",
    "x_train.drop(columns=emb_to_remove, inplace=True)\n",
    "x_test.drop(columns=emb_to_remove, inplace=True)\n",
    "\n",
    "len_embeddings = 1024 - len(emb_to_remove)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels for train and test\n",
    "y_train = train[diseases]\n",
    "y_test = test[diseases]\n",
    "# y_valid = valid[diseases]\n",
    "y_no_finding = test[\"No Finding\"]\n",
    "y_sex = test['sex']\n",
    "y_race = test['race']\n",
    "y_insurance = test['insurance_type']\n",
    "y_age = test['age']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA to reduce embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of components to retain 95.0% variance: 305\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Standardize the embeddings_list to have mean 0 and variance 1\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(np.stack(train_embeddings.values))\n",
    "X_test_scaled = scaler.transform(np.stack(test_embeddings.values))\n",
    "\n",
    "# Step 2: Set target variance threshold (e.g., 95%)\n",
    "variance_threshold = 0.95\n",
    "\n",
    "# Step 3: Fit PCA to determine the optimal number of components based on variance threshold\n",
    "pca_full = PCA()\n",
    "pca_full.fit(X_train_scaled)\n",
    "cumulative_variance = np.cumsum(pca_full.explained_variance_ratio_)\n",
    "\n",
    "# Step 4: Find the number of components that meets the variance threshold\n",
    "optimal_components = np.argmax(cumulative_variance >= variance_threshold) + 1\n",
    "print(f\"Optimal number of components to retain {variance_threshold*100}% variance: {optimal_components}\")\n",
    "\n",
    "#95% variance means that the selected principal components (reduced dimensions) retain 95% of the total variability present in the original high-dimensional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA if wanted\n",
    "pca = PCA(n_components=optimal_components)\n",
    "x_train_subset = pca.fit_transform(X_train_scaled)\n",
    "x_test_subset = pca.transform(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diseases = ['Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity', 'Lung Lesion', 'Edema', \n",
    "#             'Consolidation', 'Pneumonia', 'Atelectasis', 'Pneumothorax', \n",
    "#             'Pleural Effusion', 'Pleural Other', 'Fracture']\n",
    "diseases = ['Cardiomegaly', 'Lung Opacity', 'Edema', 'Atelectasis', 'Pneumothorax', 'Pleural Effusion']\n",
    "diseases = ['Cardiomegaly', 'Lung Opacity', 'Edema', 'Pleural Effusion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [21:36:54] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [21:36:57] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [21:37:00] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [21:37:02] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def train_model(x_train, y_train, x_test, y_test, model):\n",
    "    multi_output_model = MultiOutputClassifier(model)\n",
    "    \n",
    "\n",
    "    multi_output_model.fit(x_train_subset, y_train)\n",
    "    \n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_test_preds_proba = pd.DataFrame({disease: probs[:, 1] for disease, probs in zip(diseases, multi_output_model.predict_proba(x_test_subset))}) # Dataframe with probabilites \n",
    "    else:\n",
    "        y_test_preds_proba = None\n",
    "\n",
    "\n",
    "    return y_test_preds_proba\n",
    "        \n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    use_label_encoder=False,      \n",
    "    eval_metric='logloss',   \n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "y_pred = train_model(\n",
    "    x_train=x_train_subset, \n",
    "    y_train=y_train, \n",
    "    x_test=x_test_subset, \n",
    "    y_test=y_test, \n",
    "    model=xgb_model, \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = y_pred.values\n",
    "targets = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "diseases = ['Cardiomegaly', 'Lung Opacity', 'Edema', 'Atelectasis', 'Pneumothorax', 'Pleural Effusion']\n",
    "diseases = ['Cardiomegaly', 'Lung Opacity', 'Edema', 'Pleural Effusion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Cardiomegaly': {'Accuracy': 0.8804922221946561, 'AUC': 0.8026408369967064, 'AUPRC': 0.38518884374315265, 'F1 Score': 0.17868712702472297, 'TP Rate': 0.10564516129032259, 'FN Rate': 0.8943548387096775, 'TN Rate': 0.9892211503097859, 'FP Rate': 0.010778849690214162}, 'Lung Opacity': {'Accuracy': 0.6465626318009279, 'AUC': 0.6908386477417863, 'AUPRC': 0.6396731363406032, 'F1 Score': 0.6705213007077108, 'TP Rate': 0.7304978834912316, 'FN Rate': 0.2695021165087684, 'TN Rate': 0.5651663978888726, 'FP Rate': 0.4348336021111274}, 'Edema': {'Accuracy': 0.7762423400401915, 'AUC': 0.781974936311863, 'AUPRC': 0.499379089163803, 'F1 Score': 0.354725620662517, 'TP Rate': 0.25596282911719154, 'FN Rate': 0.7440371708828085, 'TN Rate': 0.9407942002481876, 'FP Rate': 0.05920579975181242}, 'Pleural Effusion': {'Accuracy': 0.7366462401071774, 'AUC': 0.8098310414836782, 'AUPRC': 0.7046539183916294, 'F1 Score': 0.667772526681481, 'TP Rate': 0.6714078922525017, 'FN Rate': 0.32859210774749825, 'TN Rate': 0.7790973871733967, 'FP Rate': 0.2209026128266033}}\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(predictions, targets):\n",
    "    # Calculate metrics for each disease\n",
    "    metrics = {}\n",
    "    for idx, disease in enumerate(diseases):\n",
    "        disease_pred = predictions[disease]\n",
    "        disease_true = targets[disease]\n",
    "        # disease_pred = predictions[:, idx]\n",
    "        # disease_true = targets[:, idx]\n",
    "        auc_roc = roc_auc_score(disease_true, disease_pred)\n",
    "        f1 = f1_score(disease_true, (disease_pred > 0.5).astype(int))\n",
    "        accuracy = accuracy_score(disease_true, (disease_pred > 0.5).astype(int))\n",
    "        tn, fp, fn, tp = confusion_matrix(disease_true, (disease_pred > 0.5).astype(int)).ravel()\n",
    "        tp_rate = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        tn_rate = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        fn_rate = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "        fp_rate = fp / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        \n",
    "        # Calculate Precision-Recall AUC\n",
    "        precision, recall, _ = precision_recall_curve(disease_true, disease_pred)\n",
    "        auprc = auc(recall, precision)\n",
    "\n",
    "        metrics[disease] = {\n",
    "            'Accuracy': accuracy,\n",
    "            'AUC': auc_roc,\n",
    "            'AUPRC': auprc,\n",
    "            'F1 Score': f1,\n",
    "            'TP Rate': tp_rate,\n",
    "            'FN Rate': fn_rate,\n",
    "            'TN Rate': tn_rate,\n",
    "            'FP Rate': fp_rate\n",
    "        }\n",
    "    return metrics\n",
    "\n",
    "metrics = compute_metrics(pd.DataFrame(y_pred), pd.DataFrame(y_test))\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_bc999_row0_col1, #T_bc999_row0_col9, #T_bc999_row0_col10, #T_bc999_row0_col13, #T_bc999_row1_col2, #T_bc999_row1_col3, #T_bc999_row1_col4, #T_bc999_row1_col5, #T_bc999_row1_col6, #T_bc999_row1_col8, #T_bc999_row1_col14, #T_bc999_row2_col7, #T_bc999_row3_col11, #T_bc999_row3_col12 {\n",
       "  background-color: #fff7ec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bc999_row0_col2 {\n",
       "  background-color: #970000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bc999_row0_col3, #T_bc999_row0_col5, #T_bc999_row0_col6, #T_bc999_row0_col8, #T_bc999_row0_col11, #T_bc999_row1_col7, #T_bc999_row1_col10, #T_bc999_row1_col13, #T_bc999_row2_col4, #T_bc999_row2_col9, #T_bc999_row2_col12, #T_bc999_row2_col14, #T_bc999_row3_col1, #T_bc999_row3_col2 {\n",
       "  background-color: #7f0000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bc999_row0_col4 {\n",
       "  background-color: #fc925e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bc999_row0_col7 {\n",
       "  background-color: #fdd8a6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bc999_row0_col12 {\n",
       "  background-color: #fdcd96;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bc999_row0_col14 {\n",
       "  background-color: #930000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bc999_row1_col1, #T_bc999_row3_col7 {\n",
       "  background-color: #ca1e14;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bc999_row1_col9 {\n",
       "  background-color: #feedd4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bc999_row1_col11 {\n",
       "  background-color: #feedd3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bc999_row1_col12 {\n",
       "  background-color: #fddbad;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bc999_row2_col1 {\n",
       "  background-color: #fdbf88;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bc999_row2_col2 {\n",
       "  background-color: #d2291a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bc999_row2_col3 {\n",
       "  background-color: #fddeb3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bc999_row2_col5 {\n",
       "  background-color: #f06849;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bc999_row2_col6 {\n",
       "  background-color: #fdcc96;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bc999_row2_col8 {\n",
       "  background-color: #fc9964;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bc999_row2_col10 {\n",
       "  background-color: #feeed5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bc999_row2_col11 {\n",
       "  background-color: #e54e36;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bc999_row2_col13 {\n",
       "  background-color: #feefd8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bc999_row3_col3 {\n",
       "  background-color: #fee8c9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bc999_row3_col4 {\n",
       "  background-color: #fdc791;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bc999_row3_col5 {\n",
       "  background-color: #fdc68f;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bc999_row3_col6 {\n",
       "  background-color: #f4754f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bc999_row3_col8 {\n",
       "  background-color: #feefda;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bc999_row3_col9 {\n",
       "  background-color: #f57750;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bc999_row3_col10 {\n",
       "  background-color: #f77d52;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bc999_row3_col13 {\n",
       "  background-color: #ed6145;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bc999_row3_col14 {\n",
       "  background-color: #fff7eb;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_bc999\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_bc999_level0_col0\" class=\"col_heading level0 col0\" >Disease</th>\n",
       "      <th id=\"T_bc999_level0_col1\" class=\"col_heading level0 col1\" >AUPRC</th>\n",
       "      <th id=\"T_bc999_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_bc999_level0_col3\" class=\"col_heading level0 col3\" >Delta AUPRC sex</th>\n",
       "      <th id=\"T_bc999_level0_col4\" class=\"col_heading level0 col4\" >EqOdds sex</th>\n",
       "      <th id=\"T_bc999_level0_col5\" class=\"col_heading level0 col5\" >KL div sex</th>\n",
       "      <th id=\"T_bc999_level0_col6\" class=\"col_heading level0 col6\" >Delta AUPRC race</th>\n",
       "      <th id=\"T_bc999_level0_col7\" class=\"col_heading level0 col7\" >EqOdds race</th>\n",
       "      <th id=\"T_bc999_level0_col8\" class=\"col_heading level0 col8\" >KL div race</th>\n",
       "      <th id=\"T_bc999_level0_col9\" class=\"col_heading level0 col9\" >Delta AUPRC age</th>\n",
       "      <th id=\"T_bc999_level0_col10\" class=\"col_heading level0 col10\" >EqOdds age</th>\n",
       "      <th id=\"T_bc999_level0_col11\" class=\"col_heading level0 col11\" >KL div age</th>\n",
       "      <th id=\"T_bc999_level0_col12\" class=\"col_heading level0 col12\" >Delta AUPRC health</th>\n",
       "      <th id=\"T_bc999_level0_col13\" class=\"col_heading level0 col13\" >EqOdds health</th>\n",
       "      <th id=\"T_bc999_level0_col14\" class=\"col_heading level0 col14\" >KL div health</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_bc999_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_bc999_row0_col0\" class=\"data row0 col0\" >Cardiomegaly</td>\n",
       "      <td id=\"T_bc999_row0_col1\" class=\"data row0 col1\" >38.5</td>\n",
       "      <td id=\"T_bc999_row0_col2\" class=\"data row0 col2\" >80.3</td>\n",
       "      <td id=\"T_bc999_row0_col3\" class=\"data row0 col3\" >4.6</td>\n",
       "      <td id=\"T_bc999_row0_col4\" class=\"data row0 col4\" >1.6</td>\n",
       "      <td id=\"T_bc999_row0_col5\" class=\"data row0 col5\" >1.7</td>\n",
       "      <td id=\"T_bc999_row0_col6\" class=\"data row0 col6\" >15.9</td>\n",
       "      <td id=\"T_bc999_row0_col7\" class=\"data row0 col7\" >1.3</td>\n",
       "      <td id=\"T_bc999_row0_col8\" class=\"data row0 col8\" >13.2</td>\n",
       "      <td id=\"T_bc999_row0_col9\" class=\"data row0 col9\" >0.0</td>\n",
       "      <td id=\"T_bc999_row0_col10\" class=\"data row0 col10\" >1.2</td>\n",
       "      <td id=\"T_bc999_row0_col11\" class=\"data row0 col11\" >10.6</td>\n",
       "      <td id=\"T_bc999_row0_col12\" class=\"data row0 col12\" >5.2</td>\n",
       "      <td id=\"T_bc999_row0_col13\" class=\"data row0 col13\" >1.6</td>\n",
       "      <td id=\"T_bc999_row0_col14\" class=\"data row0 col14\" >8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bc999_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_bc999_row1_col0\" class=\"data row1 col0\" >Lung Opacity</td>\n",
       "      <td id=\"T_bc999_row1_col1\" class=\"data row1 col1\" >64.0</td>\n",
       "      <td id=\"T_bc999_row1_col2\" class=\"data row1 col2\" >69.1</td>\n",
       "      <td id=\"T_bc999_row1_col3\" class=\"data row1 col3\" >0.1</td>\n",
       "      <td id=\"T_bc999_row1_col4\" class=\"data row1 col4\" >0.1</td>\n",
       "      <td id=\"T_bc999_row1_col5\" class=\"data row1 col5\" >0.0</td>\n",
       "      <td id=\"T_bc999_row1_col6\" class=\"data row1 col6\" >1.0</td>\n",
       "      <td id=\"T_bc999_row1_col7\" class=\"data row1 col7\" >3.3</td>\n",
       "      <td id=\"T_bc999_row1_col8\" class=\"data row1 col8\" >1.2</td>\n",
       "      <td id=\"T_bc999_row1_col9\" class=\"data row1 col9\" >0.6</td>\n",
       "      <td id=\"T_bc999_row1_col10\" class=\"data row1 col10\" >9.9</td>\n",
       "      <td id=\"T_bc999_row1_col11\" class=\"data row1 col11\" >3.4</td>\n",
       "      <td id=\"T_bc999_row1_col12\" class=\"data row1 col12\" >5.0</td>\n",
       "      <td id=\"T_bc999_row1_col13\" class=\"data row1 col13\" >8.3</td>\n",
       "      <td id=\"T_bc999_row1_col14\" class=\"data row1 col14\" >4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bc999_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_bc999_row2_col0\" class=\"data row2 col0\" >Edema</td>\n",
       "      <td id=\"T_bc999_row2_col1\" class=\"data row2 col1\" >49.9</td>\n",
       "      <td id=\"T_bc999_row2_col2\" class=\"data row2 col2\" >78.2</td>\n",
       "      <td id=\"T_bc999_row2_col3\" class=\"data row2 col3\" >0.9</td>\n",
       "      <td id=\"T_bc999_row2_col4\" class=\"data row2 col4\" >3.0</td>\n",
       "      <td id=\"T_bc999_row2_col5\" class=\"data row2 col5\" >1.0</td>\n",
       "      <td id=\"T_bc999_row2_col6\" class=\"data row2 col6\" >5.3</td>\n",
       "      <td id=\"T_bc999_row2_col7\" class=\"data row2 col7\" >0.7</td>\n",
       "      <td id=\"T_bc999_row2_col8\" class=\"data row2 col8\" >6.8</td>\n",
       "      <td id=\"T_bc999_row2_col9\" class=\"data row2 col9\" >6.2</td>\n",
       "      <td id=\"T_bc999_row2_col10\" class=\"data row2 col10\" >1.9</td>\n",
       "      <td id=\"T_bc999_row2_col11\" class=\"data row2 col11\" >8.1</td>\n",
       "      <td id=\"T_bc999_row2_col12\" class=\"data row2 col12\" >7.3</td>\n",
       "      <td id=\"T_bc999_row2_col13\" class=\"data row2 col13\" >2.1</td>\n",
       "      <td id=\"T_bc999_row2_col14\" class=\"data row2 col14\" >9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bc999_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_bc999_row3_col0\" class=\"data row3 col0\" >Pleural Effusion</td>\n",
       "      <td id=\"T_bc999_row3_col1\" class=\"data row3 col1\" >70.5</td>\n",
       "      <td id=\"T_bc999_row3_col2\" class=\"data row3 col2\" >81.0</td>\n",
       "      <td id=\"T_bc999_row3_col3\" class=\"data row3 col3\" >0.6</td>\n",
       "      <td id=\"T_bc999_row3_col4\" class=\"data row3 col4\" >1.1</td>\n",
       "      <td id=\"T_bc999_row3_col5\" class=\"data row3 col5\" >0.5</td>\n",
       "      <td id=\"T_bc999_row3_col6\" class=\"data row3 col6\" >9.6</td>\n",
       "      <td id=\"T_bc999_row3_col7\" class=\"data row3 col7\" >2.8</td>\n",
       "      <td id=\"T_bc999_row3_col8\" class=\"data row3 col8\" >2.0</td>\n",
       "      <td id=\"T_bc999_row3_col9\" class=\"data row3 col9\" >3.6</td>\n",
       "      <td id=\"T_bc999_row3_col10\" class=\"data row3 col10\" >6.0</td>\n",
       "      <td id=\"T_bc999_row3_col11\" class=\"data row3 col11\" >2.8</td>\n",
       "      <td id=\"T_bc999_row3_col12\" class=\"data row3 col12\" >4.4</td>\n",
       "      <td id=\"T_bc999_row3_col13\" class=\"data row3 col13\" >5.8</td>\n",
       "      <td id=\"T_bc999_row3_col14\" class=\"data row3 col14\" >4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f80f67eef10>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_distributions(y_true, y_pred):\n",
    "            P = np.array([1 - y_true, y_true]).T  # Probabiility distribution of True Labels\n",
    "            Q = np.array([1 - y_pred, y_pred]).T  # Probabiility distribution of predicted diseases\n",
    "            return P, Q\n",
    "\n",
    "# Calculate metrics for each disease and for each class\n",
    "\n",
    "metrics_female = {}\n",
    "for idx, disease in enumerate(diseases):\n",
    "    # disease_pred = predictions[:, idx]\n",
    "    disease_pred = predictions[y_sex == 1, idx]\n",
    "    disease_true = targets[y_sex == 1, idx]\n",
    "    auc_roc = roc_auc_score(disease_true, disease_pred)\n",
    "    f1 = f1_score(disease_true, (disease_pred > 0.5).astype(int))\n",
    "    accuracy = accuracy_score(disease_true, (disease_pred > 0.5).astype(int))\n",
    "    tn, fp, fn, tp = confusion_matrix(disease_true, (disease_pred > 0.5).astype(int)).ravel()\n",
    "    tp_rate = tp / (tp + fn)\n",
    "    tn_rate = tn / (tn + fp)\n",
    "    fn_rate = fn / (fn + tp)\n",
    "    fp_rate = fp / (tn + fp)\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(disease_true, disease_pred)\n",
    "    auprc = auc(recall, precision)\n",
    "\n",
    "    # KL-Divergence\n",
    "    P, Q = create_distributions(disease_true, disease_pred)\n",
    "    kl_div = np.mean([entropy(P_row, Q_row) for P_row, Q_row in zip(P, Q)])\n",
    "\n",
    "    metrics_female[disease] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'AUC': auc_roc,\n",
    "        'AUPRC': auprc,\n",
    "        'F1 Score': f1,\n",
    "        'TP Rate': tp_rate,\n",
    "        'FN Rate': fn_rate,\n",
    "        'TN Rate': tn_rate,\n",
    "        'FP Rate': fp_rate,\n",
    "        'KL Div': kl_div\n",
    "        }\n",
    "    \n",
    "metrics_male = {}\n",
    "for idx, disease in enumerate(diseases):\n",
    "    # disease_pred = predictions[:, idx]\n",
    "    disease_pred = predictions[y_sex == 0, idx]\n",
    "    disease_true = targets[y_sex == 0, idx]\n",
    "    auc_roc = roc_auc_score(disease_true, disease_pred)\n",
    "    f1 = f1_score(disease_true, (disease_pred > 0.5).astype(int))\n",
    "    accuracy = accuracy_score(disease_true, (disease_pred > 0.5).astype(int))\n",
    "    tn, fp, fn, tp = confusion_matrix(disease_true, (disease_pred > 0.5).astype(int)).ravel()\n",
    "    tp_rate = tp / (tp + fn)\n",
    "    tn_rate = tn / (tn + fp)\n",
    "    fn_rate = fn / (fn + tp)\n",
    "    fp_rate = fp / (tn + fp)\n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(disease_true, disease_pred)\n",
    "    auprc = auc(recall, precision)\n",
    "\n",
    "\n",
    "    # KL-Divergence\n",
    "    P, Q = create_distributions(disease_true, disease_pred)\n",
    "    kl_div = np.mean([entropy(P_row, Q_row) for P_row, Q_row in zip(P, Q)])\n",
    "\n",
    "    metrics_male[disease] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'AUC': auc_roc,\n",
    "        'AUPRC': auprc,\n",
    "        'F1 Score': f1,\n",
    "        'TP Rate': tp_rate,\n",
    "        'FN Rate': fn_rate,\n",
    "        'TN Rate': tn_rate,\n",
    "        'FP Rate': fp_rate,\n",
    "        'KL Div': kl_div\n",
    "        }\n",
    "    \n",
    "\n",
    "metrics_white = {}\n",
    "for idx, disease in enumerate(diseases):\n",
    "    # disease_pred = predictions[:, idx]\n",
    "    disease_pred = predictions[y_race == 0, idx]\n",
    "    disease_true = targets[y_race == 0, idx]\n",
    "    auc_roc = roc_auc_score(disease_true, disease_pred)\n",
    "    f1 = f1_score(disease_true, (disease_pred > 0.5).astype(int))\n",
    "    accuracy = accuracy_score(disease_true, (disease_pred > 0.5).astype(int))\n",
    "    tn, fp, fn, tp = confusion_matrix(disease_true, (disease_pred > 0.5).astype(int)).ravel()\n",
    "    tp_rate = tp / (tp + fn)\n",
    "    tn_rate = tn / (tn + fp)\n",
    "    fn_rate = fn / (fn + tp)\n",
    "    fp_rate = fp / (tn + fp)\n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(disease_true, disease_pred)\n",
    "    auprc = auc(recall, precision)\n",
    "\n",
    "\n",
    "    # KL-Divergence\n",
    "    P, Q = create_distributions(disease_true, disease_pred)\n",
    "    kl_div = np.mean([entropy(P_row, Q_row) for P_row, Q_row in zip(P, Q)])\n",
    "\n",
    "    metrics_white[disease] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'AUC': auc_roc,\n",
    "        'AUPRC': auprc,\n",
    "        'F1 Score': f1,\n",
    "        'TP Rate': tp_rate,\n",
    "        'FN Rate': fn_rate,\n",
    "        'TN Rate': tn_rate,\n",
    "        'FP Rate': fp_rate,\n",
    "        'KL Div': kl_div\n",
    "        }\n",
    "    \n",
    "metrics_black = {}\n",
    "for idx, disease in enumerate(diseases):\n",
    "    # disease_pred = predictions[:, idx]\n",
    "    disease_pred = predictions[y_race == 2, idx]\n",
    "    disease_true = targets[y_race == 2, idx]\n",
    "    auc_roc = roc_auc_score(disease_true, disease_pred)\n",
    "    f1 = f1_score(disease_true, (disease_pred > 0.5).astype(int))\n",
    "    accuracy = accuracy_score(disease_true, (disease_pred > 0.5).astype(int))\n",
    "    tn, fp, fn, tp = confusion_matrix(disease_true, (disease_pred > 0.5).astype(int)).ravel()\n",
    "    tp_rate = tp / (tp + fn)\n",
    "    tn_rate = tn / (tn + fp)\n",
    "    fn_rate = fn / (fn + tp)\n",
    "    fp_rate = fp / (tn + fp)\n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(disease_true, disease_pred)\n",
    "    auprc = auc(recall, precision)\n",
    "\n",
    "\n",
    "    # KL-Divergence\n",
    "    P, Q = create_distributions(disease_true, disease_pred)\n",
    "    kl_div = np.mean([entropy(P_row, Q_row) for P_row, Q_row in zip(P, Q)])\n",
    "\n",
    "    metrics_black[disease] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'AUC': auc_roc,\n",
    "        'AUPRC': auprc,\n",
    "        'F1 Score': f1,\n",
    "        'TP Rate': tp_rate,\n",
    "        'FN Rate': fn_rate,\n",
    "        'TN Rate': tn_rate,\n",
    "        'FP Rate': fp_rate,\n",
    "        'KL Div': kl_div\n",
    "        }\n",
    "    \n",
    "metrics_asian = {}\n",
    "for idx, disease in enumerate(diseases):\n",
    "    # disease_pred = predictions[:, idx]\n",
    "    disease_pred = predictions[y_race == 1, idx]\n",
    "    disease_true = targets[y_race == 1, idx]\n",
    "    auc_roc = roc_auc_score(disease_true, disease_pred)\n",
    "    f1 = f1_score(disease_true, (disease_pred > 0.5).astype(int))\n",
    "    accuracy = accuracy_score(disease_true, (disease_pred > 0.5).astype(int))\n",
    "    tn, fp, fn, tp = confusion_matrix(disease_true, (disease_pred > 0.5).astype(int)).ravel()\n",
    "    tp_rate = tp / (tp + fn)\n",
    "    tn_rate = tn / (tn + fp)\n",
    "    fn_rate = fn / (fn + tp)\n",
    "    fp_rate = fp / (tn + fp)\n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(disease_true, disease_pred)\n",
    "    auprc = auc(recall, precision)\n",
    "\n",
    "\n",
    "    # KL-Divergence\n",
    "    P, Q = create_distributions(disease_true, disease_pred)\n",
    "    kl_div = np.mean([entropy(P_row, Q_row) for P_row, Q_row in zip(P, Q)])\n",
    "\n",
    "    metrics_asian[disease] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'AUC': auc_roc,\n",
    "        'AUPRC': auprc,\n",
    "        'F1 Score': f1,\n",
    "        'TP Rate': tp_rate,\n",
    "        'FN Rate': fn_rate,\n",
    "        'TN Rate': tn_rate,\n",
    "        'FP Rate': fp_rate,\n",
    "        'KL Div': kl_div\n",
    "        }\n",
    "    \n",
    "\n",
    "metrics_medicaid = {}\n",
    "for idx, disease in enumerate(diseases):\n",
    "    # disease_pred = predictions[:, idx]\n",
    "    disease_pred = predictions[y_insurance == 0, idx]\n",
    "    disease_true = targets[y_insurance == 0, idx]\n",
    "    auc_roc = roc_auc_score(disease_true, disease_pred)\n",
    "    f1 = f1_score(disease_true, (disease_pred > 0.5).astype(int))\n",
    "    accuracy = accuracy_score(disease_true, (disease_pred > 0.5).astype(int))\n",
    "    tn, fp, fn, tp = confusion_matrix(disease_true, (disease_pred > 0.5).astype(int)).ravel()\n",
    "    tp_rate = tp / (tp + fn)\n",
    "    tn_rate = tn / (tn + fp)\n",
    "    fn_rate = fn / (fn + tp)\n",
    "    fp_rate = fp / (tn + fp)\n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(disease_true, disease_pred)\n",
    "    auprc = auc(recall, precision)\n",
    "\n",
    "\n",
    "    # KL-Divergence\n",
    "    P, Q = create_distributions(disease_true, disease_pred)\n",
    "    kl_div = np.mean([entropy(P_row, Q_row) for P_row, Q_row in zip(P, Q)])\n",
    "\n",
    "    metrics_medicaid[disease] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'AUC': auc_roc,\n",
    "        'AUPRC': auprc,\n",
    "        'F1 Score': f1,\n",
    "        'TP Rate': tp_rate,\n",
    "        'FN Rate': fn_rate,\n",
    "        'TN Rate': tn_rate,\n",
    "        'FP Rate': fp_rate,\n",
    "        'KL Div': kl_div\n",
    "        }\n",
    "    \n",
    "metrics_medicare = {}\n",
    "for idx, disease in enumerate(diseases):\n",
    "    # disease_pred = predictions[:, idx]\n",
    "    disease_pred = predictions[y_insurance == 1, idx]\n",
    "    disease_true = targets[y_insurance == 1, idx]\n",
    "    auc_roc = roc_auc_score(disease_true, disease_pred)\n",
    "    f1 = f1_score(disease_true, (disease_pred > 0.5).astype(int))\n",
    "    accuracy = accuracy_score(disease_true, (disease_pred > 0.5).astype(int))\n",
    "    tn, fp, fn, tp = confusion_matrix(disease_true, (disease_pred > 0.5).astype(int)).ravel()\n",
    "    tp_rate = tp / (tp + fn)\n",
    "    tn_rate = tn / (tn + fp)\n",
    "    fn_rate = fn / (fn + tp)\n",
    "    fp_rate = fp / (tn + fp)\n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(disease_true, disease_pred)\n",
    "    auprc = auc(recall, precision)\n",
    "\n",
    "\n",
    "    # KL-Divergence\n",
    "    P, Q = create_distributions(disease_true, disease_pred)\n",
    "    kl_div = np.mean([entropy(P_row, Q_row) for P_row, Q_row in zip(P, Q)])\n",
    "\n",
    "    metrics_medicare[disease] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'AUC': auc_roc,\n",
    "        'AUPRC': auprc,\n",
    "        'F1 Score': f1,\n",
    "        'TP Rate': tp_rate,\n",
    "        'FN Rate': fn_rate,\n",
    "        'TN Rate': tn_rate,\n",
    "        'FP Rate': fp_rate,\n",
    "        'KL Div': kl_div\n",
    "        }\n",
    "    \n",
    "metrics_private = {}\n",
    "for idx, disease in enumerate(diseases):\n",
    "    # disease_pred = predictions[:, idx]\n",
    "    disease_pred = predictions[y_insurance == 2, idx]\n",
    "    disease_true = targets[y_insurance == 2, idx]\n",
    "    auc_roc = roc_auc_score(disease_true, disease_pred)\n",
    "    f1 = f1_score(disease_true, (disease_pred > 0.5).astype(int))\n",
    "    accuracy = accuracy_score(disease_true, (disease_pred > 0.5).astype(int))\n",
    "    tn, fp, fn, tp = confusion_matrix(disease_true, (disease_pred > 0.5).astype(int)).ravel()\n",
    "    tp_rate = tp / (tp + fn)\n",
    "    tn_rate = tn / (tn + fp)\n",
    "    fn_rate = fn / (fn + tp)\n",
    "    fp_rate = fp / (tn + fp)\n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(disease_true, disease_pred)\n",
    "    auprc = auc(recall, precision)\n",
    "\n",
    "\n",
    "    # KL-Divergence\n",
    "    P, Q = create_distributions(disease_true, disease_pred)\n",
    "    kl_div = np.mean([entropy(P_row, Q_row) for P_row, Q_row in zip(P, Q)])\n",
    "\n",
    "    metrics_private[disease] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'AUC': auc_roc,\n",
    "        'AUPRC': auprc,\n",
    "        'F1 Score': f1,\n",
    "        'TP Rate': tp_rate,\n",
    "        'FN Rate': fn_rate,\n",
    "        'TN Rate': tn_rate,\n",
    "        'FP Rate': fp_rate,\n",
    "        'KL Div': kl_div\n",
    "        }\n",
    "    \n",
    "\n",
    "metrics_young = {}\n",
    "for idx, disease in enumerate(diseases):\n",
    "    # disease_pred = predictions[:, idx]\n",
    "    disease_pred = predictions[y_age == 0, idx]\n",
    "    disease_true = targets[y_age == 0, idx]\n",
    "    auc_roc = roc_auc_score(disease_true, disease_pred)\n",
    "    f1 = f1_score(disease_true, (disease_pred > 0.5).astype(int))\n",
    "    accuracy = accuracy_score(disease_true, (disease_pred > 0.5).astype(int))\n",
    "    tn, fp, fn, tp = confusion_matrix(disease_true, (disease_pred > 0.5).astype(int)).ravel()\n",
    "    tp_rate = tp / (tp + fn)\n",
    "    tn_rate = tn / (tn + fp)\n",
    "    fn_rate = fn / (fn + tp)\n",
    "    fp_rate = fp / (tn + fp)\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(disease_true, disease_pred)\n",
    "    auprc = auc(recall, precision)\n",
    "\n",
    "\n",
    "    # KL-Divergence\n",
    "    P, Q = create_distributions(disease_true, disease_pred)\n",
    "    kl_div = np.mean([entropy(P_row, Q_row) for P_row, Q_row in zip(P, Q)])\n",
    "\n",
    "    metrics_young[disease] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'AUC': auc_roc,\n",
    "        'AUPRC': auprc,\n",
    "        'F1 Score': f1,\n",
    "        'TP Rate': tp_rate,\n",
    "        'FN Rate': fn_rate,\n",
    "        'TN Rate': tn_rate,\n",
    "        'FP Rate': fp_rate,\n",
    "        'KL Div': kl_div\n",
    "        }\n",
    "    \n",
    "metrics_old = {}\n",
    "for idx, disease in enumerate(diseases):\n",
    "    # disease_pred = predictions[:, idx]\n",
    "    disease_pred = predictions[y_age == 1, idx]\n",
    "    disease_true = targets[y_age == 1, idx]\n",
    "    auc_roc = roc_auc_score(disease_true, disease_pred)\n",
    "    f1 = f1_score(disease_true, (disease_pred > 0.5).astype(int))\n",
    "    accuracy = accuracy_score(disease_true, (disease_pred > 0.5).astype(int))\n",
    "    tn, fp, fn, tp = confusion_matrix(disease_true, (disease_pred > 0.5).astype(int)).ravel()\n",
    "    tp_rate = tp / (tp + fn)\n",
    "    tn_rate = tn / (tn + fp)\n",
    "    fn_rate = fn / (fn + tp)\n",
    "    fp_rate = fp / (tn + fp)\n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(disease_true, disease_pred)\n",
    "    auprc = auc(recall, precision)\n",
    "\n",
    "\n",
    "    # KL-Divergence\n",
    "    P, Q = create_distributions(disease_true, disease_pred)\n",
    "    kl_div = np.mean([entropy(P_row, Q_row) for P_row, Q_row in zip(P, Q)])\n",
    "\n",
    "    metrics_old[disease] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'AUC': auc_roc,\n",
    "        'AUPRC': auprc,\n",
    "        'F1 Score': f1,\n",
    "        'TP Rate': tp_rate,\n",
    "        'FN Rate': fn_rate,\n",
    "        'TN Rate': tn_rate,\n",
    "        'FP Rate': fp_rate,\n",
    "        'KL Div': kl_div\n",
    "        }\n",
    "# Initialize an empty list to store the data\n",
    "data_sex = []\n",
    "\n",
    "# Iterate over the diseases in the metrics dictionary\n",
    "for disease, values in metrics.items():\n",
    "    # Extract AUC and rates from dictionaries\n",
    "    \n",
    "    auprc_overall = values['AUPRC'] *100\n",
    "\n",
    "    auc_overall = values['AUC'] *100\n",
    "    auc_male = metrics_male[disease]['AUPRC'] *100\n",
    "    auc_female = metrics_female[disease]['AUPRC'] *100\n",
    "    tp_rate_male = metrics_male[disease]['TP Rate'] *100\n",
    "    tp_rate_female = metrics_female[disease]['TP Rate'] *100\n",
    "    fp_rate_male = metrics_male[disease]['FP Rate'] *100\n",
    "    fp_rate_female = metrics_female[disease]['FP Rate'] *100\n",
    "\n",
    "    kl1 = metrics_male[disease]['KL Div'] *100\n",
    "    kl2 = metrics_female[disease]['KL Div'] *100\n",
    "\n",
    "    \n",
    "    delta_KL_sex = abs(kl1 - kl2)\n",
    "\n",
    "\n",
    "    # Calculate delta AUC and equality of odds\n",
    "    delta_auc_sex = abs(auc_male - auc_female) \n",
    "    eq_odds_sex = 0.5 * (abs(tp_rate_male - tp_rate_female) + abs(fp_rate_male - fp_rate_female))\n",
    "    \n",
    "    # Append to the data list\n",
    "    data_sex.append([disease, auprc_overall, auc_overall, auc_male, auc_female, delta_auc_sex, eq_odds_sex, delta_KL_sex])\n",
    "\n",
    "# Create a DataFrame\n",
    "df_sex = pd.DataFrame(data_sex, columns=['Disease', 'AUPRC', 'AUC', 'AUC_Male', 'AUC_Female', 'Delta AUC', 'EqOdds', 'KL div'])\n",
    "\n",
    "\n",
    "# Styling the DataFrame\n",
    "styled_df = df_sex.style.format({\n",
    "    'AUC': \"{:.3f}\", \n",
    "    'AUPRC': \"{:.3f}\",\n",
    "    'AUC_Male': \"{:.3f}\", \n",
    "    'AUC_Female': \"{:.3f}\",\n",
    "    'Delta AUC': \"{:.3f}\",\n",
    "    'EqOdds': \"{:.3f}\",\n",
    "    'KL div': \"{:.3f}\"\n",
    "}).background_gradient(cmap='viridis', subset=['AUPRC', 'AUC', 'AUC_Male', 'AUC_Female', 'Delta AUC', 'EqOdds', 'KL div'])\n",
    "\n",
    "# Display the styled DataFrame\n",
    "styled_df\n",
    "\n",
    "# Initialize an empty list to store the data\n",
    "data_race = []\n",
    "\n",
    "# Iterate over the diseases in the metrics dictionary\n",
    "for disease, values in metrics.items():\n",
    "    auprc_overall = values['AUPRC'] *100\n",
    "    auc_overall = values['AUC'] *100\n",
    "    auc_groups = [\n",
    "        metrics_white[disease]['AUPRC'] *100,\n",
    "        metrics_black[disease]['AUPRC'] *100,\n",
    "        metrics_asian[disease]['AUPRC'] *100\n",
    "    ]\n",
    "    tp_rates = [\n",
    "        metrics_white[disease]['TP Rate'] *100,\n",
    "        metrics_black[disease]['TP Rate'] *100,\n",
    "        metrics_asian[disease]['TP Rate'] *100\n",
    "    ]\n",
    "    fp_rates = [\n",
    "        metrics_white[disease]['FP Rate'] *100,\n",
    "        metrics_black[disease]['FP Rate'] *100,\n",
    "        metrics_asian[disease]['FP Rate'] *100\n",
    "    ]\n",
    "\n",
    "    kl_rates = [\n",
    "        metrics_white[disease]['KL Div'] *100,\n",
    "        metrics_black[disease]['KL Div'] *100,\n",
    "        metrics_asian[disease]['KL Div'] *100\n",
    "    ]\n",
    "\n",
    "    delta_kl_race = max(abs(kl_rates[i] - kl_rates[j]) for i in range(len(kl_rates)) for j in range(i + 1, len(kl_rates)))\n",
    "\n",
    "    # Calculate the maximum delta AUC\n",
    "    delta_auc_race = max(abs(auc_groups[i] - auc_groups[j]) for i in range(len(auc_groups)) for j in range(i + 1, len(auc_groups)))\n",
    "\n",
    "    # Calculate the maximum equality of odds\n",
    "    eq_odds_race = max(\n",
    "        0.5 * (abs(tp_rates[i] - tp_rates[j]) + abs(fp_rates[i] - fp_rates[j]))\n",
    "        for i in range(len(tp_rates)) for j in range(i + 1, len(tp_rates))\n",
    "    )\n",
    "\n",
    "    # Append to the data list\n",
    "    data_race.append([disease, auprc_overall, auc_overall] + auc_groups + [delta_auc_race, eq_odds_race, delta_kl_race])\n",
    "\n",
    "# Create a DataFrame\n",
    "columns = ['Disease', 'AUPRC', 'AUC', 'AUC_White', 'AUC_Black', 'AUC_Asian', 'Max Delta AUC', 'Max EqOdds', 'KL div']\n",
    "df_race = pd.DataFrame(data_race, columns=columns)\n",
    "\n",
    "# Display the DataFrame with styling\n",
    "# Styling the DataFrame\n",
    "styled_df = df_race.style.format({\n",
    "    'AUC': \"{:.3f}\", \n",
    "    'AUPRC': \"{:.3f}\", \n",
    "    'AUC_White': \"{:.3f}\", \n",
    "    'AUC_Black': \"{:.3f}\",\n",
    "    'AUC_Asian': \"{:.3f}\",\n",
    "    'Max Delta AUC': \"{:.3f}\",\n",
    "    'Max EqOdds': \"{:.3f}\",\n",
    "    'KL div': \"{:.3f}\"\n",
    "}).background_gradient(cmap='viridis', subset=['AUPRC', 'AUC', 'AUC_White', 'AUC_Black', 'AUC_Asian', 'Max Delta AUC', 'Max EqOdds', 'KL div'])\n",
    "\n",
    "# Display the styled DataFrame\n",
    "styled_df\n",
    "# Initialize an empty list to store the data\n",
    "data_age = []\n",
    "\n",
    "# Iterate over the diseases in the metrics dictionary\n",
    "for disease, values in metrics.items():\n",
    "    # Extract AUC and rates from dictionaries\n",
    "    \n",
    "    auprc_overall = values['AUPRC'] *100\n",
    "\n",
    "    auc_overall = values['AUC'] *100\n",
    "    auc_old = metrics_old[disease]['AUPRC'] *100\n",
    "    auc_young = metrics_young[disease]['AUPRC'] *100\n",
    "    tp_rate_old = metrics_old[disease]['TP Rate'] *100\n",
    "    tp_rate_young = metrics_young[disease]['TP Rate'] *100\n",
    "    fp_rate_old = metrics_old[disease]['FP Rate'] *100\n",
    "    fp_rate_young = metrics_young[disease]['FP Rate'] *100\n",
    "\n",
    "\n",
    "    kl1 = metrics_old[disease]['KL Div'] *100\n",
    "    kl2 = metrics_young[disease]['KL Div'] *100\n",
    "\n",
    "    \n",
    "    delta_KL_age = abs(kl1 - kl2)\n",
    "\n",
    "    \n",
    "    # Calculate delta AUC and equality of odds\n",
    "    delta_auc_age = abs(auc_old - auc_young)\n",
    "    eq_odds_age = 0.5 * (abs(tp_rate_old - tp_rate_young) + abs(fp_rate_old - fp_rate_young))\n",
    "    \n",
    "    # Append to the data list\n",
    "    data_age.append([disease, auprc_overall, auc_overall, auc_old, auc_young, delta_auc_age, eq_odds_age, delta_KL_age])\n",
    "\n",
    "# Create a DataFrame\n",
    "df_age = pd.DataFrame(data_age, columns=['Disease', 'AUPRC', 'AUC', 'AUC_old', 'AUC_young', 'Delta AUC', 'EqOdds', 'KL div'])\n",
    "\n",
    "\n",
    "# Styling the DataFrame\n",
    "styled_df = df_age.style.format({\n",
    "    'AUC': \"{:.3f}\", \n",
    "    'AUPRC': \"{:.3f}\",\n",
    "    'AUC_old': \"{:.3f}\", \n",
    "    'AUC_young': \"{:.3f}\",\n",
    "    'Delta AUC': \"{:.3f}\",\n",
    "    'EqOdds': \"{:.3f}\",\n",
    "    'KL div': \"{:.3f}\"\n",
    "}).background_gradient(cmap='viridis', subset=['AUC', 'AUPRC', 'AUC_old', 'AUC_young', 'Delta AUC', 'EqOdds', 'KL div'])\n",
    "\n",
    "# Display the styled DataFrame\n",
    "styled_df\n",
    "\n",
    "# Initialize an empty list to store the data\n",
    "data_health = []\n",
    "\n",
    "# Iterate over the diseases in the metrics dictionary\n",
    "for disease, values in metrics.items():\n",
    "    auprc_overall = values['AUPRC'] *100\n",
    "    auc_overall = values['AUC'] *100\n",
    "    auc_groups = [\n",
    "        metrics_medicaid[disease]['AUPRC'] *100,\n",
    "        metrics_medicare[disease]['AUPRC'] *100,\n",
    "        metrics_private[disease]['AUPRC'] *100\n",
    "    ]\n",
    "    tp_rates = [\n",
    "        metrics_medicaid[disease]['TP Rate'] *100,\n",
    "        metrics_medicare[disease]['TP Rate'] *100,\n",
    "        metrics_private[disease]['TP Rate'] *100\n",
    "    ]\n",
    "    fp_rates = [\n",
    "        metrics_medicaid[disease]['FP Rate'] *100,\n",
    "        metrics_medicare[disease]['FP Rate'] *100,\n",
    "        metrics_private[disease]['FP Rate'] *100\n",
    "    ]\n",
    "\n",
    "    kl_rates = [\n",
    "        metrics_medicaid[disease]['KL Div'] *100,\n",
    "        metrics_medicare[disease]['KL Div'] *100,\n",
    "        metrics_private[disease]['KL Div'] *100\n",
    "    ]\n",
    "\n",
    "    delta_kl_health = max(abs(kl_rates[i] - kl_rates[j]) for i in range(len(kl_rates)) for j in range(i + 1, len(kl_rates)))\n",
    "\n",
    "    # Calculate the maximum delta AUC\n",
    "    delta_auc_health = max(abs(auc_groups[i] - auc_groups[j]) for i in range(len(auc_groups)) for j in range(i + 1, len(auc_groups)))\n",
    "\n",
    "    # Calculate the maximum equality of odds\n",
    "    eq_odds_health = max(\n",
    "        0.5 * (abs(tp_rates[i] - tp_rates[j]) + abs(fp_rates[i] - fp_rates[j]))\n",
    "        for i in range(len(tp_rates)) for j in range(i + 1, len(tp_rates))\n",
    "    )\n",
    "\n",
    "    # Append to the data list\n",
    "    data_health.append([disease, auprc_overall, auc_overall] + auc_groups + [delta_auc_health, eq_odds_health, delta_kl_health])\n",
    "\n",
    "# Create a DataFrame\n",
    "columns = ['Disease', 'AUPRC', 'AUC', 'AUC_Medicaid', 'AUC_Medicare', 'AUC_Private', 'Max Delta AUC', 'Max EqOdds', 'KL div']\n",
    "df_health = pd.DataFrame(data_health, columns=columns)\n",
    "\n",
    "# Display the DataFrame with styling\n",
    "# Styling the DataFrame\n",
    "styled_df = df_health.style.format({\n",
    "    'AUC': \"{:.3f}\", \n",
    "    'AUPRC': \"{:.3f}\", \n",
    "    'AUC_Medicaid': \"{:.3f}\", \n",
    "    'AUC_Medicare': \"{:.3f}\",\n",
    "    'AUC_Private': \"{:.3f}\",\n",
    "    'Max Delta AUC': \"{:.3f}\",\n",
    "    'Max EqOdds': \"{:.3f}\",\n",
    "    'KL div': \"{:.3f}\"\n",
    "}).background_gradient(cmap='viridis', subset=['AUPRC', 'AUC',  'AUC_Medicaid', 'AUC_Medicare', 'AUC_Private', 'Max Delta AUC', 'Max EqOdds', 'KL div'])\n",
    "\n",
    "# Display the styled DataFrame\n",
    "styled_df\n",
    "# Initialize an empty list to store the data\n",
    "data = []\n",
    "i = 0\n",
    "\n",
    "# Assuming 'metrics', 'df_sex', 'df_race', 'df_age', and 'df_health' are predefined and correctly structured\n",
    "# Iterate over the diseases in the metrics dictionary\n",
    "for disease, values in metrics.items():\n",
    "    auprc_overall = values['AUPRC'] * 100\n",
    "    auc_overall = values['AUC'] * 100\n",
    "\n",
    "    # Append to the data list\n",
    "    data.append([disease, auprc_overall, auc_overall] +\n",
    "                [df_sex['Delta AUC'][i], df_sex['EqOdds'][i], df_sex['KL div'][i]] +\n",
    "                [df_race['Max Delta AUC'][i], df_race['Max EqOdds'][i], df_race['KL div'][i]] +\n",
    "                [df_age['Delta AUC'][i], df_age['EqOdds'][i], df_age['KL div'][i]] +\n",
    "                [df_health['Max Delta AUC'][i], df_health['Max EqOdds'][i], df_health['KL div'][i]])\n",
    "    i += 1\n",
    "\n",
    "# Create a DataFrame\n",
    "columns = ['Disease', 'AUPRC', 'AUC', 'Delta AUPRC sex', 'EqOdds sex', 'KL div sex',\n",
    "           'Delta AUPRC race', 'EqOdds race', 'KL div race', 'Delta AUPRC age', 'EqOdds age', 'KL div age',\n",
    "           'Delta AUPRC health', 'EqOdds health', 'KL div health']\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Styling the DataFrame\n",
    "styled_df = df.style.format({\n",
    "    'AUPRC': \"{:.1f}\",\n",
    "    'AUC': \"{:.1f}\",\n",
    "    'Delta AUPRC sex': \"{:.1f}\",\n",
    "    'EqOdds sex': \"{:.1f}\",\n",
    "    'KL div sex': \"{:.1f}\",\n",
    "    'Delta AUPRC race': \"{:.1f}\",\n",
    "    'EqOdds race': \"{:.1f}\",\n",
    "    'KL div race': \"{:.1f}\",\n",
    "    'Delta AUPRC age': \"{:.1f}\",\n",
    "    'EqOdds age': \"{:.1f}\",\n",
    "    'KL div age': \"{:.1f}\",\n",
    "    'Delta AUPRC health': \"{:.1f}\",\n",
    "    'EqOdds health': \"{:.1f}\",\n",
    "    'KL div health': \"{:.1f}\"\n",
    "}).background_gradient(cmap='OrRd', subset=[\n",
    "    'AUPRC', 'AUC', 'Delta AUPRC sex', 'EqOdds sex', 'KL div sex', 'Delta AUPRC race', 'EqOdds race', 'KL div race',\n",
    "    'Delta AUPRC age', 'EqOdds age', 'KL div age', 'Delta AUPRC health', 'EqOdds health', 'KL div health'\n",
    "])\n",
    "\n",
    "# Display the styled DataFrame\n",
    "styled_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"remove_emb_xgb.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mitigate-bias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
