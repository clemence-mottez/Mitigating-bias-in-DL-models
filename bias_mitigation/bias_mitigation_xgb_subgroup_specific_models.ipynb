{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from collections import defaultdict\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix, roc_auc_score, precision_recall_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['path_to_image', 'path_to_dcm', 'age', 'sex', 'race', 'insurance_type',\n",
      "       'No Finding', 'Enlarged Cardiomediastinum', 'Cardiomegaly',\n",
      "       'Lung Opacity', 'Lung Lesion', 'Edema', 'Consolidation', 'Pneumonia',\n",
      "       'Atelectasis', 'Pneumothorax', 'Pleural Effusion', 'Pleural Other',\n",
      "       'Fracture', 'Support Devices', 'embeddings'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path_to_image</th>\n",
       "      <th>path_to_dcm</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>insurance_type</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>...</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Support Devices</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/patient47347/study3/view1_frontal.jpg</td>\n",
       "      <td>train/patient47347/study3/view1_frontal.dcm</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0029132624622434378, 0.1020001769065857, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/patient37527/study12/view1_frontal.jpg</td>\n",
       "      <td>train/patient37527/study12/view1_frontal.dcm</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0014348188415169716, 0.0543656125664711, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/patient41208/study9/view1_frontal.jpg</td>\n",
       "      <td>train/patient41208/study9/view1_frontal.dcm</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.001982336398214102, 0.040021587163209915, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/patient39357/study1/view1_frontal.jpg</td>\n",
       "      <td>train/patient39357/study1/view1_frontal.dcm</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.001741771469824016, 0.0560498870909214, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/patient31982/study4/view1_frontal.jpg</td>\n",
       "      <td>train/patient31982/study4/view1_frontal.dcm</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[9.678312198957428e-05, 0.12247737497091293, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  path_to_image  \\\n",
       "0   train/patient47347/study3/view1_frontal.jpg   \n",
       "1  train/patient37527/study12/view1_frontal.jpg   \n",
       "2   train/patient41208/study9/view1_frontal.jpg   \n",
       "3   train/patient39357/study1/view1_frontal.jpg   \n",
       "4   train/patient31982/study4/view1_frontal.jpg   \n",
       "\n",
       "                                    path_to_dcm   age  sex  race  \\\n",
       "0   train/patient47347/study3/view1_frontal.dcm  78.0    1     0   \n",
       "1  train/patient37527/study12/view1_frontal.dcm  63.0    0     1   \n",
       "2   train/patient41208/study9/view1_frontal.dcm  70.0    0     0   \n",
       "3   train/patient39357/study1/view1_frontal.dcm  79.0    1     1   \n",
       "4   train/patient31982/study4/view1_frontal.dcm  67.0    0     0   \n",
       "\n",
       "   insurance_type  No Finding  Enlarged Cardiomediastinum  Cardiomegaly  \\\n",
       "0               1           0                           0             1   \n",
       "1               2           0                           0             0   \n",
       "2               1           0                           0             0   \n",
       "3               1           0                           0             0   \n",
       "4               0           0                           0             0   \n",
       "\n",
       "   Lung Opacity  ...  Edema  Consolidation  Pneumonia  Atelectasis  \\\n",
       "0             0  ...      1              0          0            1   \n",
       "1             0  ...      0              0          0            0   \n",
       "2             1  ...      0              0          0            0   \n",
       "3             0  ...      0              0          1            0   \n",
       "4             0  ...      0              1          0            0   \n",
       "\n",
       "   Pneumothorax  Pleural Effusion  Pleural Other  Fracture  Support Devices  \\\n",
       "0             0                 1              0         1                1   \n",
       "1             0                 1              0         0                0   \n",
       "2             0                 0              0         0                0   \n",
       "3             0                 0              0         0                0   \n",
       "4             0                 1              0         0                0   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [0.0029132624622434378, 0.1020001769065857, 0....  \n",
       "1  [0.0014348188415169716, 0.0543656125664711, 0....  \n",
       "2  [0.001982336398214102, 0.040021587163209915, 0...  \n",
       "3  [0.001741771469824016, 0.0560498870909214, 0.1...  \n",
       "4  [9.678312198957428e-05, 0.12247737497091293, 0...  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"../model_dev/densenet_data/densenet_test_embeddings.csv\", quotechar='\"', on_bad_lines='skip')\n",
    "train = pd.read_csv(\"../model_dev/densenet_data/densenet_train_embeddings.csv\", quotechar='\"', on_bad_lines='skip')\n",
    "# valid = pd.read_csv(\"../model_dev/densenet_data/densenet_valid_embeddings.csv\", quotechar='\"', on_bad_lines='skip')\n",
    "\n",
    "print(test.columns)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert embeddings from str to list (a bit long for large data sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['embeddings'] = test['embeddings'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['embeddings'] = train['embeddings'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(columns=['path_to_image', 'path_to_dcm'])\n",
    "train = train.drop(columns=['path_to_image', 'path_to_dcm'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove rows that were not processed (embeddings = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test removed rows = 51\n",
      "Number of train removed rows = 67\n"
     ]
    }
   ],
   "source": [
    "initial_size = test.shape[0] \n",
    "\n",
    "# The previous logic with transforming the list to string and filtering on the length of said string is not necessarily stable and misleading.\n",
    "# Let's implement a more explicit test for what we actually care about: \n",
    "\n",
    "test = test[test['embeddings'].apply(type) == list]\n",
    "\n",
    "final_size = test.shape[0] \n",
    "\n",
    "print(f'Number of test removed rows = {initial_size - final_size}')\n",
    "\n",
    "initial_size = train.shape[0] \n",
    "\n",
    "train = train[train['embeddings'].apply(type) == list]\n",
    "\n",
    "final_size = train.shape[0] \n",
    "\n",
    "print(f'Number of train removed rows = {initial_size - final_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert age to binary to study bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 70\n",
    "test['age'] = (test['age'] >= a).astype(int)\n",
    "train['age'] = (train['age'] >= a).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create artificial training distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial sex Distribution:\n",
      "sex\n",
      "0    38998\n",
      "1    28198\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Initial Race Distribution:\n",
      "race\n",
      "0    52553\n",
      "1     9844\n",
      "2     4799\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Initial Age Distribution:\n",
      "age\n",
      "0    42267\n",
      "1    24929\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Initial Health Distribution:\n",
      "insurance_type\n",
      "1    43076\n",
      "2    18340\n",
      "0     5780\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial sex Distribution:\")\n",
    "print(train['sex'].value_counts())\n",
    "\n",
    "print(\"\\nInitial Race Distribution:\")\n",
    "print(train['race'].value_counts())\n",
    "\n",
    "print(\"\\nInitial Age Distribution:\")\n",
    "print(train['age'].value_counts())\n",
    "\n",
    "print(\"\\nInitial Health Distribution:\")\n",
    "print(train['insurance_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diseases = ['Cardiomegaly', 'Lung Opacity', 'Edema', 'Atelectasis', 'Pneumothorax', 'Pleural Effusion']\n",
    "# other_cols = ['age', 'sex', 'race', 'insurance_type','embeddings']\n",
    "\n",
    "# train = train[diseases + other_cols]\n",
    "\n",
    "\n",
    "# # Create a list to store resampled data\n",
    "# resampled_data = []\n",
    "\n",
    "# # Determine the size of the largest group based on `sex`, `race`, `insurance_type`\n",
    "# max_size = train.groupby(['sex', 'race', 'age', 'insurance_type']).size().max()\n",
    "\n",
    "# # Loop over each group combination of `sex`, `race`, `insurance_type`\n",
    "# for group, data in train.groupby(['sex', 'race', 'age', 'insurance_type']):\n",
    "\n",
    "#     # Calculate the number of times we need to repeat the data to reach `max_size`\n",
    "#     num_repeats = max_size // len(data)\n",
    "#     remainder = max_size % len(data)\n",
    "\n",
    "#     # Repeat the data `num_repeats` times and add a random sample to reach `max_size`\n",
    "#     resampled_group = pd.concat([data] * num_repeats + [data.sample(remainder, random_state=42)])\n",
    "\n",
    "#     # Append to the list of resampled data\n",
    "#     resampled_data.append(resampled_group)\n",
    "\n",
    "# # Combine all resampled groups back into a single DataFrame\n",
    "# train = pd.concat(resampled_data, ignore_index=True)\n",
    "\n",
    "\n",
    "# train = train.sample(frac=1).reset_index(drop=True)\n",
    "# train = train[:65000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\nFinal sex Distribution:\")\n",
    "# print(train['sex'].value_counts())\n",
    "\n",
    "# print(\"\\nFinal Race Distribution:\")\n",
    "# print(train['race'].value_counts())\n",
    "\n",
    "# print(\"\\nFinal Age Distribution:\")\n",
    "# print(train['age'].value_counts())\n",
    "\n",
    "# print(\"\\nFinal Health Distribution:\")\n",
    "# print(train['insurance_type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose which subgroup doing a model for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of components to retain 95.0% variance: 300\n"
     ]
    }
   ],
   "source": [
    "train1 = train[train[\"age\"]==0]\n",
    "test1 = test[test[\"age\"]==0]\n",
    "\n",
    "train_embeddings = pd.DataFrame(train1['embeddings'].tolist())\n",
    "test_embeddings = pd.DataFrame(test1['embeddings'].tolist())\n",
    "# valid_embeddings = pd.DataFrame(valid['embeddings'].tolist())\n",
    "\n",
    "diseases = ['Cardiomegaly', 'Lung Opacity', 'Edema', 'Atelectasis', 'Pneumothorax', 'Pleural Effusion']\n",
    "\n",
    "# Labels for train and test\n",
    "y_train = train1[diseases]\n",
    "y_test = test1[diseases]\n",
    "\n",
    "# Create x_train and x_test\n",
    "x_train = pd.concat([train1.reset_index(), train_embeddings], axis=1)\n",
    "x_test =  pd.concat([test1.reset_index(), test_embeddings], axis=1)\n",
    "\n",
    "x_train.drop(columns=[\"embeddings\"] + diseases, inplace=True)\n",
    "x_test.drop(columns=[\"embeddings\"] + diseases, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Labels for train and test\n",
    "y_train = train1[diseases]\n",
    "y_test = test1[diseases]\n",
    "# y_valid = valid[diseases]\n",
    "y_no_finding = test1[\"No Finding\"]\n",
    "y_sex = test1['sex']\n",
    "y_race = test1['race']\n",
    "y_insurance = test1['insurance_type']\n",
    "y_age = test1['age']\n",
    "\n",
    "\n",
    "# Step 1: Standardize the embeddings_list to have mean 0 and variance 1\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(np.stack(train_embeddings.values))\n",
    "X_test_scaled = scaler.transform(np.stack(test_embeddings.values))\n",
    "\n",
    "# Step 2: Set target variance threshold (e.g., 95%)\n",
    "variance_threshold = 0.95\n",
    "\n",
    "# Step 3: Fit PCA to determine the optimal number of components based on variance threshold\n",
    "pca_full = PCA()\n",
    "pca_full.fit(X_train_scaled)\n",
    "cumulative_variance = np.cumsum(pca_full.explained_variance_ratio_)\n",
    "\n",
    "# Step 4: Find the number of components that meets the variance threshold\n",
    "optimal_components = np.argmax(cumulative_variance >= variance_threshold) + 1\n",
    "print(f\"Optimal number of components to retain {variance_threshold*100}% variance: {optimal_components}\")\n",
    "\n",
    "# Apply PCA if wanted\n",
    "pca = PCA(n_components=optimal_components)\n",
    "x_train_subset = pca.fit_transform(X_train_scaled)\n",
    "x_test_subset = pca.transform(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [14:42:35] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [14:42:37] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [14:42:39] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [14:42:41] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [14:42:43] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [14:42:46] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "def train_model(x_train, y_train, x_test, y_test, model):\n",
    "    multi_output_model = MultiOutputClassifier(model)\n",
    "    \n",
    "\n",
    "    multi_output_model.fit(x_train_subset, y_train)\n",
    "    \n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_test_preds_proba = pd.DataFrame({disease: probs[:, 1] for disease, probs in zip(diseases, multi_output_model.predict_proba(x_test_subset))}) # Dataframe with probabilites \n",
    "    else:\n",
    "        y_test_preds_proba = None\n",
    "\n",
    "\n",
    "    return y_test_preds_proba\n",
    "        \n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    use_label_encoder=False,      \n",
    "    eval_metric='logloss',   \n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "y_pred = train_model(\n",
    "    x_train=x_train_subset, \n",
    "    y_train=y_train, \n",
    "    x_test=x_test_subset, \n",
    "    y_test=y_test, \n",
    "    model=xgb_model, \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1 = y_pred.values\n",
    "targets1 = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of components to retain 95.0% variance: 310\n"
     ]
    }
   ],
   "source": [
    "train2 = train[train[\"age\"]==1]\n",
    "test2 = test[test[\"age\"]==1]\n",
    "\n",
    "train_embeddings = pd.DataFrame(train2['embeddings'].tolist())\n",
    "test_embeddings = pd.DataFrame(test2['embeddings'].tolist())\n",
    "# valid_embeddings = pd.DataFrame(valid['embeddings'].tolist())\n",
    "\n",
    "diseases = ['Cardiomegaly', 'Lung Opacity', 'Edema', 'Atelectasis', 'Pneumothorax', 'Pleural Effusion']\n",
    "\n",
    "# Labels for train and test\n",
    "y_train = train2[diseases]\n",
    "y_test = test2[diseases]\n",
    "\n",
    "# Create x_train and x_test\n",
    "x_train = pd.concat([train2.reset_index(), train_embeddings], axis=1)\n",
    "x_test =  pd.concat([test2.reset_index(), test_embeddings], axis=1)\n",
    "\n",
    "x_train.drop(columns=[\"embeddings\"] + diseases, inplace=True)\n",
    "x_test.drop(columns=[\"embeddings\"] + diseases, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Labels for train and test\n",
    "y_train = train2[diseases]\n",
    "y_test = test2[diseases]\n",
    "# y_valid = valid[diseases]\n",
    "y_no_finding = test2[\"No Finding\"]\n",
    "y_sex = test2['sex']\n",
    "y_race = test2['race']\n",
    "y_insurance = test2['insurance_type']\n",
    "y_age = test2['age']\n",
    "\n",
    "\n",
    "# Step 1: Standardize the embeddings_list to have mean 0 and variance 1\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(np.stack(train_embeddings.values))\n",
    "X_test_scaled = scaler.transform(np.stack(test_embeddings.values))\n",
    "\n",
    "# Step 2: Set target variance threshold (e.g., 95%)\n",
    "variance_threshold = 0.95\n",
    "\n",
    "# Step 3: Fit PCA to determine the optimal number of components based on variance threshold\n",
    "pca_full = PCA()\n",
    "pca_full.fit(X_train_scaled)\n",
    "cumulative_variance = np.cumsum(pca_full.explained_variance_ratio_)\n",
    "\n",
    "# Step 4: Find the number of components that meets the variance threshold\n",
    "optimal_components = np.argmax(cumulative_variance >= variance_threshold) + 1\n",
    "print(f\"Optimal number of components to retain {variance_threshold*100}% variance: {optimal_components}\")\n",
    "\n",
    "# Apply PCA if wanted\n",
    "pca = PCA(n_components=optimal_components)\n",
    "x_train_subset = pca.fit_transform(X_train_scaled)\n",
    "x_test_subset = pca.transform(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [14:42:59] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [14:43:01] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [14:43:03] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [14:43:05] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [14:43:07] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [14:43:08] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "def train_model(x_train, y_train, x_test, y_test, model):\n",
    "    multi_output_model = MultiOutputClassifier(model)\n",
    "    \n",
    "\n",
    "    multi_output_model.fit(x_train_subset, y_train)\n",
    "    \n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_test_preds_proba = pd.DataFrame({disease: probs[:, 1] for disease, probs in zip(diseases, multi_output_model.predict_proba(x_test_subset))}) # Dataframe with probabilites \n",
    "    else:\n",
    "        y_test_preds_proba = None\n",
    "\n",
    "\n",
    "    return y_test_preds_proba\n",
    "        \n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    use_label_encoder=False,      \n",
    "    eval_metric='logloss',   \n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "y_pred = train_model(\n",
    "    x_train=x_train_subset, \n",
    "    y_train=y_train, \n",
    "    x_test=x_test_subset, \n",
    "    y_test=y_test, \n",
    "    model=xgb_model, \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = y_pred.values\n",
    "targets2 = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of components to retain 95.0% variance: 310\n"
     ]
    }
   ],
   "source": [
    "train3 = train[train[\"age\"]==1]\n",
    "test3 = test[test[\"age\"]==1]\n",
    "\n",
    "train_embeddings = pd.DataFrame(train2['embeddings'].tolist())\n",
    "test_embeddings = pd.DataFrame(test2['embeddings'].tolist())\n",
    "# valid_embeddings = pd.DataFrame(valid['embeddings'].tolist())\n",
    "\n",
    "diseases = ['Cardiomegaly', 'Lung Opacity', 'Edema', 'Atelectasis', 'Pneumothorax', 'Pleural Effusion']\n",
    "\n",
    "# Labels for train and test\n",
    "y_train = train3[diseases]\n",
    "y_test = test3[diseases]\n",
    "\n",
    "# Create x_train and x_test\n",
    "x_train = pd.concat([train3.reset_index(), train_embeddings], axis=1)\n",
    "x_test =  pd.concat([test3.reset_index(), test_embeddings], axis=1)\n",
    "\n",
    "x_train.drop(columns=[\"embeddings\"] + diseases, inplace=True)\n",
    "x_test.drop(columns=[\"embeddings\"] + diseases, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Labels for train and test\n",
    "y_train = train3[diseases]\n",
    "y_test = test3[diseases]\n",
    "# y_valid = valid[diseases]\n",
    "y_no_finding = test3[\"No Finding\"]\n",
    "y_sex = test3['sex']\n",
    "y_race = test3['race']\n",
    "y_insurance = test3['insurance_type']\n",
    "y_age = test3['age']\n",
    "\n",
    "\n",
    "# Step 1: Standardize the embeddings_list to have mean 0 and variance 1\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(np.stack(train_embeddings.values))\n",
    "X_test_scaled = scaler.transform(np.stack(test_embeddings.values))\n",
    "\n",
    "# Step 2: Set target variance threshold (e.g., 95%)\n",
    "variance_threshold = 0.95\n",
    "\n",
    "# Step 3: Fit PCA to determine the optimal number of components based on variance threshold\n",
    "pca_full = PCA()\n",
    "pca_full.fit(X_train_scaled)\n",
    "cumulative_variance = np.cumsum(pca_full.explained_variance_ratio_)\n",
    "\n",
    "# Step 4: Find the number of components that meets the variance threshold\n",
    "optimal_components = np.argmax(cumulative_variance >= variance_threshold) + 1\n",
    "print(f\"Optimal number of components to retain {variance_threshold*100}% variance: {optimal_components}\")\n",
    "\n",
    "# Apply PCA if wanted\n",
    "pca = PCA(n_components=optimal_components)\n",
    "x_train_subset = pca.fit_transform(X_train_scaled)\n",
    "x_test_subset = pca.transform(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [14:43:23] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [14:43:24] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [14:43:26] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [14:43:28] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [14:43:30] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/cmottez/miniconda3/envs/mitigate-bias/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [14:43:32] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "def train_model(x_train, y_train, x_test, y_test, model):\n",
    "    multi_output_model = MultiOutputClassifier(model)\n",
    "    \n",
    "\n",
    "    multi_output_model.fit(x_train_subset, y_train)\n",
    "    \n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_test_preds_proba = pd.DataFrame({disease: probs[:, 1] for disease, probs in zip(diseases, multi_output_model.predict_proba(x_test_subset))}) # Dataframe with probabilites \n",
    "    else:\n",
    "        y_test_preds_proba = None\n",
    "\n",
    "\n",
    "    return y_test_preds_proba\n",
    "        \n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    use_label_encoder=False,      \n",
    "    eval_metric='logloss',   \n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "y_pred = train_model(\n",
    "    x_train=x_train_subset, \n",
    "    y_train=y_train, \n",
    "    x_test=x_test_subset, \n",
    "    y_test=y_test, \n",
    "    model=xgb_model, \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions3 = y_pred.values\n",
    "targets3 = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "diseases = ['Cardiomegaly', 'Lung Opacity', 'Edema', 'Atelectasis', 'Pneumothorax', 'Pleural Effusion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate metrics for each disease and for each class\n",
    "\n",
    "metrics_1 = {}\n",
    "for idx, disease in enumerate(diseases):\n",
    "    # disease_pred = predictions[:, idx]\n",
    "    disease_pred = predictions1[:, idx]\n",
    "    disease_true = targets1[:, idx]\n",
    "    auc_roc = roc_auc_score(disease_true, disease_pred)\n",
    "    f1 = f1_score(disease_true, (disease_pred > 0.5).astype(int))\n",
    "    accuracy = accuracy_score(disease_true, (disease_pred > 0.5).astype(int))\n",
    "    tn, fp, fn, tp = confusion_matrix(disease_true, (disease_pred > 0.5).astype(int)).ravel()\n",
    "    tp_rate = tp / (tp + fn)\n",
    "    tn_rate = tn / (tn + fp)\n",
    "    fn_rate = fn / (fn + tp)\n",
    "    fp_rate = fp / (tn + fp)\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(disease_true, disease_pred)\n",
    "    auprc = auc(recall, precision)\n",
    "\n",
    "\n",
    "    metrics_1[disease] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'AUC': auc_roc,\n",
    "        'AUPRC': auprc,\n",
    "        'F1 Score': f1,\n",
    "        'TP Rate': tp_rate,\n",
    "        'FN Rate': fn_rate,\n",
    "        'TN Rate': tn_rate,\n",
    "        'FP Rate': fp_rate\n",
    "        }\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "metrics2 = {}\n",
    "for idx, disease in enumerate(diseases):\n",
    "    # disease_pred = predictions[:, idx]\n",
    "    disease_pred = predictions2[y_sex == 0, idx]\n",
    "    disease_true = targets2[y_sex == 0, idx]\n",
    "    auc_roc = roc_auc_score(disease_true, disease_pred)\n",
    "    f1 = f1_score(disease_true, (disease_pred > 0.5).astype(int))\n",
    "    accuracy = accuracy_score(disease_true, (disease_pred > 0.5).astype(int))\n",
    "    tn, fp, fn, tp = confusion_matrix(disease_true, (disease_pred > 0.5).astype(int)).ravel()\n",
    "    tp_rate = tp / (tp + fn)\n",
    "    tn_rate = tn / (tn + fp)\n",
    "    fn_rate = fn / (fn + tp)\n",
    "    fp_rate = fp / (tn + fp)\n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(disease_true, disease_pred)\n",
    "    auprc = auc(recall, precision)\n",
    "\n",
    "\n",
    "    metrics2[disease] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'AUC': auc_roc,\n",
    "        'AUPRC': auprc,\n",
    "        'F1 Score': f1,\n",
    "        'TP Rate': tp_rate,\n",
    "        'FN Rate': fn_rate,\n",
    "        'TN Rate': tn_rate,\n",
    "        'FP Rate': fp_rate\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_3 = {}\n",
    "for idx, disease in enumerate(diseases):\n",
    "    # disease_pred = predictions[:, idx]\n",
    "    disease_pred = predictions3[:, idx]\n",
    "    disease_true = targets3[:, idx]\n",
    "    auc_roc = roc_auc_score(disease_true, disease_pred)\n",
    "    f1 = f1_score(disease_true, (disease_pred > 0.5).astype(int))\n",
    "    accuracy = accuracy_score(disease_true, (disease_pred > 0.5).astype(int))\n",
    "    tn, fp, fn, tp = confusion_matrix(disease_true, (disease_pred > 0.5).astype(int)).ravel()\n",
    "    tp_rate = tp / (tp + fn)\n",
    "    tn_rate = tn / (tn + fp)\n",
    "    fn_rate = fn / (fn + tp)\n",
    "    fp_rate = fp / (tn + fp)\n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(disease_true, disease_pred)\n",
    "    auprc = auc(recall, precision)\n",
    "\n",
    "\n",
    "    metrics_3[disease] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'AUC': auc_roc,\n",
    "        'AUPRC': auprc,\n",
    "        'F1 Score': f1,\n",
    "        'TP Rate': tp_rate,\n",
    "        'FN Rate': fn_rate,\n",
    "        'TN Rate': tn_rate,\n",
    "        'FP Rate': fp_rate\n",
    "        }\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e2600_row0_col1, #T_e2600_row1_col3, #T_e2600_row1_col4, #T_e2600_row5_col2 {\n",
       "  background-color: #fde725;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e2600_row0_col2 {\n",
       "  background-color: #b2dd2d;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e2600_row0_col3 {\n",
       "  background-color: #21918c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e2600_row0_col4 {\n",
       "  background-color: #46337f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e2600_row1_col1 {\n",
       "  background-color: #297a8e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e2600_row1_col2 {\n",
       "  background-color: #3d4e8a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e2600_row2_col1 {\n",
       "  background-color: #a8db34;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e2600_row2_col2 {\n",
       "  background-color: #9dd93b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e2600_row2_col3 {\n",
       "  background-color: #453581;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e2600_row2_col4 {\n",
       "  background-color: #70cf57;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e2600_row3_col1, #T_e2600_row3_col2, #T_e2600_row3_col4, #T_e2600_row5_col3 {\n",
       "  background-color: #440154;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e2600_row3_col3 {\n",
       "  background-color: #238a8d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e2600_row4_col1 {\n",
       "  background-color: #20a486;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e2600_row4_col2 {\n",
       "  background-color: #21a685;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e2600_row4_col3 {\n",
       "  background-color: #424186;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e2600_row4_col4 {\n",
       "  background-color: #482071;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e2600_row5_col1 {\n",
       "  background-color: #f6e620;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e2600_row5_col4 {\n",
       "  background-color: #28ae80;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e2600\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e2600_level0_col0\" class=\"col_heading level0 col0\" >Disease</th>\n",
       "      <th id=\"T_e2600_level0_col1\" class=\"col_heading level0 col1\" >AUC_1</th>\n",
       "      <th id=\"T_e2600_level0_col2\" class=\"col_heading level0 col2\" >AUC_2</th>\n",
       "      <th id=\"T_e2600_level0_col3\" class=\"col_heading level0 col3\" >Delta AUC</th>\n",
       "      <th id=\"T_e2600_level0_col4\" class=\"col_heading level0 col4\" >EqOdds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e2600_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e2600_row0_col0\" class=\"data row0 col0\" >Cardiomegaly</td>\n",
       "      <td id=\"T_e2600_row0_col1\" class=\"data row0 col1\" >81.263</td>\n",
       "      <td id=\"T_e2600_row0_col2\" class=\"data row0 col2\" >77.021</td>\n",
       "      <td id=\"T_e2600_row0_col3\" class=\"data row0 col3\" >4.243</td>\n",
       "      <td id=\"T_e2600_row0_col4\" class=\"data row0 col4\" >1.553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e2600_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_e2600_row1_col0\" class=\"data row1 col0\" >Lung Opacity</td>\n",
       "      <td id=\"T_e2600_row1_col1\" class=\"data row1 col1\" >70.360</td>\n",
       "      <td id=\"T_e2600_row1_col2\" class=\"data row1 col2\" >63.560</td>\n",
       "      <td id=\"T_e2600_row1_col3\" class=\"data row1 col3\" >6.799</td>\n",
       "      <td id=\"T_e2600_row1_col4\" class=\"data row1 col4\" >10.586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e2600_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_e2600_row2_col0\" class=\"data row2 col0\" >Edema</td>\n",
       "      <td id=\"T_e2600_row2_col1\" class=\"data row2 col1\" >78.838</td>\n",
       "      <td id=\"T_e2600_row2_col2\" class=\"data row2 col2\" >76.378</td>\n",
       "      <td id=\"T_e2600_row2_col3\" class=\"data row2 col3\" >2.460</td>\n",
       "      <td id=\"T_e2600_row2_col4\" class=\"data row2 col4\" >8.286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e2600_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_e2600_row3_col0\" class=\"data row3 col0\" >Atelectasis</td>\n",
       "      <td id=\"T_e2600_row3_col1\" class=\"data row3 col1\" >62.816</td>\n",
       "      <td id=\"T_e2600_row3_col2\" class=\"data row3 col2\" >58.709</td>\n",
       "      <td id=\"T_e2600_row3_col3\" class=\"data row3 col3\" >4.107</td>\n",
       "      <td id=\"T_e2600_row3_col4\" class=\"data row3 col4\" >0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e2600_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_e2600_row4_col0\" class=\"data row4 col0\" >Pneumothorax</td>\n",
       "      <td id=\"T_e2600_row4_col1\" class=\"data row4 col1\" >73.621</td>\n",
       "      <td id=\"T_e2600_row4_col2\" class=\"data row4 col2\" >70.958</td>\n",
       "      <td id=\"T_e2600_row4_col3\" class=\"data row4 col3\" >2.663</td>\n",
       "      <td id=\"T_e2600_row4_col4\" class=\"data row4 col4\" >0.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e2600_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_e2600_row5_col0\" class=\"data row5 col0\" >Pleural Effusion</td>\n",
       "      <td id=\"T_e2600_row5_col1\" class=\"data row5 col1\" >81.024</td>\n",
       "      <td id=\"T_e2600_row5_col2\" class=\"data row5 col2\" >79.365</td>\n",
       "      <td id=\"T_e2600_row5_col3\" class=\"data row5 col3\" >1.659</td>\n",
       "      <td id=\"T_e2600_row5_col4\" class=\"data row5 col4\" >6.622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f4af525aa30>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize an empty list to store the data\n",
    "data_sex = []\n",
    "\n",
    "# Iterate over the diseases in the metrics dictionary\n",
    "for disease, values in metrics2.items():\n",
    "    # Extract AUC and rates from dictionaries\n",
    "    \n",
    "    auc_1 = metrics_1[disease]['AUC'] *100\n",
    "    auc_2 = metrics2[disease]['AUC'] *100\n",
    "    tp_rate_1 = metrics_1[disease]['TP Rate'] *100\n",
    "    tp_rate_2 = metrics2[disease]['TP Rate'] *100\n",
    "    fp_rate_1 = metrics_1[disease]['FP Rate'] *100\n",
    "    fp_rate_2 = metrics2[disease]['FP Rate'] *100\n",
    "    \n",
    "    # Calculate delta AUC and equality of odds\n",
    "    delta_auc_sex = abs(auc_1 - auc_2)\n",
    "    eq_odds_sex = 0.5 * (abs(tp_rate_1 - tp_rate_2) + abs(fp_rate_1 - fp_rate_2))\n",
    "    \n",
    "    # Append to the data list\n",
    "    data_sex.append([disease, auc_1, auc_2, delta_auc_sex, eq_odds_sex])\n",
    "\n",
    "# Create a DataFrame\n",
    "df_sex = pd.DataFrame(data_sex, columns=['Disease', 'AUC_1', 'AUC_2', 'Delta AUC', 'EqOdds'])\n",
    "\n",
    "\n",
    "# Styling the DataFrame\n",
    "styled_df = df_sex.style.format({\n",
    "    'AUC_1': \"{:.3f}\", \n",
    "    'AUC_2': \"{:.3f}\",\n",
    "    'Delta AUC': \"{:.3f}\",\n",
    "    'EqOdds': \"{:.3f}\"\n",
    "}).background_gradient(cmap='viridis', subset=['AUC_1', 'AUC_2', 'Delta AUC', 'EqOdds'])\n",
    "\n",
    "# Display the styled DataFrame\n",
    "styled_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize an empty list to store the data\n",
    "# data_race = []\n",
    "\n",
    "# # Iterate over the diseases in the metrics dictionary\n",
    "# for disease, values in metrics2.items():\n",
    "   \n",
    "#     auc_groups = [\n",
    "#         metrics_1[disease]['AUC'] *100,\n",
    "#         metrics2[disease]['AUC'] *100,\n",
    "#         metrics_3[disease]['AUC'] *100\n",
    "#     ]\n",
    "#     tp_rates = [\n",
    "#         metrics_1[disease]['TP Rate'] *100,\n",
    "#         metrics2[disease]['TP Rate'] *100,\n",
    "#         metrics_3[disease]['TP Rate'] *100\n",
    "#     ]\n",
    "#     fp_rates = [\n",
    "#         metrics_1[disease]['FP Rate'] *100,\n",
    "#         metrics2[disease]['FP Rate'] *100,\n",
    "#         metrics_3[disease]['FP Rate'] *100\n",
    "#     ]\n",
    "\n",
    "#     # Calculate the maximum delta AUC\n",
    "#     delta_auc_race = max(abs(auc_groups[i] - auc_groups[j]) for i in range(len(auc_groups)) for j in range(i + 1, len(auc_groups)))\n",
    "\n",
    "#     # Calculate the maximum equality of odds\n",
    "#     eq_odds_race = max(\n",
    "#         0.5 * (abs(tp_rates[i] - tp_rates[j]) + abs(fp_rates[i] - fp_rates[j]))\n",
    "#         for i in range(len(tp_rates)) for j in range(i + 1, len(tp_rates))\n",
    "#     )\n",
    "\n",
    "#     # Append to the data list\n",
    "#     data_race.append([disease] + auc_groups + [delta_auc_race, eq_odds_race])\n",
    "\n",
    "\n",
    "\n",
    "# df_sex = pd.DataFrame(data_sex, columns=['Disease', 'AUC_1', 'AUC_2', 'AUC_3', 'Delta AUC', 'EqOdds'])\n",
    "\n",
    "\n",
    "# # Styling the DataFrame\n",
    "# styled_df = df_sex.style.format({\n",
    "#     'AUC_1': \"{:.3f}\", \n",
    "#     'AUC_2': \"{:.3f}\",\n",
    "#     'AUC_3': \"{:.3f}\",\n",
    "#     'Delta AUC': \"{:.3f}\",\n",
    "#     'EqOdds': \"{:.3f}\"\n",
    "# }).background_gradient(cmap='viridis', subset=['AUC_1', 'AUC_2', 'AUC_3', 'Delta AUC', 'EqOdds'])\n",
    "\n",
    "# # Display the styled DataFrame\n",
    "# styled_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mitigate-bias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
